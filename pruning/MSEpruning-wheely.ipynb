{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Краткий отчёт о пользе обрезания - теперь со вкусом NDCG\n",
    "формул EventFilter\n",
    "\n",
    "Рассматривается формула EventFilterRegressor, обученная ранжировать результаты поиска на данных MSLR-Web10k.\n",
    "\n",
    "[ http://research.microsoft.com/en-us/projects/mslr/ ]\n",
    "\n",
    "Сравниваются 2 варианта прунинга (удаления из формулы) деревьев: жадный и иерархический прунинг.\n",
    "\n",
    "##Много вспомогательных модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "#math & plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#sklearn\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import cPickle\n",
    "def cDump(obj,fname):\n",
    "    with open(fname,'w') as f:\n",
    "        cPickle.dump(obj,f)\n",
    "def cLoad(fname):\n",
    "    with open(fname,'r') as f:\n",
    "        return cPickle.load(f)\n",
    "        \n",
    "import _matrixnetapplier as mnet\n",
    "\n",
    "#debug purposes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "target_n_trees = 100\n",
    "global_n_jobs = 8\n",
    "global_use_joblib = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные MSLR-Web10k\n",
    "* Около 1.2 миллиона документов\n",
    "* 10 000 запросов\n",
    "\n",
    "[ http://research.microsoft.com/en-us/projects/mslr/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io_ranking as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_data = False\n",
    "if generate_data:\n",
    "    #Пересохраняем csv в H5\n",
    "    ##warning! this can take a long time. no need to rerun that code if u have CSV files created once.\n",
    "    io.save_csv(\"../data/MSLR10/Fold1/train.txt\",\"../data/MSLR10/mslr_train\")\n",
    "    io.save_csv(\"../data/MSLR10/Fold1/test.txt\",\"../data/MSLR10/mslr_test\")\n",
    "    io.save_csv(\"../data/MSLR10/Fold1/vali.txt\",\"../data/MSLR10/mslr_vali\")\n",
    "    print \"converted that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from ../data/MSLR10/mslr_vali\n",
      "done\n",
      "reading from ../data/MSLR10/mslr_test\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#используется Fold1\n",
    "Xtr,Qtr,Ytr = io.load_csv(\"../data/MSLR10/mslr_vali\")\n",
    "Xts,Qts,Yts = io.load_csv(\"../data/MSLR10/mslr_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#обёртка над данными для удобства работы с ними\n",
    "from factory import RegressionFactory\n",
    "#DataFactory is just a data wrapper that can handle splits, predictions, etc. \n",
    "#Used to avoid recommputing metadata at each predictions and passing large argument strings\n",
    "trainFactory = RegressionFactory(Xtr.astype('float32'),Ytr.astype('int8'),ids = Qtr.astype('int32'))\n",
    "testFactory = RegressionFactory(Xts.astype('float32'),Yts.astype('int8'),ids = Qts.astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (235259, 136) qids: 2000\n",
      "test:  (241521, 136) qids: 2000\n",
      "qid intersection: 0 (must be 0)\n"
     ]
    }
   ],
   "source": [
    "print \"train: \",trainFactory.events.shape,\"qids:\",len(set(Qtr))\n",
    "print \"test: \",testFactory.events.shape,\"qids:\",len(set(Qts))\n",
    "print \"qid intersection:\",len(set.intersection(set(Qtr),set(Qts))),\"(must be 0)\"\n",
    "del Xtr,Ytr,Xts,Yts,Qtr,Qts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первоначальная формула\n",
    "EventFilterRegressor на 10к деревьев, обученный по MSE без прикрас"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "\n",
    "read = True\n",
    "fname = \"../formula/MSLR10k_ef.mx\"\n",
    "if not read:\n",
    "    from rep_ef.estimators import EventFilterRegressor\n",
    "    ef = EventFilterRegressor(iterations=10000, connection='test_connection', dataset_name='letor-{random}').fit(Xtr,Ytr)\n",
    "    cDump(ef.formula_mx, fname)\n",
    "else:\n",
    "    with open(fname, 'r') as f:\n",
    "        formula = mnet.MatrixnetClassifier(StringIO(cPickle.load(f))) #btw he's a regressor, not classifier\n",
    "\n",
    "    depth, nTrees, itr = formula.iterate_trees().next()\n",
    "    trees = [tree for tree in itr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#конвертируем в местный формат для удобства работы\n",
    "from greedy import PrunedFormula as pf\n",
    "bias = 0.0# NOT np.average(trainFactory.labels)\n",
    "trees_stupid = pf(trees[:target_n_trees],bias)\n",
    "trees_full = pf(trees,bias)\n",
    "\n",
    "y_pred_stupid = trees_stupid.predict(testFactory)\n",
    "\n",
    "read=True\n",
    "fname = \"../dumps/pred_full_formula.pcl\"\n",
    "if not read:\n",
    "    y_pred_full = trees_full.predict(testFactory)\n",
    "    cDump(y_pred_full,fname)\n",
    "else:\n",
    "    y_pred_full = cLoad(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#колёсико"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import greedy #модуль, который умеет делать жадный прунинг\n",
    "from loss_functions import MSELoss #функция потерь для него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration # 0  ntrees =  9997 \n",
      "best loss =  129650.437819\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 1  ntrees =  9997 \n",
      "best loss =  129640.835905 \n",
      "last loss =  129640.835905\n",
      "Validation loss: 133938.461344\n",
      "changed index 1638\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 2  ntrees =  9997 \n",
      "best loss =  129631.421162 \n",
      "last loss =  129631.421162\n",
      "Validation loss: 133937.360857\n",
      "changed index 8762\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 3  ntrees =  9997 \n",
      "best loss =  129623.378222 \n",
      "last loss =  129623.378222\n",
      "Validation loss: 133935.654792\n",
      "changed index 5540\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 4  ntrees =  9997 \n",
      "best loss =  129616.7219 \n",
      "last loss =  129616.7219\n",
      "Validation loss: 133934.148072\n",
      "changed index 7826\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 5  ntrees =  9997 \n",
      "best loss =  129607.597663 \n",
      "last loss =  129607.597663\n",
      "Validation loss: 133939.778625\n",
      "changed index 161\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 6  ntrees =  9997 \n",
      "best loss =  129600.238492 \n",
      "last loss =  129600.238492\n",
      "Validation loss: 133938.101526\n",
      "changed index 3084\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 7  ntrees =  9997 \n",
      "best loss =  129592.883671 \n",
      "last loss =  129592.883671\n",
      "Validation loss: 133937.949281\n",
      "changed index 9362\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 8  ntrees =  9997 \n",
      "best loss =  129585.147839 \n",
      "last loss =  129585.147839\n",
      "Validation loss: 133936.714991\n",
      "changed index 1652\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 9  ntrees =  9997 \n",
      "best loss =  129577.960327 \n",
      "last loss =  129577.960327\n",
      "Validation loss: 133937.077171\n",
      "changed index 9832\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 10  ntrees =  9997 \n",
      "best loss =  129570.913495 \n",
      "last loss =  129570.913495\n",
      "Validation loss: 133937.494056\n",
      "changed index 9420\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 11  ntrees =  9997 \n",
      "best loss =  129563.374872 \n",
      "last loss =  129563.374872\n",
      "Validation loss: 133936.23902\n",
      "changed index 7308\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 12  ntrees =  9997 \n",
      "best loss =  129556.253564 \n",
      "last loss =  129556.253564\n",
      "Validation loss: 133935.202525\n",
      "changed index 424\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 13  ntrees =  9997 \n",
      "best loss =  129549.272003 \n",
      "last loss =  129549.272003\n",
      "Validation loss: 133934.92993\n",
      "changed index 2251\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 14  ntrees =  9997 \n",
      "best loss =  129542.429433 \n",
      "last loss =  129542.429433\n",
      "Validation loss: 133935.38797\n",
      "changed index 2300\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 15  ntrees =  9997 \n",
      "best loss =  129535.554126 \n",
      "last loss =  129535.554126\n",
      "Validation loss: 133937.324984\n",
      "changed index 5922\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 16  ntrees =  9997 \n",
      "best loss =  129528.244064 \n",
      "last loss =  129528.244064\n",
      "Validation loss: 133936.880861\n",
      "changed index 690\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 17  ntrees =  9997 \n",
      "best loss =  129521.531159 \n",
      "last loss =  129521.531159\n",
      "Validation loss: 133938.886484\n",
      "changed index 1340\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 18  ntrees =  9997 \n",
      "best loss =  129513.069 \n",
      "last loss =  129513.069\n",
      "Validation loss: 133937.704155\n",
      "changed index 4476\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 19  ntrees =  9997 \n",
      "best loss =  129504.771682 \n",
      "last loss =  129504.771682\n",
      "Validation loss: 133936.870872\n",
      "changed index 4918\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 20  ntrees =  9997 \n",
      "best loss =  129496.63599 \n",
      "last loss =  129496.63599\n",
      "Validation loss: 133936.61319\n",
      "changed index 2710\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 21  ntrees =  9997 \n",
      "best loss =  129488.658769 \n",
      "last loss =  129488.658769\n",
      "Validation loss: 133936.033571\n",
      "changed index 4553\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 22  ntrees =  9997 \n",
      "best loss =  129481.945559 \n",
      "last loss =  129481.945559\n",
      "Validation loss: 133935.472753\n",
      "changed index 6834\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 23  ntrees =  9997 \n",
      "best loss =  129474.139274 \n",
      "last loss =  129474.139274\n",
      "Validation loss: 133935.304387\n",
      "changed index 3716\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 24  ntrees =  9997 \n",
      "best loss =  129467.70918 \n",
      "last loss =  129467.70918\n",
      "Validation loss: 133934.401639\n",
      "changed index 1885\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 25  ntrees =  9997 \n",
      "best loss =  129461.097495 \n",
      "last loss =  129461.097495\n",
      "Validation loss: 133932.912382\n",
      "changed index 6319\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 26  ntrees =  9997 \n",
      "best loss =  129453.50049 \n",
      "last loss =  129453.50049\n",
      "Validation loss: 133932.543766\n",
      "changed index 9874\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 27  ntrees =  9997 \n",
      "best loss =  129447.171184 \n",
      "last loss =  129447.171184\n",
      "Validation loss: 133930.894328\n",
      "changed index 6978\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 28  ntrees =  9997 \n",
      "best loss =  129440.792852 \n",
      "last loss =  129440.792852\n",
      "Validation loss: 133929.488016\n",
      "changed index 2336\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 29  ntrees =  9997 \n",
      "best loss =  129434.033851 \n",
      "last loss =  129434.033851\n",
      "Validation loss: 133929.701746\n",
      "changed index 2321\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 30  ntrees =  9997 \n",
      "best loss =  129426.702566 \n",
      "last loss =  129426.702566\n",
      "Validation loss: 133929.496916\n",
      "changed index 8434\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 31  ntrees =  9997 \n",
      "best loss =  129420.467406 \n",
      "last loss =  129420.467406\n",
      "Validation loss: 133928.650748\n",
      "changed index 4178\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 32  ntrees =  9997 \n",
      "best loss =  129414.184257 \n",
      "last loss =  129414.184257\n",
      "Validation loss: 133927.354561\n",
      "changed index 7609\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 33  ntrees =  9997 \n",
      "best loss =  129407.047107 \n",
      "last loss =  129407.047107\n",
      "Validation loss: 133927.239782\n",
      "changed index 5070\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 34  ntrees =  9997 \n",
      "best loss =  129400.537557 \n",
      "last loss =  129400.537557\n",
      "Validation loss: 133926.814813\n",
      "changed index 8131\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 35  ntrees =  9997 \n",
      "best loss =  129393.574882 \n",
      "last loss =  129393.574882\n",
      "Validation loss: 133927.091702\n",
      "changed index 4378\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 36  ntrees =  9997 \n",
      "best loss =  129387.227888 \n",
      "last loss =  129387.227888\n",
      "Validation loss: 133929.484109\n",
      "changed index 204\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 37  ntrees =  9997 \n",
      "best loss =  129381.109317 \n",
      "last loss =  129381.109317\n",
      "Validation loss: 133931.347464\n",
      "changed index 5932\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 38  ntrees =  9997 \n",
      "best loss =  129374.907457 \n",
      "last loss =  129374.907457\n",
      "Validation loss: 133930.887033\n",
      "changed index 8758\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 39  ntrees =  9997 \n",
      "best loss =  129368.176107 \n",
      "last loss =  129368.176107\n",
      "Validation loss: 133930.796261\n",
      "changed index 3297\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 40  ntrees =  9997 \n",
      "best loss =  129361.814188 \n",
      "last loss =  129361.814188\n",
      "Validation loss: 133938.182485\n",
      "changed index 148\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 41  ntrees =  9997 \n",
      "best loss =  129355.577099 \n",
      "last loss =  129355.577099\n",
      "Validation loss: 133937.341651\n",
      "changed index 9913\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 42  ntrees =  9997 \n",
      "best loss =  129349.550708 \n",
      "last loss =  129349.550708\n",
      "Validation loss: 133937.283805\n",
      "changed index 2369\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 43  ntrees =  9997 \n",
      "best loss =  129343.007003 \n",
      "last loss =  129343.007003\n",
      "Validation loss: 133937.266753\n",
      "changed index 8450\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 44  ntrees =  9997 \n",
      "best loss =  129336.59064 \n",
      "last loss =  129336.59064\n",
      "Validation loss: 133937.8153\n",
      "changed index 7363\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 45  ntrees =  9997 \n",
      "best loss =  129330.623844 \n",
      "last loss =  129330.623844\n",
      "Validation loss: 133934.915242\n",
      "changed index 1075\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 46  ntrees =  9997 \n",
      "best loss =  129324.646115 \n",
      "last loss =  129324.646115\n",
      "Validation loss: 133934.343501\n",
      "changed index 7228\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 47  ntrees =  9997 \n",
      "best loss =  129318.377773 \n",
      "last loss =  129318.377773\n",
      "Validation loss: 133934.795098\n",
      "changed index 8446\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 48  ntrees =  9997 \n",
      "best loss =  129312.231398 \n",
      "last loss =  129312.231398\n",
      "Validation loss: 133935.028762\n",
      "changed index 5651\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 49  ntrees =  9997 \n",
      "best loss =  129306.204614 \n",
      "last loss =  129306.204614\n",
      "Validation loss: 133935.425599\n",
      "changed index 1384\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 50  ntrees =  9997 \n",
      "best loss =  129300.416846 \n",
      "last loss =  129300.416846\n",
      "Validation loss: 133936.148165\n",
      "changed index 7779\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 51  ntrees =  9997 \n",
      "best loss =  129294.590799 \n",
      "last loss =  129294.590799\n",
      "Validation loss: 133935.337305\n",
      "changed index 9951\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 52  ntrees =  9997 \n",
      "best loss =  129288.57949 \n",
      "last loss =  129288.57949\n",
      "Validation loss: 133956.706997\n",
      "changed index 62\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 53  ntrees =  9997 \n",
      "best loss =  129282.686127 \n",
      "last loss =  129282.686127\n",
      "Validation loss: 133956.341503\n",
      "changed index 4312\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 54  ntrees =  9997 \n",
      "best loss =  129276.833314 \n",
      "last loss =  129276.833314\n",
      "Validation loss: 133956.607489\n",
      "changed index 6933\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 55  ntrees =  9997 \n",
      "best loss =  129271.113951 \n",
      "last loss =  129271.113951\n",
      "Validation loss: 133953.766938\n",
      "changed index 1511\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 56  ntrees =  9997 \n",
      "best loss =  129265.448001 \n",
      "last loss =  129265.448001\n",
      "Validation loss: 133955.629962\n",
      "changed index 2827\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 57  ntrees =  9997 \n",
      "best loss =  129259.70045 \n",
      "last loss =  129259.70045\n",
      "Validation loss: 133955.416456\n",
      "changed index 7778\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 58  ntrees =  9997 \n",
      "best loss =  129254.030528 \n",
      "last loss =  129254.030528\n",
      "Validation loss: 133954.804591\n",
      "changed index 9386\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 59  ntrees =  9997 \n",
      "best loss =  129248.399147 \n",
      "last loss =  129248.399147\n",
      "Validation loss: 133954.52542\n",
      "changed index 4375\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 60  ntrees =  9997 \n",
      "best loss =  129242.761824 \n",
      "last loss =  129242.761824\n",
      "Validation loss: 133953.370848\n",
      "changed index 7648\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 61  ntrees =  9997 \n",
      "best loss =  129237.158384 \n",
      "last loss =  129237.158384\n",
      "Validation loss: 133953.377383\n",
      "changed index 5927\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 62  ntrees =  9997 \n",
      "best loss =  129231.655018 \n",
      "last loss =  129231.655018\n",
      "Validation loss: 133952.724504\n",
      "changed index 5753\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 63  ntrees =  9997 \n",
      "best loss =  129226.132286 \n",
      "last loss =  129226.132286\n",
      "Validation loss: 133949.831971\n",
      "changed index 6183\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 64  ntrees =  9997 \n",
      "best loss =  129220.521441 \n",
      "last loss =  129220.521441\n",
      "Validation loss: 133951.086612\n",
      "changed index 8840\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 65  ntrees =  9997 \n",
      "best loss =  129215.052185 \n",
      "last loss =  129215.052185\n",
      "Validation loss: 133950.089737\n",
      "changed index 9637\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 66  ntrees =  9997 \n",
      "best loss =  129209.653657 \n",
      "last loss =  129209.653657\n",
      "Validation loss: 133977.022613\n",
      "changed index 71\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 67  ntrees =  9997 \n",
      "best loss =  129204.145886 \n",
      "last loss =  129204.145886\n",
      "Validation loss: 133976.534116\n",
      "changed index 5755\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 68  ntrees =  9997 \n",
      "best loss =  129198.722041 \n",
      "last loss =  129198.722041\n",
      "Validation loss: 133977.430592\n",
      "changed index 2442\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 69  ntrees =  9997 \n",
      "best loss =  129193.428259 \n",
      "last loss =  129193.428259\n",
      "Validation loss: 133976.270269\n",
      "changed index 2506\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 70  ntrees =  9997 \n",
      "best loss =  129188.025958 \n",
      "last loss =  129188.025958\n",
      "Validation loss: 133975.691342\n",
      "changed index 8495\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 71  ntrees =  9997 \n",
      "best loss =  129182.771148 \n",
      "last loss =  129182.771148\n",
      "Validation loss: 133974.892488\n",
      "changed index 574\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 72  ntrees =  9997 \n",
      "best loss =  129177.419987 \n",
      "last loss =  129177.419987\n",
      "Validation loss: 133973.993842\n",
      "changed index 3637\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 73  ntrees =  9997 \n",
      "best loss =  129172.062467 \n",
      "last loss =  129172.062467\n",
      "Validation loss: 133976.607102\n",
      "changed index 3687\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 74  ntrees =  9997 \n",
      "best loss =  129166.692746 \n",
      "last loss =  129166.692746\n",
      "Validation loss: 133976.417667\n",
      "changed index 9709\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 75  ntrees =  9997 \n",
      "best loss =  129161.397364 \n",
      "last loss =  129161.397364\n",
      "Validation loss: 133976.910929\n",
      "changed index 3028\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 76  ntrees =  9997 \n",
      "best loss =  129156.153385 \n",
      "last loss =  129156.153385\n",
      "Validation loss: 133976.119388\n",
      "changed index 5230\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 77  ntrees =  9997 \n",
      "best loss =  129150.857563 \n",
      "last loss =  129150.857563\n",
      "Validation loss: 133975.986608\n",
      "changed index 4414\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 78  ntrees =  9997 \n",
      "best loss =  129145.614222 \n",
      "last loss =  129145.614222\n",
      "Validation loss: 133973.361385\n",
      "changed index 2278\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 79  ntrees =  9997 \n",
      "best loss =  129140.371799 \n",
      "last loss =  129140.371799\n",
      "Validation loss: 133972.261312\n",
      "changed index 3257\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 80  ntrees =  9997 \n",
      "best loss =  129135.114675 \n",
      "last loss =  129135.114675\n",
      "Validation loss: 133972.370542\n",
      "changed index 4818\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 81  ntrees =  9997 \n",
      "best loss =  129129.976805 \n",
      "last loss =  129129.976805\n",
      "Validation loss: 133975.088396\n",
      "changed index 311\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 82  ntrees =  9997 \n",
      "best loss =  129124.752258 \n",
      "last loss =  129124.752258\n",
      "Validation loss: 133974.693778\n",
      "changed index 5967\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 83  ntrees =  9997 \n",
      "best loss =  129119.719354 \n",
      "last loss =  129119.719354\n",
      "Validation loss: 133973.574201\n",
      "changed index 8794\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 84  ntrees =  9997 \n",
      "best loss =  129114.814875 \n",
      "last loss =  129114.814875\n",
      "Validation loss: 133972.865715\n",
      "changed index 1222\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 85  ntrees =  9997 \n",
      "best loss =  129109.700579 \n",
      "last loss =  129109.700579\n",
      "Validation loss: 133973.694355\n",
      "changed index 4749\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 86  ntrees =  9997 \n",
      "best loss =  129104.558649 \n",
      "last loss =  129104.558649\n",
      "Validation loss: 133973.574229\n",
      "changed index 8953\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 87  ntrees =  9997 \n",
      "best loss =  129099.444679 \n",
      "last loss =  129099.444679\n",
      "Validation loss: 133975.577369\n",
      "changed index 1945\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 88  ntrees =  9997 \n",
      "best loss =  129094.474659 \n",
      "last loss =  129094.474659\n",
      "Validation loss: 133975.145504\n",
      "changed index 7522\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 89  ntrees =  9997 \n",
      "best loss =  129089.424072 \n",
      "last loss =  129089.424072\n",
      "Validation loss: 133974.537166\n",
      "changed index 9240\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 90  ntrees =  9997 \n",
      "best loss =  129084.329732 \n",
      "last loss =  129084.329732\n",
      "Validation loss: 133974.673778\n",
      "changed index 1700\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 91  ntrees =  9997 \n",
      "best loss =  129079.258864 \n",
      "last loss =  129079.258864\n",
      "Validation loss: 133974.144569\n",
      "changed index 1780\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 92  ntrees =  9997 \n",
      "best loss =  129074.2645 \n",
      "last loss =  129074.2645\n",
      "Validation loss: 133995.249546\n",
      "changed index 117\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 93  ntrees =  9997 \n",
      "best loss =  129069.256744 \n",
      "last loss =  129069.256744\n",
      "Validation loss: 133996.049438\n",
      "changed index 2019\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 94  ntrees =  9997 \n",
      "best loss =  129064.281082 \n",
      "last loss =  129064.281082\n",
      "Validation loss: 133999.216565\n",
      "changed index 373\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 95  ntrees =  9997 \n",
      "best loss =  129059.317711 \n",
      "last loss =  129059.317711\n",
      "Validation loss: 133996.604756\n",
      "changed index 9427\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 96  ntrees =  9997 \n",
      "best loss =  129054.344341 \n",
      "last loss =  129054.344341\n",
      "Validation loss: 133996.652928\n",
      "changed index 9799\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 97  ntrees =  9997 \n",
      "best loss =  129049.435104 \n",
      "last loss =  129049.435104\n",
      "Validation loss: 133996.127505\n",
      "changed index 6282\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 98  ntrees =  9997 \n",
      "best loss =  129044.496449 \n",
      "last loss =  129044.496449\n",
      "Validation loss: 133995.603789\n",
      "changed index 6703\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 99  ntrees =  9997 \n",
      "best loss =  129039.654138 \n",
      "last loss =  129039.654138\n",
      "Validation loss: 133995.3717\n",
      "changed index 9359\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 100  ntrees =  9997 \n",
      "best loss =  129034.695661 \n",
      "last loss =  129034.695661\n",
      "Validation loss: 133993.786746\n",
      "changed index 5527\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 101  ntrees =  9997 \n",
      "best loss =  129029.798016 \n",
      "last loss =  129029.798016\n",
      "Validation loss: 133998.769717\n",
      "changed index 265\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 102  ntrees =  9997 \n",
      "best loss =  129024.93041 \n",
      "last loss =  129024.93041\n",
      "Validation loss: 133998.739265\n",
      "changed index 9750\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 103  ntrees =  9997 \n",
      "best loss =  129020.132362 \n",
      "last loss =  129020.132362\n",
      "Validation loss: 133997.880179\n",
      "changed index 6673\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 104  ntrees =  9997 \n",
      "best loss =  129015.269733 \n",
      "last loss =  129015.269733\n",
      "Validation loss: 133997.942609\n",
      "changed index 3611\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 105  ntrees =  9997 \n",
      "best loss =  129010.475999 \n",
      "last loss =  129010.475999\n",
      "Validation loss: 133995.506292\n",
      "changed index 7829\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 106  ntrees =  9997 \n",
      "best loss =  129005.704552 \n",
      "last loss =  129005.704552\n",
      "Validation loss: 133994.644074\n",
      "changed index 5529\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 107  ntrees =  9997 \n",
      "best loss =  129000.891476 \n",
      "last loss =  129000.891476\n",
      "Validation loss: 133995.904353\n",
      "changed index 9500\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 108  ntrees =  9997 \n",
      "best loss =  128996.070872 \n",
      "last loss =  128996.070872\n",
      "Validation loss: 133995.155311\n",
      "changed index 3923\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 109  ntrees =  9997 \n",
      "best loss =  128991.297268 \n",
      "last loss =  128991.297268\n",
      "Validation loss: 133998.096822\n",
      "changed index 610\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 110  ntrees =  9997 \n",
      "best loss =  128986.54236 \n",
      "last loss =  128986.54236\n",
      "Validation loss: 133998.935248\n",
      "changed index 1614\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 111  ntrees =  9997 \n",
      "best loss =  128981.814254 \n",
      "last loss =  128981.814254\n",
      "Validation loss: 133999.098139\n",
      "changed index 1399\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 112  ntrees =  9997 \n",
      "best loss =  128977.070204 \n",
      "last loss =  128977.070204\n",
      "Validation loss: 134000.559326\n",
      "changed index 4604\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 113  ntrees =  9997 \n",
      "best loss =  128972.373879 \n",
      "last loss =  128972.373879\n",
      "Validation loss: 134000.123036\n",
      "changed index 3724\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 114  ntrees =  9997 \n",
      "best loss =  128967.700572 \n",
      "last loss =  128967.700572\n",
      "Validation loss: 133999.360572\n",
      "changed index 4393\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 115  ntrees =  9997 \n",
      "best loss =  128963.073606 \n",
      "last loss =  128963.073606\n",
      "Validation loss: 133998.572479\n",
      "changed index 2580\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 116  ntrees =  9997 \n",
      "best loss =  128958.417898 \n",
      "last loss =  128958.417898\n",
      "Validation loss: 133998.265789\n",
      "changed index 6483\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 117  ntrees =  9997 \n",
      "best loss =  128953.698287 \n",
      "last loss =  128953.698287\n",
      "Validation loss: 133998.424811\n",
      "changed index 2763\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 118  ntrees =  9997 \n",
      "best loss =  128949.016917 \n",
      "last loss =  128949.016917\n",
      "Validation loss: 133997.777265\n",
      "changed index 2268\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 119  ntrees =  9997 \n",
      "best loss =  128944.358875 \n",
      "last loss =  128944.358875\n",
      "Validation loss: 133997.880424\n",
      "changed index 3741\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 120  ntrees =  9997 \n",
      "best loss =  128939.733524 \n",
      "last loss =  128939.733524\n",
      "Validation loss: 133999.696668\n",
      "changed index 1008\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 121  ntrees =  9997 \n",
      "best loss =  128935.112062 \n",
      "last loss =  128935.112062\n",
      "Validation loss: 133999.802279\n",
      "changed index 2858\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 122  ntrees =  9997 \n",
      "best loss =  128930.523538 \n",
      "last loss =  128930.523538\n",
      "Validation loss: 134002.049324\n",
      "changed index 6612\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 123  ntrees =  9997 \n",
      "best loss =  128925.94506 \n",
      "last loss =  128925.94506\n",
      "Validation loss: 134003.670313\n",
      "changed index 3932\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 124  ntrees =  9997 \n",
      "best loss =  128921.363016 \n",
      "last loss =  128921.363016\n",
      "Validation loss: 134003.855219\n",
      "changed index 7338\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 125  ntrees =  9997 \n",
      "best loss =  128916.822412 \n",
      "last loss =  128916.822412\n",
      "Validation loss: 134005.053154\n",
      "changed index 7802\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 126  ntrees =  9997 \n",
      "best loss =  128912.267801 \n",
      "last loss =  128912.267801\n",
      "Validation loss: 134004.549384\n",
      "changed index 9343\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 127  ntrees =  9997 \n",
      "best loss =  128907.746875 \n",
      "last loss =  128907.746875\n",
      "Validation loss: 134005.550099\n",
      "changed index 1034\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 128  ntrees =  9997 \n",
      "best loss =  128903.244213 \n",
      "last loss =  128903.244213\n",
      "Validation loss: 134004.940466\n",
      "changed index 7562\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 129  ntrees =  9997 \n",
      "best loss =  128898.764248 \n",
      "last loss =  128898.764248\n",
      "Validation loss: 134005.07967\n",
      "changed index 1074\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 130  ntrees =  9997 \n",
      "best loss =  128894.210181 \n",
      "last loss =  128894.210181\n",
      "Validation loss: 134005.555967\n",
      "changed index 8056\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 131  ntrees =  9997 \n",
      "best loss =  128889.684062 \n",
      "last loss =  128889.684062\n",
      "Validation loss: 134005.40393\n",
      "changed index 5147\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 132  ntrees =  9997 \n",
      "best loss =  128885.197189 \n",
      "last loss =  128885.197189\n",
      "Validation loss: 134004.686654\n",
      "changed index 2993\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 133  ntrees =  9997 \n",
      "best loss =  128880.729379 \n",
      "last loss =  128880.729379\n",
      "Validation loss: 134005.293252\n",
      "changed index 4343\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 134  ntrees =  9997 \n",
      "best loss =  128876.285063 \n",
      "last loss =  128876.285063\n",
      "Validation loss: 134005.720313\n",
      "changed index 1532\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 135  ntrees =  9997 \n",
      "best loss =  128871.818218 \n",
      "last loss =  128871.818218\n",
      "Validation loss: 134006.293287\n",
      "changed index 6300\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 136  ntrees =  9997 \n",
      "best loss =  128867.392912 \n",
      "last loss =  128867.392912\n",
      "Validation loss: 134006.130645\n",
      "changed index 4141\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 137  ntrees =  9997 \n",
      "best loss =  128862.976081 \n",
      "last loss =  128862.976081\n",
      "Validation loss: 134007.764718\n",
      "changed index 4638\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 138  ntrees =  9997 \n",
      "best loss =  128858.574188 \n",
      "last loss =  128858.574188\n",
      "Validation loss: 134042.091432\n",
      "changed index 63\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 139  ntrees =  9997 \n",
      "best loss =  128854.109101 \n",
      "last loss =  128854.109101\n",
      "Validation loss: 134041.579998\n",
      "changed index 5350\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 140  ntrees =  9997 \n",
      "best loss =  128849.698378 \n",
      "last loss =  128849.698378\n",
      "Validation loss: 134041.734282\n",
      "changed index 5894\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 141  ntrees =  9997 \n",
      "best loss =  128845.294266 \n",
      "last loss =  128845.294266\n",
      "Validation loss: 134042.615775\n",
      "changed index 429\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 142  ntrees =  9997 \n",
      "best loss =  128840.949136 \n",
      "last loss =  128840.949136\n",
      "Validation loss: 134042.714257\n",
      "changed index 9317\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 143  ntrees =  9997 \n",
      "best loss =  128836.58711 \n",
      "last loss =  128836.58711\n",
      "Validation loss: 134041.522226\n",
      "changed index 1170\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 144  ntrees =  9997 \n",
      "best loss =  128832.254389 \n",
      "last loss =  128832.254389\n",
      "Validation loss: 134041.400842\n",
      "changed index 5988\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 145  ntrees =  9997 \n",
      "best loss =  128827.916795 \n",
      "last loss =  128827.916795\n",
      "Validation loss: 134041.872797\n",
      "changed index 6355\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 146  ntrees =  9997 \n",
      "best loss =  128823.596769 \n",
      "last loss =  128823.596769\n",
      "Validation loss: 134042.214519\n",
      "changed index 8981\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 147  ntrees =  9997 \n",
      "best loss =  128819.241617 \n",
      "last loss =  128819.241617\n",
      "Validation loss: 134044.409145\n",
      "changed index 5548\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 148  ntrees =  9997 \n",
      "best loss =  128814.932821 \n",
      "last loss =  128814.932821\n",
      "Validation loss: 134043.3122\n",
      "changed index 6540\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 149  ntrees =  9997 \n",
      "best loss =  128810.630855 \n",
      "last loss =  128810.630855\n",
      "Validation loss: 134043.602484\n",
      "changed index 4471\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 150  ntrees =  9997 \n",
      "best loss =  128806.333029 \n",
      "last loss =  128806.333029\n",
      "Validation loss: 134042.767979\n",
      "changed index 1582\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 151  ntrees =  9997 \n",
      "best loss =  128801.994591 \n",
      "last loss =  128801.994591\n",
      "Validation loss: 134042.577675\n",
      "changed index 7733\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 152  ntrees =  9997 \n",
      "best loss =  128797.716075 \n",
      "last loss =  128797.716075\n",
      "Validation loss: 134042.256929\n",
      "changed index 4781\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 153  ntrees =  9997 \n",
      "best loss =  128793.454877 \n",
      "last loss =  128793.454877\n",
      "Validation loss: 134042.804753\n",
      "changed index 8022\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 154  ntrees =  9997 \n",
      "best loss =  128789.259715 \n",
      "last loss =  128789.259715\n",
      "Validation loss: 134043.206873\n",
      "changed index 3817\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 155  ntrees =  9997 \n",
      "best loss =  128784.995759 \n",
      "last loss =  128784.995759\n",
      "Validation loss: 134041.348863\n",
      "changed index 8988\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 156  ntrees =  9997 \n",
      "best loss =  128780.777017 \n",
      "last loss =  128780.777017\n",
      "Validation loss: 134041.732264\n",
      "changed index 3482\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 157  ntrees =  9997 \n",
      "best loss =  128776.56267 \n",
      "last loss =  128776.56267\n",
      "Validation loss: 134041.440669\n",
      "changed index 2395\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 158  ntrees =  9997 \n",
      "best loss =  128772.327333 \n",
      "last loss =  128772.327333\n",
      "Validation loss: 134041.158282\n",
      "changed index 5354\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 159  ntrees =  9997 \n",
      "best loss =  128768.112158 \n",
      "last loss =  128768.112158\n",
      "Validation loss: 134040.848283\n",
      "changed index 9936\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 160  ntrees =  9997 \n",
      "best loss =  128763.921465 \n",
      "last loss =  128763.921465\n",
      "Validation loss: 134041.449822\n",
      "changed index 7004\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 161  ntrees =  9997 \n",
      "best loss =  128759.729608 \n",
      "last loss =  128759.729608\n",
      "Validation loss: 134041.211168\n",
      "changed index 870\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 162  ntrees =  9997 \n",
      "best loss =  128755.523078 \n",
      "last loss =  128755.523078\n",
      "Validation loss: 134043.087272\n",
      "changed index 1834\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 163  ntrees =  9997 \n",
      "best loss =  128751.355284 \n",
      "last loss =  128751.355284\n",
      "Validation loss: 134045.200478\n",
      "changed index 7244\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 164  ntrees =  9997 \n",
      "best loss =  128747.227191 \n",
      "last loss =  128747.227191\n",
      "Validation loss: 134044.671678\n",
      "changed index 1111\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 165  ntrees =  9997 \n",
      "best loss =  128743.053363 \n",
      "last loss =  128743.053363\n",
      "Validation loss: 134044.564648\n",
      "changed index 5868\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 166  ntrees =  9997 \n",
      "best loss =  128738.864724 \n",
      "last loss =  128738.864724\n",
      "Validation loss: 134044.807601\n",
      "changed index 8119\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 167  ntrees =  9997 \n",
      "best loss =  128734.73471 \n",
      "last loss =  128734.73471\n",
      "Validation loss: 134044.238205\n",
      "changed index 8996\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 168  ntrees =  9997 \n",
      "best loss =  128730.586616 \n",
      "last loss =  128730.586616\n",
      "Validation loss: 134043.940993\n",
      "changed index 5460\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 169  ntrees =  9997 \n",
      "best loss =  128726.507757 \n",
      "last loss =  128726.507757\n",
      "Validation loss: 134043.750454\n",
      "changed index 8377\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 170  ntrees =  9997 \n",
      "best loss =  128722.434286 \n",
      "last loss =  128722.434286\n",
      "Validation loss: 134046.180875\n",
      "changed index 7185\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 171  ntrees =  9997 \n",
      "best loss =  128718.347569 \n",
      "last loss =  128718.347569\n",
      "Validation loss: 134047.220434\n",
      "changed index 5711\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 172  ntrees =  9997 \n",
      "best loss =  128714.251477 \n",
      "last loss =  128714.251477\n",
      "Validation loss: 134045.442515\n",
      "changed index 6799\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 173  ntrees =  9997 \n",
      "best loss =  128710.234661 \n",
      "last loss =  128710.234661\n",
      "Validation loss: 134045.478801\n",
      "changed index 936\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 174  ntrees =  9997 \n",
      "best loss =  128706.121655 \n",
      "last loss =  128706.121655\n",
      "Validation loss: 134045.251832\n",
      "changed index 7827\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 175  ntrees =  9997 \n",
      "best loss =  128702.021363 \n",
      "last loss =  128702.021363\n",
      "Validation loss: 134045.914337\n",
      "changed index 5518\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 176  ntrees =  9997 \n",
      "best loss =  128697.945353 \n",
      "last loss =  128697.945353\n",
      "Validation loss: 134046.014484\n",
      "changed index 9723\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 177  ntrees =  9997 \n",
      "best loss =  128693.912674 \n",
      "last loss =  128693.912674\n",
      "Validation loss: 134049.201834\n",
      "changed index 386\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 178  ntrees =  9997 \n",
      "best loss =  128689.884542 \n",
      "last loss =  128689.884542\n",
      "Validation loss: 134049.20055\n",
      "changed index 3530\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 179  ntrees =  9997 \n",
      "best loss =  128685.834897 \n",
      "last loss =  128685.834897\n",
      "Validation loss: 134049.837608\n",
      "changed index 4467\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 180  ntrees =  9997 \n",
      "best loss =  128681.771919 \n",
      "last loss =  128681.771919\n",
      "Validation loss: 134050.103973\n",
      "changed index 9092\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 181  ntrees =  9997 \n",
      "best loss =  128677.73123 \n",
      "last loss =  128677.73123\n",
      "Validation loss: 134051.269172\n",
      "changed index 1819\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 182  ntrees =  9997 \n",
      "best loss =  128673.688391 \n",
      "last loss =  128673.688391\n",
      "Validation loss: 134051.04467\n",
      "changed index 8126\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 183  ntrees =  9997 \n",
      "best loss =  128669.70971 \n",
      "last loss =  128669.70971\n",
      "Validation loss: 134051.57924\n",
      "changed index 4857\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 184  ntrees =  9997 \n",
      "best loss =  128665.743893 \n",
      "last loss =  128665.743893\n",
      "Validation loss: 134050.049904\n",
      "changed index 9010\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 185  ntrees =  9997 \n",
      "best loss =  128661.754718 \n",
      "last loss =  128661.754718\n",
      "Validation loss: 134050.340277\n",
      "changed index 3730\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 186  ntrees =  9997 \n",
      "best loss =  128657.768836 \n",
      "last loss =  128657.768836\n",
      "Validation loss: 134052.558519\n",
      "changed index 643\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 187  ntrees =  9997 \n",
      "best loss =  128653.815262 \n",
      "last loss =  128653.815262\n",
      "Validation loss: 134054.432731\n",
      "changed index 2554\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 188  ntrees =  9997 \n",
      "best loss =  128649.813351 \n",
      "last loss =  128649.813351\n",
      "Validation loss: 134054.7318\n",
      "changed index 8702\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 189  ntrees =  9997 \n",
      "best loss =  128645.808662 \n",
      "last loss =  128645.808662\n",
      "Validation loss: 134055.399393\n",
      "changed index 4337\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 190  ntrees =  9997 \n",
      "best loss =  128641.881142 \n",
      "last loss =  128641.881142\n",
      "Validation loss: 134056.065974\n",
      "changed index 6814\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 191  ntrees =  9997 \n",
      "best loss =  128637.936219 \n",
      "last loss =  128637.936219\n",
      "Validation loss: 134056.172688\n",
      "changed index 1222\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 192  ntrees =  9997 \n",
      "best loss =  128633.998674 \n",
      "last loss =  128633.998674\n",
      "Validation loss: 134054.326362\n",
      "changed index 161\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 193  ntrees =  9997 \n",
      "best loss =  128630.08139 \n",
      "last loss =  128630.08139\n",
      "Validation loss: 134063.571281\n",
      "changed index 231\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 194  ntrees =  9997 \n",
      "best loss =  128626.145914 \n",
      "last loss =  128626.145914\n",
      "Validation loss: 134063.822251\n",
      "changed index 2637\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 195  ntrees =  9997 \n",
      "best loss =  128622.250275 \n",
      "last loss =  128622.250275\n",
      "Validation loss: 134063.194742\n",
      "changed index 9547\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 196  ntrees =  9997 \n",
      "best loss =  128618.330358 \n",
      "last loss =  128618.330358\n",
      "Validation loss: 134064.088821\n",
      "changed index 4521\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 197  ntrees =  9997 \n",
      "best loss =  128614.413949 \n",
      "last loss =  128614.413949\n",
      "Validation loss: 134063.506857\n",
      "changed index 9431\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 198  ntrees =  9997 \n",
      "best loss =  128610.514559 \n",
      "last loss =  128610.514559\n",
      "Validation loss: 134062.551512\n",
      "changed index 3957\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 199  ntrees =  9997 \n",
      "best loss =  128606.613204 \n",
      "last loss =  128606.613204\n",
      "Validation loss: 134063.713093\n",
      "changed index 659\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 200  ntrees =  9997 \n",
      "best loss =  128602.747619 \n",
      "last loss =  128602.747619\n",
      "Validation loss: 134063.677802\n",
      "changed index 5609\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 201  ntrees =  9997 \n",
      "best loss =  128598.886762 \n",
      "last loss =  128598.886762\n",
      "Validation loss: 134119.620237\n",
      "changed index 31\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 202  ntrees =  9997 \n",
      "best loss =  128595.0302 \n",
      "last loss =  128595.0302\n",
      "Validation loss: 134120.364178\n",
      "changed index 905\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 203  ntrees =  9997 \n",
      "best loss =  128591.188776 \n",
      "last loss =  128591.188776\n",
      "Validation loss: 134121.509177\n",
      "changed index 1463\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 204  ntrees =  9997 \n",
      "best loss =  128587.353713 \n",
      "last loss =  128587.353713\n",
      "Validation loss: 134121.800025\n",
      "changed index 779\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 205  ntrees =  9997 \n",
      "best loss =  128583.505011 \n",
      "last loss =  128583.505011\n",
      "Validation loss: 134123.050165\n",
      "changed index 2107\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 206  ntrees =  9997 \n",
      "best loss =  128579.685699 \n",
      "last loss =  128579.685699\n",
      "Validation loss: 134121.498347\n",
      "changed index 2920\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 207  ntrees =  9997 \n",
      "best loss =  128575.854044 \n",
      "last loss =  128575.854044\n",
      "Validation loss: 134123.562437\n",
      "changed index 6475\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 208  ntrees =  9997 \n",
      "best loss =  128572.044452 \n",
      "last loss =  128572.044452\n",
      "Validation loss: 134123.682796\n",
      "changed index 7258\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 209  ntrees =  9997 \n",
      "best loss =  128568.219827 \n",
      "last loss =  128568.219827\n",
      "Validation loss: 134123.523142\n",
      "changed index 1053\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 210  ntrees =  9997 \n",
      "best loss =  128564.397051 \n",
      "last loss =  128564.397051\n",
      "Validation loss: 134123.071002\n",
      "changed index 6533\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 211  ntrees =  9997 \n",
      "best loss =  128560.611188 \n",
      "last loss =  128560.611188\n",
      "Validation loss: 134124.23016\n",
      "changed index 2906\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 212  ntrees =  9997 \n",
      "best loss =  128556.836856 \n",
      "last loss =  128556.836856\n",
      "Validation loss: 134124.182122\n",
      "changed index 6674\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 213  ntrees =  9997 \n",
      "best loss =  128553.070183 \n",
      "last loss =  128553.070183\n",
      "Validation loss: 134124.719042\n",
      "changed index 1666\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 214  ntrees =  9997 \n",
      "best loss =  128549.304327 \n",
      "last loss =  128549.304327\n",
      "Validation loss: 134126.08397\n",
      "changed index 806\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 215  ntrees =  9997 \n",
      "best loss =  128545.551265 \n",
      "last loss =  128545.551265\n",
      "Validation loss: 134126.460043\n",
      "changed index 3626\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 216  ntrees =  9997 \n",
      "best loss =  128541.783234 \n",
      "last loss =  128541.783234\n",
      "Validation loss: 134129.565834\n",
      "changed index 393\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 217  ntrees =  9997 \n",
      "best loss =  128538.021336 \n",
      "last loss =  128538.021336\n",
      "Validation loss: 134129.03285\n",
      "changed index 2928\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 218  ntrees =  9997 \n",
      "best loss =  128534.221271 \n",
      "last loss =  128534.221271\n",
      "Validation loss: 134130.023636\n",
      "changed index 9126\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 219  ntrees =  9997 \n",
      "best loss =  128530.476985 \n",
      "last loss =  128530.476985\n",
      "Validation loss: 134131.064567\n",
      "changed index 516\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 220  ntrees =  9997 \n",
      "best loss =  128526.751079 \n",
      "last loss =  128526.751079\n",
      "Validation loss: 134131.718202\n",
      "changed index 6742\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 221  ntrees =  9997 \n",
      "best loss =  128523.029047 \n",
      "last loss =  128523.029047\n",
      "Validation loss: 134131.582072\n",
      "changed index 7331\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 222  ntrees =  9997 \n",
      "best loss =  128519.303996 \n",
      "last loss =  128519.303996\n",
      "Validation loss: 134132.529202\n",
      "changed index 967\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 223  ntrees =  9997 \n",
      "best loss =  128515.58121 \n",
      "last loss =  128515.58121\n",
      "Validation loss: 134133.031738\n",
      "changed index 1436\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 224  ntrees =  9997 \n",
      "best loss =  128511.89019 \n",
      "last loss =  128511.89019\n",
      "Validation loss: 134132.801902\n",
      "changed index 2281\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 225  ntrees =  9997 \n",
      "best loss =  128508.173728 \n",
      "last loss =  128508.173728\n",
      "Validation loss: 134131.137494\n",
      "changed index 1399\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 226  ntrees =  9997 \n",
      "best loss =  128504.471201 \n",
      "last loss =  128504.471201\n",
      "Validation loss: 134130.682426\n",
      "changed index 4848\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 227  ntrees =  9997 \n",
      "best loss =  128500.781042 \n",
      "last loss =  128500.781042\n",
      "Validation loss: 134130.844423\n",
      "changed index 2409\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 228  ntrees =  9997 \n",
      "best loss =  128497.064635 \n",
      "last loss =  128497.064635\n",
      "Validation loss: 134131.218588\n",
      "changed index 5817\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 229  ntrees =  9997 \n",
      "best loss =  128493.38251 \n",
      "last loss =  128493.38251\n",
      "Validation loss: 134131.237787\n",
      "changed index 8779\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 230  ntrees =  9997 \n",
      "best loss =  128489.733608 \n",
      "last loss =  128489.733608\n",
      "Validation loss: 134131.182556\n",
      "changed index 8888\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 231  ntrees =  9997 \n",
      "best loss =  128486.056269 \n",
      "last loss =  128486.056269\n",
      "Validation loss: 134132.942094\n",
      "changed index 1978\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 232  ntrees =  9997 \n",
      "best loss =  128482.398291 \n",
      "last loss =  128482.398291\n",
      "Validation loss: 134132.048414\n",
      "changed index 7096\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 233  ntrees =  9997 \n",
      "best loss =  128478.724208 \n",
      "last loss =  128478.724208\n",
      "Validation loss: 134132.125658\n",
      "changed index 2227\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 234  ntrees =  9997 \n",
      "best loss =  128475.059091 \n",
      "last loss =  128475.059091\n",
      "Validation loss: 134143.289113\n",
      "changed index 211\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 235  ntrees =  9997 \n",
      "best loss =  128471.413745 \n",
      "last loss =  128471.413745\n",
      "Validation loss: 134142.996786\n",
      "changed index 4472\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 236  ntrees =  9997 \n",
      "best loss =  128467.785451 \n",
      "last loss =  128467.785451\n",
      "Validation loss: 134212.562781\n",
      "changed index 34\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 237  ntrees =  9997 \n",
      "best loss =  128464.131643 \n",
      "last loss =  128464.131643\n",
      "Validation loss: 134212.231859\n",
      "changed index 4913\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 238  ntrees =  9997 \n",
      "best loss =  128460.505517 \n",
      "last loss =  128460.505517\n",
      "Validation loss: 134212.506663\n",
      "changed index 4639\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 239  ntrees =  9997 \n",
      "best loss =  128456.841707 \n",
      "last loss =  128456.841707\n",
      "Validation loss: 134213.664719\n",
      "changed index 4950\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 240  ntrees =  9997 \n",
      "best loss =  128453.220751 \n",
      "last loss =  128453.220751\n",
      "Validation loss: 134213.40787\n",
      "changed index 6886\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 241  ntrees =  9997 \n",
      "best loss =  128449.594507 \n",
      "last loss =  128449.594507\n",
      "Validation loss: 134213.657977\n",
      "changed index 7310\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 242  ntrees =  9997 \n",
      "best loss =  128445.994291 \n",
      "last loss =  128445.994291\n",
      "Validation loss: 134213.795587\n",
      "changed index 9760\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 243  ntrees =  9997 \n",
      "best loss =  128442.40312 \n",
      "last loss =  128442.40312\n",
      "Validation loss: 134213.89663\n",
      "changed index 5306\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 244  ntrees =  9997 \n",
      "best loss =  128438.823579 \n",
      "last loss =  128438.823579\n",
      "Validation loss: 134216.067681\n",
      "changed index 4451\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 245  ntrees =  9997 \n",
      "best loss =  128435.238743 \n",
      "last loss =  128435.238743\n",
      "Validation loss: 134217.119693\n",
      "changed index 8841\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 246  ntrees =  9997 \n",
      "best loss =  128431.660673 \n",
      "last loss =  128431.660673\n",
      "Validation loss: 134217.335166\n",
      "changed index 4900\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 247  ntrees =  9997 \n",
      "best loss =  128428.096073 \n",
      "last loss =  128428.096073\n",
      "Validation loss: 134219.00705\n",
      "changed index 4173\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 248  ntrees =  9997 \n",
      "best loss =  128424.505437 \n",
      "last loss =  128424.505437\n",
      "Validation loss: 134218.379176\n",
      "changed index 7587\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 249  ntrees =  9997 \n",
      "best loss =  128420.940544 \n",
      "last loss =  128420.940544\n",
      "Validation loss: 134218.470574\n",
      "changed index 9303\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 250  ntrees =  9997 \n",
      "best loss =  128417.356918 \n",
      "last loss =  128417.356918\n",
      "Validation loss: 134217.850423\n",
      "changed index 2649\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 251  ntrees =  9997 \n",
      "best loss =  128413.793303 \n",
      "last loss =  128413.793303\n",
      "Validation loss: 134217.84766\n",
      "changed index 1559\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 252  ntrees =  9997 \n",
      "best loss =  128410.243603 \n",
      "last loss =  128410.243603\n",
      "Validation loss: 134218.052126\n",
      "changed index 1429\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 253  ntrees =  9997 \n",
      "best loss =  128406.708886 \n",
      "last loss =  128406.708886\n",
      "Validation loss: 134220.495104\n",
      "changed index 665\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 254  ntrees =  9997 \n",
      "best loss =  128403.144857 \n",
      "last loss =  128403.144857\n",
      "Validation loss: 134221.21118\n",
      "changed index 2096\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 255  ntrees =  9997 \n",
      "best loss =  128399.593892 \n",
      "last loss =  128399.593892\n",
      "Validation loss: 134222.030402\n",
      "changed index 956\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 256  ntrees =  9997 \n",
      "best loss =  128396.056999 \n",
      "last loss =  128396.056999\n",
      "Validation loss: 134221.686336\n",
      "changed index 8797\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 257  ntrees =  9997 \n",
      "best loss =  128392.515547 \n",
      "last loss =  128392.515547\n",
      "Validation loss: 134222.427449\n",
      "changed index 8759\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 258  ntrees =  9997 \n",
      "best loss =  128388.996704 \n",
      "last loss =  128388.996704\n",
      "Validation loss: 134221.508691\n",
      "changed index 6610\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 259  ntrees =  9997 \n",
      "best loss =  128385.480023 \n",
      "last loss =  128385.480023\n",
      "Validation loss: 134220.706928\n",
      "changed index 5455\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 260  ntrees =  9997 \n",
      "best loss =  128381.967281 \n",
      "last loss =  128381.967281\n",
      "Validation loss: 134220.680989\n",
      "changed index 5444\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 261  ntrees =  9997 \n",
      "best loss =  128378.45527 \n",
      "last loss =  128378.45527\n",
      "Validation loss: 134221.290119\n",
      "changed index 7525\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 262  ntrees =  9997 \n",
      "best loss =  128374.948384 \n",
      "last loss =  128374.948384\n",
      "Validation loss: 134221.288809\n",
      "changed index 9942\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 263  ntrees =  9997 \n",
      "best loss =  128371.452889 \n",
      "last loss =  128371.452889\n",
      "Validation loss: 134220.619652\n",
      "changed index 5137\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 264  ntrees =  9997 \n",
      "best loss =  128367.953159 \n",
      "last loss =  128367.953159\n",
      "Validation loss: 134220.374678\n",
      "changed index 6504\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 265  ntrees =  9997 \n",
      "best loss =  128364.457989 \n",
      "last loss =  128364.457989\n",
      "Validation loss: 134220.715764\n",
      "changed index 4296\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 266  ntrees =  9997 \n",
      "best loss =  128360.970384 \n",
      "last loss =  128360.970384\n",
      "Validation loss: 134222.135197\n",
      "changed index 7648\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 267  ntrees =  9997 \n",
      "best loss =  128357.486796 \n",
      "last loss =  128357.486796\n",
      "Validation loss: 134221.103506\n",
      "changed index 5671\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 268  ntrees =  9997 \n",
      "best loss =  128353.997524 \n",
      "last loss =  128353.997524\n",
      "Validation loss: 134220.982943\n",
      "changed index 9935\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 269  ntrees =  9997 \n",
      "best loss =  128350.508264 \n",
      "last loss =  128350.508264\n",
      "Validation loss: 134220.58833\n",
      "changed index 2765\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 270  ntrees =  9997 \n",
      "best loss =  128347.04421 \n",
      "last loss =  128347.04421\n",
      "Validation loss: 134221.14935\n",
      "changed index 7739\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 271  ntrees =  9997 \n",
      "best loss =  128343.581345 \n",
      "last loss =  128343.581345\n",
      "Validation loss: 134221.304399\n",
      "changed index 6843\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 272  ntrees =  9997 \n",
      "best loss =  128340.100186 \n",
      "last loss =  128340.100186\n",
      "Validation loss: 134222.157326\n",
      "changed index 8554\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 273  ntrees =  9997 \n",
      "best loss =  128336.625666 \n",
      "last loss =  128336.625666\n",
      "Validation loss: 134222.182191\n",
      "changed index 3129\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 274  ntrees =  9997 \n",
      "best loss =  128333.171883 \n",
      "last loss =  128333.171883\n",
      "Validation loss: 134224.073486\n",
      "changed index 1024\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 275  ntrees =  9997 \n",
      "best loss =  128329.72703 \n",
      "last loss =  128329.72703\n",
      "Validation loss: 134223.903213\n",
      "changed index 8432\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 276  ntrees =  9997 \n",
      "best loss =  128326.254003 \n",
      "last loss =  128326.254003\n",
      "Validation loss: 134224.005305\n",
      "changed index 8306\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 277  ntrees =  9997 \n",
      "best loss =  128322.803766 \n",
      "last loss =  128322.803766\n",
      "Validation loss: 134223.397184\n",
      "changed index 4814\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 278  ntrees =  9997 \n",
      "best loss =  128319.35394 \n",
      "last loss =  128319.35394\n",
      "Validation loss: 134220.041237\n",
      "changed index 606\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 279  ntrees =  9997 \n",
      "best loss =  128315.914499 \n",
      "last loss =  128315.914499\n",
      "Validation loss: 134220.075908\n",
      "changed index 9305\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 280  ntrees =  9997 \n",
      "best loss =  128312.477724 \n",
      "last loss =  128312.477724\n",
      "Validation loss: 134219.333245\n",
      "changed index 2521\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 281  ntrees =  9997 \n",
      "best loss =  128309.056183 \n",
      "last loss =  128309.056183\n",
      "Validation loss: 134219.254842\n",
      "changed index 2056\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 282  ntrees =  9997 \n",
      "best loss =  128305.637375 \n",
      "last loss =  128305.637375\n",
      "Validation loss: 134220.083881\n",
      "changed index 932\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 283  ntrees =  9997 \n",
      "best loss =  128302.232048 \n",
      "last loss =  128302.232048\n",
      "Validation loss: 134219.097628\n",
      "changed index 3134\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 284  ntrees =  9997 \n",
      "best loss =  128298.798429 \n",
      "last loss =  128298.798429\n",
      "Validation loss: 134218.458044\n",
      "changed index 7851\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 285  ntrees =  9997 \n",
      "best loss =  128295.399999 \n",
      "last loss =  128295.399999\n",
      "Validation loss: 134218.610158\n",
      "changed index 5275\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 286  ntrees =  9997 \n",
      "best loss =  128291.972455 \n",
      "last loss =  128291.972455\n",
      "Validation loss: 134221.953488\n",
      "changed index 365\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 287  ntrees =  9997 \n",
      "best loss =  128288.571372 \n",
      "last loss =  128288.571372\n",
      "Validation loss: 134221.74097\n",
      "changed index 1346\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 288  ntrees =  9997 \n",
      "best loss =  128285.158318 \n",
      "last loss =  128285.158318\n",
      "Validation loss: 134220.891164\n",
      "changed index 503\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 289  ntrees =  9997 \n",
      "best loss =  128281.759852 \n",
      "last loss =  128281.759852\n",
      "Validation loss: 134223.098291\n",
      "changed index 5223\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 290  ntrees =  9997 \n",
      "best loss =  128278.357786 \n",
      "last loss =  128278.357786\n",
      "Validation loss: 134224.504185\n",
      "changed index 2372\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 291  ntrees =  9997 \n",
      "best loss =  128274.959198 \n",
      "last loss =  128274.959198\n",
      "Validation loss: 134229.993551\n",
      "changed index 328\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 292  ntrees =  9997 \n",
      "best loss =  128271.574373 \n",
      "last loss =  128271.574373\n",
      "Validation loss: 134230.343385\n",
      "changed index 2953\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 293  ntrees =  9997 \n",
      "best loss =  128268.188207 \n",
      "last loss =  128268.188207\n",
      "Validation loss: 134228.957534\n",
      "changed index 7363\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 294  ntrees =  9997 \n",
      "best loss =  128264.811594 \n",
      "last loss =  128264.811594\n",
      "Validation loss: 134230.950269\n",
      "changed index 742\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 295  ntrees =  9997 \n",
      "best loss =  128261.43891 \n",
      "last loss =  128261.43891\n",
      "Validation loss: 134231.319558\n",
      "changed index 5683\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 296  ntrees =  9997 \n",
      "best loss =  128258.073311 \n",
      "last loss =  128258.073311\n",
      "Validation loss: 134237.503893\n",
      "changed index 378\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 297  ntrees =  9997 \n",
      "best loss =  128254.712266 \n",
      "last loss =  128254.712266\n",
      "Validation loss: 134253.406387\n",
      "changed index 217\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 298  ntrees =  9997 \n",
      "best loss =  128251.360383 \n",
      "last loss =  128251.360383\n",
      "Validation loss: 134253.410612\n",
      "changed index 2448\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 299  ntrees =  9997 \n",
      "best loss =  128247.996696 \n",
      "last loss =  128247.996696\n",
      "Validation loss: 134253.378057\n",
      "changed index 7669\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 300  ntrees =  9997 \n",
      "best loss =  128244.640906 \n",
      "last loss =  128244.640906\n",
      "Validation loss: 134253.159172\n",
      "changed index 7945\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 301  ntrees =  9997 \n",
      "best loss =  128241.270815 \n",
      "last loss =  128241.270815\n",
      "Validation loss: 134252.52804\n",
      "changed index 6870\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 302  ntrees =  9997 \n",
      "best loss =  128237.909348 \n",
      "last loss =  128237.909348\n",
      "Validation loss: 134252.9588\n",
      "changed index 3066\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 303  ntrees =  9997 \n",
      "best loss =  128234.557228 \n",
      "last loss =  128234.557228\n",
      "Validation loss: 134252.799859\n",
      "changed index 5654\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 304  ntrees =  9997 \n",
      "best loss =  128231.227158 \n",
      "last loss =  128231.227158\n",
      "Validation loss: 134253.058427\n",
      "changed index 1381\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 305  ntrees =  9997 \n",
      "best loss =  128227.898554 \n",
      "last loss =  128227.898554\n",
      "Validation loss: 134252.48684\n",
      "changed index 6039\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 306  ntrees =  9997 \n",
      "best loss =  128224.559331 \n",
      "last loss =  128224.559331\n",
      "Validation loss: 134253.018778\n",
      "changed index 5017\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 307  ntrees =  9997 \n",
      "best loss =  128221.23495 \n",
      "last loss =  128221.23495\n",
      "Validation loss: 134253.663149\n",
      "changed index 886\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 308  ntrees =  9997 \n",
      "best loss =  128217.916663 \n",
      "last loss =  128217.916663\n",
      "Validation loss: 134254.102247\n",
      "changed index 6578\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 309  ntrees =  9997 \n",
      "best loss =  128214.583951 \n",
      "last loss =  128214.583951\n",
      "Validation loss: 134254.678491\n",
      "changed index 505\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 310  ntrees =  9997 \n",
      "best loss =  128211.268381 \n",
      "last loss =  128211.268381\n",
      "Validation loss: 134254.763862\n",
      "changed index 9792\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 311  ntrees =  9997 \n",
      "best loss =  128207.953808 \n",
      "last loss =  128207.953808\n",
      "Validation loss: 134254.610278\n",
      "changed index 6457\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 312  ntrees =  9997 \n",
      "best loss =  128204.642214 \n",
      "last loss =  128204.642214\n",
      "Validation loss: 134254.537373\n",
      "changed index 2296\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 313  ntrees =  9997 \n",
      "best loss =  128201.318957 \n",
      "last loss =  128201.318957\n",
      "Validation loss: 134254.372245\n",
      "changed index 2978\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 314  ntrees =  9997 \n",
      "best loss =  128197.99445 \n",
      "last loss =  128197.99445\n",
      "Validation loss: 134253.848526\n",
      "changed index 5206\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 315  ntrees =  9997 \n",
      "best loss =  128194.69165 \n",
      "last loss =  128194.69165\n",
      "Validation loss: 134253.465628\n",
      "changed index 5394\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 316  ntrees =  9997 \n",
      "best loss =  128191.396142 \n",
      "last loss =  128191.396142\n",
      "Validation loss: 134254.075542\n",
      "changed index 5568\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 317  ntrees =  9997 \n",
      "best loss =  128188.096215 \n",
      "last loss =  128188.096215\n",
      "Validation loss: 134253.984942\n",
      "changed index 4825\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 318  ntrees =  9997 \n",
      "best loss =  128184.800315 \n",
      "last loss =  128184.800315\n",
      "Validation loss: 134253.773908\n",
      "changed index 9540\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 319  ntrees =  9997 \n",
      "best loss =  128181.500899 \n",
      "last loss =  128181.500899\n",
      "Validation loss: 134254.485631\n",
      "changed index 5521\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 320  ntrees =  9997 \n",
      "best loss =  128178.208994 \n",
      "last loss =  128178.208994\n",
      "Validation loss: 134255.669872\n",
      "changed index 658\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 321  ntrees =  9997 \n",
      "best loss =  128174.92139 \n",
      "last loss =  128174.92139\n",
      "Validation loss: 134361.390573\n",
      "changed index 10\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 322  ntrees =  9997 \n",
      "best loss =  128171.636549 \n",
      "last loss =  128171.636549\n",
      "Validation loss: 134359.559795\n",
      "changed index 7337\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 323  ntrees =  9997 \n",
      "best loss =  128168.354531 \n",
      "last loss =  128168.354531\n",
      "Validation loss: 134360.111541\n",
      "changed index 4268\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 324  ntrees =  9997 \n",
      "best loss =  128165.077928 \n",
      "last loss =  128165.077928\n",
      "Validation loss: 134361.688777\n",
      "changed index 5982\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 325  ntrees =  9997 \n",
      "best loss =  128161.808867 \n",
      "last loss =  128161.808867\n",
      "Validation loss: 134362.364769\n",
      "changed index 6493\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 326  ntrees =  9997 \n",
      "best loss =  128158.526736 \n",
      "last loss =  128158.526736\n",
      "Validation loss: 134361.764476\n",
      "changed index 9768\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 327  ntrees =  9997 \n",
      "best loss =  128155.257428 \n",
      "last loss =  128155.257428\n",
      "Validation loss: 134361.829199\n",
      "changed index 9914\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 328  ntrees =  9997 \n",
      "best loss =  128151.990208 \n",
      "last loss =  128151.990208\n",
      "Validation loss: 134361.62084\n",
      "changed index 9971\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 329  ntrees =  9997 \n",
      "best loss =  128148.728608 \n",
      "last loss =  128148.728608\n",
      "Validation loss: 134361.118038\n",
      "changed index 5221\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 330  ntrees =  9997 \n",
      "best loss =  128145.471176 \n",
      "last loss =  128145.471176\n",
      "Validation loss: 134360.036252\n",
      "changed index 4760\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 331  ntrees =  9997 \n",
      "best loss =  128142.215047 \n",
      "last loss =  128142.215047\n",
      "Validation loss: 134359.704887\n",
      "changed index 1658\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 332  ntrees =  9997 \n",
      "best loss =  128138.948411 \n",
      "last loss =  128138.948411\n",
      "Validation loss: 134359.863727\n",
      "changed index 6115\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 333  ntrees =  9997 \n",
      "best loss =  128135.698807 \n",
      "last loss =  128135.698807\n",
      "Validation loss: 134359.746145\n",
      "changed index 4999\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 334  ntrees =  9997 \n",
      "best loss =  128132.458017 \n",
      "last loss =  128132.458017\n",
      "Validation loss: 134359.757123\n",
      "changed index 3645\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 335  ntrees =  9997 \n",
      "best loss =  128129.213787 \n",
      "last loss =  128129.213787\n",
      "Validation loss: 134359.736392\n",
      "changed index 1384\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 336  ntrees =  9997 \n",
      "best loss =  128125.977847 \n",
      "last loss =  128125.977847\n",
      "Validation loss: 134384.262717\n",
      "changed index 189\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 337  ntrees =  9997 \n",
      "best loss =  128122.733117 \n",
      "last loss =  128122.733117\n",
      "Validation loss: 134383.877524\n",
      "changed index 2869\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 338  ntrees =  9997 \n",
      "best loss =  128119.493432 \n",
      "last loss =  128119.493432\n",
      "Validation loss: 134387.017006\n",
      "changed index 2518\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 339  ntrees =  9997 \n",
      "best loss =  128116.25875 \n",
      "last loss =  128116.25875\n",
      "Validation loss: 134388.374599\n",
      "changed index 7207\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 340  ntrees =  9997 \n",
      "best loss =  128113.020184 \n",
      "last loss =  128113.020184\n",
      "Validation loss: 134388.671263\n",
      "changed index 6381\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 341  ntrees =  9997 \n",
      "best loss =  128109.785569 \n",
      "last loss =  128109.785569\n",
      "Validation loss: 134387.93626\n",
      "changed index 3801\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 342  ntrees =  9997 \n",
      "best loss =  128106.563948 \n",
      "last loss =  128106.563948\n",
      "Validation loss: 134388.058054\n",
      "changed index 7182\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 343  ntrees =  9997 \n",
      "best loss =  128103.330348 \n",
      "last loss =  128103.330348\n",
      "Validation loss: 134389.542966\n",
      "changed index 3915\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 344  ntrees =  9997 \n",
      "best loss =  128100.105893 \n",
      "last loss =  128100.105893\n",
      "Validation loss: 134388.864662\n",
      "changed index 9656\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 345  ntrees =  9997 \n",
      "best loss =  128096.885002 \n",
      "last loss =  128096.885002\n",
      "Validation loss: 134387.802994\n",
      "changed index 1821\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 346  ntrees =  9997 \n",
      "best loss =  128093.661622 \n",
      "last loss =  128093.661622\n",
      "Validation loss: 134387.697991\n",
      "changed index 8437\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 347  ntrees =  9997 \n",
      "best loss =  128090.443472 \n",
      "last loss =  128090.443472\n",
      "Validation loss: 134387.261928\n",
      "changed index 9188\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 348  ntrees =  9997 \n",
      "best loss =  128087.229896 \n",
      "last loss =  128087.229896\n",
      "Validation loss: 134387.666957\n",
      "changed index 4979\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 349  ntrees =  9997 \n",
      "best loss =  128084.019526 \n",
      "last loss =  128084.019526\n",
      "Validation loss: 134388.053934\n",
      "changed index 7483\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 350  ntrees =  9997 \n",
      "best loss =  128080.802854 \n",
      "last loss =  128080.802854\n",
      "Validation loss: 134409.267283\n",
      "changed index 207\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 351  ntrees =  9997 \n",
      "best loss =  128077.595203 \n",
      "last loss =  128077.595203\n",
      "Validation loss: 134410.027593\n",
      "changed index 8717\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 352  ntrees =  9997 \n",
      "best loss =  128074.387907 \n",
      "last loss =  128074.387907\n",
      "Validation loss: 134409.374162\n",
      "changed index 9569\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 353  ntrees =  9997 \n",
      "best loss =  128071.188371 \n",
      "last loss =  128071.188371\n",
      "Validation loss: 134410.427058\n",
      "changed index 1203\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 354  ntrees =  9997 \n",
      "best loss =  128067.995198 \n",
      "last loss =  128067.995198\n",
      "Validation loss: 134410.067979\n",
      "changed index 3260\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 355  ntrees =  9997 \n",
      "best loss =  128064.807993 \n",
      "last loss =  128064.807993\n",
      "Validation loss: 134410.061358\n",
      "changed index 3339\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 356  ntrees =  9997 \n",
      "best loss =  128061.615198 \n",
      "last loss =  128061.615198\n",
      "Validation loss: 134409.534124\n",
      "changed index 3351\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 357  ntrees =  9997 \n",
      "best loss =  128058.425865 \n",
      "last loss =  128058.425865\n",
      "Validation loss: 134409.43916\n",
      "changed index 6161\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 358  ntrees =  9997 \n",
      "best loss =  128055.234487 \n",
      "last loss =  128055.234487\n",
      "Validation loss: 134409.052796\n",
      "changed index 9361\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 359  ntrees =  9997 \n",
      "best loss =  128052.059672 \n",
      "last loss =  128052.059672\n",
      "Validation loss: 134407.837393\n",
      "changed index 7311\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 360  ntrees =  9997 \n",
      "best loss =  128048.880421 \n",
      "last loss =  128048.880421\n",
      "Validation loss: 134407.123826\n",
      "changed index 1047\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 361  ntrees =  9997 \n",
      "best loss =  128045.712705 \n",
      "last loss =  128045.712705\n",
      "Validation loss: 134406.491443\n",
      "changed index 5141\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 362  ntrees =  9997 \n",
      "best loss =  128042.531145 \n",
      "last loss =  128042.531145\n",
      "Validation loss: 134406.394381\n",
      "changed index 4976\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 363  ntrees =  9997 \n",
      "best loss =  128039.368265 \n",
      "last loss =  128039.368265\n",
      "Validation loss: 134406.259066\n",
      "changed index 3178\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 364  ntrees =  9997 \n",
      "best loss =  128036.199494 \n",
      "last loss =  128036.199494\n",
      "Validation loss: 134406.103594\n",
      "changed index 3801\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 365  ntrees =  9997 \n",
      "best loss =  128033.039321 \n",
      "last loss =  128033.039321\n",
      "Validation loss: 134406.652681\n",
      "changed index 589\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 366  ntrees =  9997 \n",
      "best loss =  128029.875488 \n",
      "last loss =  128029.875488\n",
      "Validation loss: 134406.743232\n",
      "changed index 2265\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 367  ntrees =  9997 \n",
      "best loss =  128026.713757 \n",
      "last loss =  128026.713757\n",
      "Validation loss: 134406.721335\n",
      "changed index 9371\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 368  ntrees =  9997 \n",
      "best loss =  128023.56051 \n",
      "last loss =  128023.56051\n",
      "Validation loss: 134407.555072\n",
      "changed index 5547\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 369  ntrees =  9997 \n",
      "best loss =  128020.402714 \n",
      "last loss =  128020.402714\n",
      "Validation loss: 134407.848715\n",
      "changed index 3120\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 370  ntrees =  9997 \n",
      "best loss =  128017.247832 \n",
      "last loss =  128017.247832\n",
      "Validation loss: 134407.585258\n",
      "changed index 5952\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 371  ntrees =  9997 \n",
      "best loss =  128014.093684 \n",
      "last loss =  128014.093684\n",
      "Validation loss: 134407.433814\n",
      "changed index 2402\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 372  ntrees =  9997 \n",
      "best loss =  128010.962469 \n",
      "last loss =  128010.962469\n",
      "Validation loss: 134409.504296\n",
      "changed index 996\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 373  ntrees =  9997 \n",
      "best loss =  128007.806998 \n",
      "last loss =  128007.806998\n",
      "Validation loss: 134495.680122\n",
      "changed index 58\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 374  ntrees =  9997 \n",
      "best loss =  128004.671231 \n",
      "last loss =  128004.671231\n",
      "Validation loss: 134495.797411\n",
      "changed index 7862\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 375  ntrees =  9997 \n",
      "best loss =  128001.532903 \n",
      "last loss =  128001.532903\n",
      "Validation loss: 134495.785364\n",
      "changed index 3254\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 376  ntrees =  9997 \n",
      "best loss =  127998.395202 \n",
      "last loss =  127998.395202\n",
      "Validation loss: 134496.127942\n",
      "changed index 7119\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 377  ntrees =  9997 \n",
      "best loss =  127995.25995 \n",
      "last loss =  127995.25995\n",
      "Validation loss: 134496.478\n",
      "changed index 1041\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 378  ntrees =  9997 \n",
      "best loss =  127992.129278 \n",
      "last loss =  127992.129278\n",
      "Validation loss: 134496.486133\n",
      "changed index 6715\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 379  ntrees =  9997 \n",
      "best loss =  127988.998015 \n",
      "last loss =  127988.998015\n",
      "Validation loss: 134498.130354\n",
      "changed index 546\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 380  ntrees =  9997 \n",
      "best loss =  127985.87045 \n",
      "last loss =  127985.87045\n",
      "Validation loss: 134497.189528\n",
      "changed index 2004\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 381  ntrees =  9997 \n",
      "best loss =  127982.751264 \n",
      "last loss =  127982.751264\n",
      "Validation loss: 134497.912787\n",
      "changed index 3284\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 382  ntrees =  9997 \n",
      "best loss =  127979.624023 \n",
      "last loss =  127979.624023\n",
      "Validation loss: 134497.53999\n",
      "changed index 5174\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 383  ntrees =  9997 \n",
      "best loss =  127976.501332 \n",
      "last loss =  127976.501332\n",
      "Validation loss: 134496.96285\n",
      "changed index 1079\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 384  ntrees =  9997 \n",
      "best loss =  127973.381902 \n",
      "last loss =  127973.381902\n",
      "Validation loss: 134497.134296\n",
      "changed index 2536\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 385  ntrees =  9997 \n",
      "best loss =  127970.263035 \n",
      "last loss =  127970.263035\n",
      "Validation loss: 134497.397114\n",
      "changed index 9849\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 386  ntrees =  9997 \n",
      "best loss =  127967.148685 \n",
      "last loss =  127967.148685\n",
      "Validation loss: 134498.243033\n",
      "changed index 9432\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 387  ntrees =  9997 \n",
      "best loss =  127964.032744 \n",
      "last loss =  127964.032744\n",
      "Validation loss: 134498.009072\n",
      "changed index 1376\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 388  ntrees =  9997 \n",
      "best loss =  127960.925144 \n",
      "last loss =  127960.925144\n",
      "Validation loss: 134498.221329\n",
      "changed index 8868\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 389  ntrees =  9997 \n",
      "best loss =  127957.811988 \n",
      "last loss =  127957.811988\n",
      "Validation loss: 134499.008733\n",
      "changed index 881\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 390  ntrees =  9997 \n",
      "best loss =  127954.708279 \n",
      "last loss =  127954.708279\n",
      "Validation loss: 134499.146577\n",
      "changed index 6095\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 391  ntrees =  9997 \n",
      "best loss =  127951.609644 \n",
      "last loss =  127951.609644\n",
      "Validation loss: 134500.977435\n",
      "changed index 8891\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 392  ntrees =  9997 \n",
      "best loss =  127948.516226 \n",
      "last loss =  127948.516226\n",
      "Validation loss: 134502.216667\n",
      "changed index 1190\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 393  ntrees =  9997 \n",
      "best loss =  127945.417704 \n",
      "last loss =  127945.417704\n",
      "Validation loss: 134502.397784\n",
      "changed index 9572\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 394  ntrees =  9997 \n",
      "best loss =  127942.332276 \n",
      "last loss =  127942.332276\n",
      "Validation loss: 134500.750398\n",
      "changed index 9549\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 395  ntrees =  9997 \n",
      "best loss =  127939.231639 \n",
      "last loss =  127939.231639\n",
      "Validation loss: 134502.172466\n",
      "changed index 5161\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 396  ntrees =  9997 \n",
      "best loss =  127936.147745 \n",
      "last loss =  127936.147745\n",
      "Validation loss: 134501.366329\n",
      "changed index 601\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 397  ntrees =  9997 \n",
      "best loss =  127933.063036 \n",
      "last loss =  127933.063036\n",
      "Validation loss: 134501.649152\n",
      "changed index 4029\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 398  ntrees =  9997 \n",
      "best loss =  127929.98441 \n",
      "last loss =  127929.98441\n",
      "Validation loss: 134501.190093\n",
      "changed index 9366\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 399  ntrees =  9997 \n",
      "best loss =  127926.894095 \n",
      "last loss =  127926.894095\n",
      "Validation loss: 134498.890568\n",
      "changed index 5164\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 400  ntrees =  9997 \n",
      "best loss =  127923.82116 \n",
      "last loss =  127923.82116\n",
      "Validation loss: 134499.549856\n",
      "changed index 4720\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 401  ntrees =  9997 \n",
      "best loss =  127920.749905 \n",
      "last loss =  127920.749905\n",
      "Validation loss: 134499.328001\n",
      "changed index 6721\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 402  ntrees =  9997 \n",
      "best loss =  127917.679762 \n",
      "last loss =  127917.679762\n",
      "Validation loss: 134499.35832\n",
      "changed index 6101\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 403  ntrees =  9997 \n",
      "best loss =  127914.612532 \n",
      "last loss =  127914.612532\n",
      "Validation loss: 134498.584021\n",
      "changed index 2949\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 404  ntrees =  9997 \n",
      "best loss =  127911.535653 \n",
      "last loss =  127911.535653\n",
      "Validation loss: 134503.946656\n",
      "changed index 407\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 405  ntrees =  9997 \n",
      "best loss =  127908.471095 \n",
      "last loss =  127908.471095\n",
      "Validation loss: 134503.966595\n",
      "changed index 9443\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 406  ntrees =  9997 \n",
      "best loss =  127905.40777 \n",
      "last loss =  127905.40777\n",
      "Validation loss: 134504.01939\n",
      "changed index 2528\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 407  ntrees =  9997 \n",
      "best loss =  127902.342237 \n",
      "last loss =  127902.342237\n",
      "Validation loss: 134504.272656\n",
      "changed index 2318\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 408  ntrees =  9997 \n",
      "best loss =  127899.279387 \n",
      "last loss =  127899.279387\n",
      "Validation loss: 134503.671803\n",
      "changed index 7037\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 409  ntrees =  9997 \n",
      "best loss =  127896.221619 \n",
      "last loss =  127896.221619\n",
      "Validation loss: 134504.561303\n",
      "changed index 3489\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 410  ntrees =  9997 \n",
      "best loss =  127893.162747 \n",
      "last loss =  127893.162747\n",
      "Validation loss: 134504.543357\n",
      "changed index 6731\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 411  ntrees =  9997 \n",
      "best loss =  127890.108485 \n",
      "last loss =  127890.108485\n",
      "Validation loss: 134504.904726\n",
      "changed index 4547\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 412  ntrees =  9997 \n",
      "best loss =  127887.06059 \n",
      "last loss =  127887.06059\n",
      "Validation loss: 134504.860438\n",
      "changed index 6104\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 413  ntrees =  9997 \n",
      "best loss =  127884.003158 \n",
      "last loss =  127884.003158\n",
      "Validation loss: 134506.289329\n",
      "changed index 2570\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 414  ntrees =  9997 \n",
      "best loss =  127880.954259 \n",
      "last loss =  127880.954259\n",
      "Validation loss: 134506.327559\n",
      "changed index 3442\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 415  ntrees =  9997 \n",
      "best loss =  127877.906514 \n",
      "last loss =  127877.906514\n",
      "Validation loss: 134505.12103\n",
      "changed index 3406\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 416  ntrees =  9997 \n",
      "best loss =  127874.859295 \n",
      "last loss =  127874.859295\n",
      "Validation loss: 134504.734886\n",
      "changed index 9636\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 417  ntrees =  9997 \n",
      "best loss =  127871.813644 \n",
      "last loss =  127871.813644\n",
      "Validation loss: 134503.740265\n",
      "changed index 7199\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 418  ntrees =  9997 \n",
      "best loss =  127868.773613 \n",
      "last loss =  127868.773613\n",
      "Validation loss: 134503.947142\n",
      "changed index 5174\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 419  ntrees =  9997 \n",
      "best loss =  127865.739113 \n",
      "last loss =  127865.739113\n",
      "Validation loss: 134504.024859\n",
      "changed index 4254\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 420  ntrees =  9997 \n",
      "best loss =  127862.706052 \n",
      "last loss =  127862.706052\n",
      "Validation loss: 134504.499961\n",
      "changed index 4597\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 421  ntrees =  9997 \n",
      "best loss =  127859.667138 \n",
      "last loss =  127859.667138\n",
      "Validation loss: 134506.981993\n",
      "changed index 757\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 422  ntrees =  9997 \n",
      "best loss =  127856.636737 \n",
      "last loss =  127856.636737\n",
      "Validation loss: 134505.773108\n",
      "changed index 3842\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 423  ntrees =  9997 \n",
      "best loss =  127853.611212 \n",
      "last loss =  127853.611212\n",
      "Validation loss: 134506.170745\n",
      "changed index 9080\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 424  ntrees =  9997 \n",
      "best loss =  127850.591159 \n",
      "last loss =  127850.591159\n",
      "Validation loss: 134506.1722\n",
      "changed index 5672\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 425  ntrees =  9997 \n",
      "best loss =  127847.56649 \n",
      "last loss =  127847.56649\n",
      "Validation loss: 134505.773565\n",
      "changed index 4375\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 426  ntrees =  9997 \n",
      "best loss =  127844.557488 \n",
      "last loss =  127844.557488\n",
      "Validation loss: 134507.052726\n",
      "changed index 6711\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 427  ntrees =  9997 \n",
      "best loss =  127841.552591 \n",
      "last loss =  127841.552591\n",
      "Validation loss: 134506.813617\n",
      "changed index 9608\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 428  ntrees =  9997 \n",
      "best loss =  127838.53837 \n",
      "last loss =  127838.53837\n",
      "Validation loss: 134507.604506\n",
      "changed index 7937\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 429  ntrees =  9997 \n",
      "best loss =  127835.527746 \n",
      "last loss =  127835.527746\n",
      "Validation loss: 134507.436508\n",
      "changed index 7800\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 430  ntrees =  9997 \n",
      "best loss =  127832.519091 \n",
      "last loss =  127832.519091\n",
      "Validation loss: 134508.567477\n",
      "changed index 694\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 431  ntrees =  9997 \n",
      "best loss =  127829.506663 \n",
      "last loss =  127829.506663\n",
      "Validation loss: 134509.089668\n",
      "changed index 5576\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 432  ntrees =  9997 \n",
      "best loss =  127826.499523 \n",
      "last loss =  127826.499523\n",
      "Validation loss: 134508.560505\n",
      "changed index 9739\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 433  ntrees =  9997 \n",
      "best loss =  127823.497085 \n",
      "last loss =  127823.497085\n",
      "Validation loss: 134509.736176\n",
      "changed index 5702\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 434  ntrees =  9997 \n",
      "best loss =  127820.495665 \n",
      "last loss =  127820.495665\n",
      "Validation loss: 134508.579383\n",
      "changed index 9025\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 435  ntrees =  9997 \n",
      "best loss =  127817.495365 \n",
      "last loss =  127817.495365\n",
      "Validation loss: 134508.732033\n",
      "changed index 2081\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 436  ntrees =  9997 \n",
      "best loss =  127814.495641 \n",
      "last loss =  127814.495641\n",
      "Validation loss: 134508.716026\n",
      "changed index 4884\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 437  ntrees =  9997 \n",
      "best loss =  127811.499062 \n",
      "last loss =  127811.499062\n",
      "Validation loss: 134508.76848\n",
      "changed index 6940\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 438  ntrees =  9997 \n",
      "best loss =  127808.505893 \n",
      "last loss =  127808.505893\n",
      "Validation loss: 134508.6996\n",
      "changed index 9559\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 439  ntrees =  9997 \n",
      "best loss =  127805.515512 \n",
      "last loss =  127805.515512\n",
      "Validation loss: 134509.015748\n",
      "changed index 2763\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 440  ntrees =  9997 \n",
      "best loss =  127802.538794 \n",
      "last loss =  127802.538794\n",
      "Validation loss: 134509.943715\n",
      "changed index 3343\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 441  ntrees =  9997 \n",
      "best loss =  127799.548243 \n",
      "last loss =  127799.548243\n",
      "Validation loss: 134510.272829\n",
      "changed index 4698\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 442  ntrees =  9997 \n",
      "best loss =  127796.565675 \n",
      "last loss =  127796.565675\n",
      "Validation loss: 134516.017062\n",
      "changed index 401\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 443  ntrees =  9997 \n",
      "best loss =  127793.572474 \n",
      "last loss =  127793.572474\n",
      "Validation loss: 134516.218161\n",
      "changed index 3549\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 444  ntrees =  9997 \n",
      "best loss =  127790.589596 \n",
      "last loss =  127790.589596\n",
      "Validation loss: 134516.469531\n",
      "changed index 3065\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 445  ntrees =  9997 \n",
      "best loss =  127787.610041 \n",
      "last loss =  127787.610041\n",
      "Validation loss: 134516.472607\n",
      "changed index 6145\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 446  ntrees =  9997 \n",
      "best loss =  127784.640748 \n",
      "last loss =  127784.640748\n",
      "Validation loss: 134517.064031\n",
      "changed index 692\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 447  ntrees =  9997 \n",
      "best loss =  127781.670986 \n",
      "last loss =  127781.670986\n",
      "Validation loss: 134516.531847\n",
      "changed index 2172\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 448  ntrees =  9997 \n",
      "best loss =  127778.694712 \n",
      "last loss =  127778.694712\n",
      "Validation loss: 134516.02287\n",
      "changed index 3677\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 449  ntrees =  9997 \n",
      "best loss =  127775.72728 \n",
      "last loss =  127775.72728\n",
      "Validation loss: 134516.482695\n",
      "changed index 4934\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 450  ntrees =  9997 \n",
      "best loss =  127772.758995 \n",
      "last loss =  127772.758995\n",
      "Validation loss: 134518.332937\n",
      "changed index 674\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 451  ntrees =  9997 \n",
      "best loss =  127769.802174 \n",
      "last loss =  127769.802174\n",
      "Validation loss: 134519.388576\n",
      "changed index 5886\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 452  ntrees =  9997 \n",
      "best loss =  127766.83804 \n",
      "last loss =  127766.83804\n",
      "Validation loss: 134519.247542\n",
      "changed index 6248\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 453  ntrees =  9997 \n",
      "best loss =  127763.871224 \n",
      "last loss =  127763.871224\n",
      "Validation loss: 134518.626159\n",
      "changed index 2540\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 454  ntrees =  9997 \n",
      "best loss =  127760.911369 \n",
      "last loss =  127760.911369\n",
      "Validation loss: 134517.539288\n",
      "changed index 8175\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 455  ntrees =  9997 \n",
      "best loss =  127757.954232 \n",
      "last loss =  127757.954232\n",
      "Validation loss: 134516.557096\n",
      "changed index 9402\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 456  ntrees =  9997 \n",
      "best loss =  127754.995334 \n",
      "last loss =  127754.995334\n",
      "Validation loss: 134515.836991\n",
      "changed index 5426\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 457  ntrees =  9997 \n",
      "best loss =  127752.037378 \n",
      "last loss =  127752.037378\n",
      "Validation loss: 134517.80113\n",
      "changed index 548\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 458  ntrees =  9997 \n",
      "best loss =  127749.083982 \n",
      "last loss =  127749.083982\n",
      "Validation loss: 134517.182212\n",
      "changed index 4126\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 459  ntrees =  9997 \n",
      "best loss =  127746.130797 \n",
      "last loss =  127746.130797\n",
      "Validation loss: 134519.488534\n",
      "changed index 8800\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 460  ntrees =  9997 \n",
      "best loss =  127743.182363 \n",
      "last loss =  127743.182363\n",
      "Validation loss: 134642.531193\n",
      "changed index 29\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 461  ntrees =  9997 \n",
      "best loss =  127740.238839 \n",
      "last loss =  127740.238839\n",
      "Validation loss: 134641.944053\n",
      "changed index 3103\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 462  ntrees =  9997 \n",
      "best loss =  127737.288735 \n",
      "last loss =  127737.288735\n",
      "Validation loss: 134643.091485\n",
      "changed index 6759\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 463  ntrees =  9997 \n",
      "best loss =  127734.34302 \n",
      "last loss =  127734.34302\n",
      "Validation loss: 134642.78252\n",
      "changed index 2477\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 464  ntrees =  9997 \n",
      "best loss =  127731.404127 \n",
      "last loss =  127731.404127\n",
      "Validation loss: 134643.200544\n",
      "changed index 3878\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 465  ntrees =  9997 \n",
      "best loss =  127728.467586 \n",
      "last loss =  127728.467586\n",
      "Validation loss: 134643.659653\n",
      "changed index 4092\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 466  ntrees =  9997 \n",
      "best loss =  127725.535141 \n",
      "last loss =  127725.535141\n",
      "Validation loss: 134643.284152\n",
      "changed index 5135\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 467  ntrees =  9997 \n",
      "best loss =  127722.59949 \n",
      "last loss =  127722.59949\n",
      "Validation loss: 134643.021408\n",
      "changed index 5482\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 468  ntrees =  9997 \n",
      "best loss =  127719.674201 \n",
      "last loss =  127719.674201\n",
      "Validation loss: 134642.022608\n",
      "changed index 6934\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 469  ntrees =  9997 \n",
      "best loss =  127716.74327 \n",
      "last loss =  127716.74327\n",
      "Validation loss: 134640.25302\n",
      "changed index 1143\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 470  ntrees =  9997 \n",
      "best loss =  127713.814503 \n",
      "last loss =  127713.814503\n",
      "Validation loss: 134639.991124\n",
      "changed index 4191\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 471  ntrees =  9997 \n",
      "best loss =  127710.894273 \n",
      "last loss =  127710.894273\n",
      "Validation loss: 134641.009414\n",
      "changed index 4796\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 472  ntrees =  9997 \n",
      "best loss =  127707.965723 \n",
      "last loss =  127707.965723\n",
      "Validation loss: 134641.102957\n",
      "changed index 8284\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 473  ntrees =  9997 \n",
      "best loss =  127705.048081 \n",
      "last loss =  127705.048081\n",
      "Validation loss: 134641.927705\n",
      "changed index 5740\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 474  ntrees =  9997 \n",
      "best loss =  127702.13136 \n",
      "last loss =  127702.13136\n",
      "Validation loss: 134641.452762\n",
      "changed index 4050\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 475  ntrees =  9997 \n",
      "best loss =  127699.212672 \n",
      "last loss =  127699.212672\n",
      "Validation loss: 134643.085449\n",
      "changed index 7661\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 476  ntrees =  9997 \n",
      "best loss =  127696.28456 \n",
      "last loss =  127696.28456\n",
      "Validation loss: 134649.272078\n",
      "changed index 367\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 477  ntrees =  9997 \n",
      "best loss =  127693.372821 \n",
      "last loss =  127693.372821\n",
      "Validation loss: 134648.226395\n",
      "changed index 2574\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 478  ntrees =  9997 \n",
      "best loss =  127690.462848 \n",
      "last loss =  127690.462848\n",
      "Validation loss: 134648.833018\n",
      "changed index 4826\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 479  ntrees =  9997 \n",
      "best loss =  127687.551774 \n",
      "last loss =  127687.551774\n",
      "Validation loss: 134648.441654\n",
      "changed index 7508\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 480  ntrees =  9997 \n",
      "best loss =  127684.655805 \n",
      "last loss =  127684.655805\n",
      "Validation loss: 134648.518557\n",
      "changed index 5204\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 481  ntrees =  9997 \n",
      "best loss =  127681.749391 \n",
      "last loss =  127681.749391\n",
      "Validation loss: 134649.680992\n",
      "changed index 7361\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 482  ntrees =  9997 \n",
      "best loss =  127678.845757 \n",
      "last loss =  127678.845757\n",
      "Validation loss: 134651.770001\n",
      "changed index 1565\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 483  ntrees =  9997 \n",
      "best loss =  127675.939725 \n",
      "last loss =  127675.939725\n",
      "Validation loss: 134651.851737\n",
      "changed index 8157\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 484  ntrees =  9997 \n",
      "best loss =  127673.044358 \n",
      "last loss =  127673.044358\n",
      "Validation loss: 134651.866163\n",
      "changed index 8635\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 485  ntrees =  9997 \n",
      "best loss =  127670.147294 \n",
      "last loss =  127670.147294\n",
      "Validation loss: 134652.386706\n",
      "changed index 6655\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 486  ntrees =  9997 \n",
      "best loss =  127667.24229 \n",
      "last loss =  127667.24229\n",
      "Validation loss: 134650.732341\n",
      "changed index 2880\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 487  ntrees =  9997 \n",
      "best loss =  127664.347617 \n",
      "last loss =  127664.347617\n",
      "Validation loss: 134651.264568\n",
      "changed index 5254\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 488  ntrees =  9997 \n",
      "best loss =  127661.449202 \n",
      "last loss =  127661.449202\n",
      "Validation loss: 134651.372698\n",
      "changed index 2953\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 489  ntrees =  9997 \n",
      "best loss =  127658.573975 \n",
      "last loss =  127658.573975\n",
      "Validation loss: 134652.303501\n",
      "changed index 1679\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 490  ntrees =  9997 \n",
      "best loss =  127655.683987 \n",
      "last loss =  127655.683987\n",
      "Validation loss: 134653.063054\n",
      "changed index 8358\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 491  ntrees =  9997 \n",
      "best loss =  127652.793633 \n",
      "last loss =  127652.793633\n",
      "Validation loss: 134653.329204\n",
      "changed index 7823\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 492  ntrees =  9997 \n",
      "best loss =  127649.907428 \n",
      "last loss =  127649.907428\n",
      "Validation loss: 134652.763221\n",
      "changed index 5231\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 493  ntrees =  9997 \n",
      "best loss =  127647.019022 \n",
      "last loss =  127647.019022\n",
      "Validation loss: 134653.874107\n",
      "changed index 2020\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 494  ntrees =  9997 \n",
      "best loss =  127644.136249 \n",
      "last loss =  127644.136249\n",
      "Validation loss: 134655.87133\n",
      "changed index 6772\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 495  ntrees =  9997 \n",
      "best loss =  127641.263295 \n",
      "last loss =  127641.263295\n",
      "Validation loss: 134655.833565\n",
      "changed index 4422\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 496  ntrees =  9997 \n",
      "best loss =  127638.396591 \n",
      "last loss =  127638.396591\n",
      "Validation loss: 134656.521737\n",
      "changed index 2172\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 497  ntrees =  9997 \n",
      "best loss =  127635.515529 \n",
      "last loss =  127635.515529\n",
      "Validation loss: 134657.198369\n",
      "changed index 8406\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 498  ntrees =  9997 \n",
      "best loss =  127632.641075 \n",
      "last loss =  127632.641075\n",
      "Validation loss: 134656.936844\n",
      "changed index 5923\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 499  ntrees =  9997 \n",
      "best loss =  127629.763964 \n",
      "last loss =  127629.763964\n",
      "Validation loss: 134657.0344\n",
      "changed index 5334\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 500  ntrees =  9997 \n",
      "best loss =  127626.901823 \n",
      "last loss =  127626.901823\n",
      "Validation loss: 134656.169953\n",
      "changed index 8515\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 501  ntrees =  9997 \n",
      "best loss =  127624.019294 \n",
      "last loss =  127624.019294\n",
      "Validation loss: 134665.873914\n",
      "changed index 292\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 502  ntrees =  9997 \n",
      "best loss =  127621.156732 \n",
      "last loss =  127621.156732\n",
      "Validation loss: 134665.771319\n",
      "changed index 2893\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 503  ntrees =  9997 \n",
      "best loss =  127618.305693 \n",
      "last loss =  127618.305693\n",
      "Validation loss: 134665.532172\n",
      "changed index 4362\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 504  ntrees =  9997 \n",
      "best loss =  127615.444943 \n",
      "last loss =  127615.444943\n",
      "Validation loss: 134665.777091\n",
      "changed index 5019\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 505  ntrees =  9997 \n",
      "best loss =  127612.574226 \n",
      "last loss =  127612.574226\n",
      "Validation loss: 134666.426907\n",
      "changed index 1625\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 506  ntrees =  9997 \n",
      "best loss =  127609.726287 \n",
      "last loss =  127609.726287\n",
      "Validation loss: 134668.120066\n",
      "changed index 1662\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 507  ntrees =  9997 \n",
      "best loss =  127606.879211 \n",
      "last loss =  127606.879211\n",
      "Validation loss: 134669.835302\n",
      "changed index 1097\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 508  ntrees =  9997 \n",
      "best loss =  127604.030096 \n",
      "last loss =  127604.030096\n",
      "Validation loss: 134670.595463\n",
      "changed index 9247\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 509  ntrees =  9997 \n",
      "best loss =  127601.177596 \n",
      "last loss =  127601.177596\n",
      "Validation loss: 134671.294703\n",
      "changed index 6806\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 510  ntrees =  9997 \n",
      "best loss =  127598.328551 \n",
      "last loss =  127598.328551\n",
      "Validation loss: 134792.177728\n",
      "changed index 41\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 511  ntrees =  9997 \n",
      "best loss =  127595.477055 \n",
      "last loss =  127595.477055\n",
      "Validation loss: 134791.834373\n",
      "changed index 1393\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 512  ntrees =  9997 \n",
      "best loss =  127592.622208 \n",
      "last loss =  127592.622208\n",
      "Validation loss: 134792.05895\n",
      "changed index 9172\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 513  ntrees =  9997 \n",
      "best loss =  127589.772828 \n",
      "last loss =  127589.772828\n",
      "Validation loss: 134791.154918\n",
      "changed index 3112\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 514  ntrees =  9997 \n",
      "best loss =  127586.934296 \n",
      "last loss =  127586.934296\n",
      "Validation loss: 134791.141651\n",
      "changed index 3795\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 515  ntrees =  9997 \n",
      "best loss =  127584.099894 \n",
      "last loss =  127584.099894\n",
      "Validation loss: 134792.488117\n",
      "changed index 1921\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 516  ntrees =  9997 \n",
      "best loss =  127581.267381 \n",
      "last loss =  127581.267381\n",
      "Validation loss: 134792.969274\n",
      "changed index 8187\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 517  ntrees =  9997 \n",
      "best loss =  127578.433411 \n",
      "last loss =  127578.433411\n",
      "Validation loss: 134794.39533\n",
      "changed index 3277\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 518  ntrees =  9997 \n",
      "best loss =  127575.601848 \n",
      "last loss =  127575.601848\n",
      "Validation loss: 134795.017367\n",
      "changed index 6042\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 519  ntrees =  9997 \n",
      "best loss =  127572.763835 \n",
      "last loss =  127572.763835\n",
      "Validation loss: 134795.121505\n",
      "changed index 2867\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 520  ntrees =  9997 \n",
      "best loss =  127569.933214 \n",
      "last loss =  127569.933214\n",
      "Validation loss: 134794.829869\n",
      "changed index 9890\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 521  ntrees =  9997 \n",
      "best loss =  127567.100826 \n",
      "last loss =  127567.100826\n",
      "Validation loss: 134794.265319\n",
      "changed index 5348\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 522  ntrees =  9997 \n",
      "best loss =  127564.268787 \n",
      "last loss =  127564.268787\n",
      "Validation loss: 134793.73813\n",
      "changed index 8524\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 523  ntrees =  9997 \n",
      "best loss =  127561.449718 \n",
      "last loss =  127561.449718\n",
      "Validation loss: 134793.208904\n",
      "changed index 3093\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 524  ntrees =  9997 \n",
      "best loss =  127558.621693 \n",
      "last loss =  127558.621693\n",
      "Validation loss: 134795.115668\n",
      "changed index 6161\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 525  ntrees =  9997 \n",
      "best loss =  127555.793283 \n",
      "last loss =  127555.793283\n",
      "Validation loss: 134795.260144\n",
      "changed index 8789\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 526  ntrees =  9997 \n",
      "best loss =  127552.967769 \n",
      "last loss =  127552.967769\n",
      "Validation loss: 134795.807963\n",
      "changed index 637\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 527  ntrees =  9997 \n",
      "best loss =  127550.148402 \n",
      "last loss =  127550.148402\n",
      "Validation loss: 134796.148845\n",
      "changed index 8016\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 528  ntrees =  9997 \n",
      "best loss =  127547.327742 \n",
      "last loss =  127547.327742\n",
      "Validation loss: 134795.972138\n",
      "changed index 9985\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 529  ntrees =  9997 \n",
      "best loss =  127544.50991 \n",
      "last loss =  127544.50991\n",
      "Validation loss: 134795.72836\n",
      "changed index 4588\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 530  ntrees =  9997 \n",
      "best loss =  127541.693894 \n",
      "last loss =  127541.693894\n",
      "Validation loss: 134796.041201\n",
      "changed index 756\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 531  ntrees =  9997 \n",
      "best loss =  127538.886116 \n",
      "last loss =  127538.886116\n",
      "Validation loss: 134797.617358\n",
      "changed index 7141\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 532  ntrees =  9997 \n",
      "best loss =  127536.074324 \n",
      "last loss =  127536.074324\n",
      "Validation loss: 134800.423296\n",
      "changed index 585\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 533  ntrees =  9997 \n",
      "best loss =  127533.252541 \n",
      "last loss =  127533.252541\n",
      "Validation loss: 134800.247513\n",
      "changed index 2478\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 534  ntrees =  9997 \n",
      "best loss =  127530.444629 \n",
      "last loss =  127530.444629\n",
      "Validation loss: 134800.580204\n",
      "changed index 822\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 535  ntrees =  9997 \n",
      "best loss =  127527.634459 \n",
      "last loss =  127527.634459\n",
      "Validation loss: 134800.95862\n",
      "changed index 5005\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 536  ntrees =  9997 \n",
      "best loss =  127524.830904 \n",
      "last loss =  127524.830904\n",
      "Validation loss: 134802.017228\n",
      "changed index 5098\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 537  ntrees =  9997 \n",
      "best loss =  127522.024972 \n",
      "last loss =  127522.024972\n",
      "Validation loss: 134802.090899\n",
      "changed index 4215\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 538  ntrees =  9997 \n",
      "best loss =  127519.225184 \n",
      "last loss =  127519.225184\n",
      "Validation loss: 134802.380853\n",
      "changed index 4250\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 539  ntrees =  9997 \n",
      "best loss =  127516.438141 \n",
      "last loss =  127516.438141\n",
      "Validation loss: 134802.164902\n",
      "changed index 4581\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 540  ntrees =  9997 \n",
      "best loss =  127513.634217 \n",
      "last loss =  127513.634217\n",
      "Validation loss: 134802.663683\n",
      "changed index 5067\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 541  ntrees =  9997 \n",
      "best loss =  127510.838945 \n",
      "last loss =  127510.838945\n",
      "Validation loss: 134802.90145\n",
      "changed index 3139\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 542  ntrees =  9997 \n",
      "best loss =  127508.046021 \n",
      "last loss =  127508.046021\n",
      "Validation loss: 134803.115017\n",
      "changed index 9763\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 543  ntrees =  9997 \n",
      "best loss =  127505.255178 \n",
      "last loss =  127505.255178\n",
      "Validation loss: 134802.620389\n",
      "changed index 9733\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 544  ntrees =  9997 \n",
      "best loss =  127502.46459 \n",
      "last loss =  127502.46459\n",
      "Validation loss: 134802.074619\n",
      "changed index 8523\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 545  ntrees =  9997 \n",
      "best loss =  127499.674146 \n",
      "last loss =  127499.674146\n",
      "Validation loss: 134801.909165\n",
      "changed index 3228\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 546  ntrees =  9997 \n",
      "best loss =  127496.890125 \n",
      "last loss =  127496.890125\n",
      "Validation loss: 134802.781771\n",
      "changed index 1424\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 547  ntrees =  9997 \n",
      "best loss =  127494.108447 \n",
      "last loss =  127494.108447\n",
      "Validation loss: 134802.385113\n",
      "changed index 9968\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 548  ntrees =  9997 \n",
      "best loss =  127491.332913 \n",
      "last loss =  127491.332913\n",
      "Validation loss: 134801.801153\n",
      "changed index 6816\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 549  ntrees =  9997 \n",
      "best loss =  127488.552042 \n",
      "last loss =  127488.552042\n",
      "Validation loss: 134802.949241\n",
      "changed index 4877\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 550  ntrees =  9997 \n",
      "best loss =  127485.772528 \n",
      "last loss =  127485.772528\n",
      "Validation loss: 134803.069983\n",
      "changed index 4767\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 551  ntrees =  9997 \n",
      "best loss =  127482.998678 \n",
      "last loss =  127482.998678\n",
      "Validation loss: 134803.73888\n",
      "changed index 7476\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 552  ntrees =  9997 \n",
      "best loss =  127480.22752 \n",
      "last loss =  127480.22752\n",
      "Validation loss: 134803.932437\n",
      "changed index 9493\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 553  ntrees =  9997 \n",
      "best loss =  127477.450431 \n",
      "last loss =  127477.450431\n",
      "Validation loss: 134804.061916\n",
      "changed index 9648\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 554  ntrees =  9997 \n",
      "best loss =  127474.677686 \n",
      "last loss =  127474.677686\n",
      "Validation loss: 134803.08079\n",
      "changed index 6312\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 555  ntrees =  9997 \n",
      "best loss =  127471.903568 \n",
      "last loss =  127471.903568\n",
      "Validation loss: 134801.486716\n",
      "changed index 646\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 556  ntrees =  9997 \n",
      "best loss =  127469.134666 \n",
      "last loss =  127469.134666\n",
      "Validation loss: 134802.330121\n",
      "changed index 2211\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 557  ntrees =  9997 \n",
      "best loss =  127466.372225 \n",
      "last loss =  127466.372225\n",
      "Validation loss: 134802.636488\n",
      "changed index 2896\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 558  ntrees =  9997 \n",
      "best loss =  127463.610606 \n",
      "last loss =  127463.610606\n",
      "Validation loss: 134802.279188\n",
      "changed index 601\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 559  ntrees =  9997 \n",
      "best loss =  127460.846731 \n",
      "last loss =  127460.846731\n",
      "Validation loss: 134801.193782\n",
      "changed index 9852\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 560  ntrees =  9997 \n",
      "best loss =  127458.081485 \n",
      "last loss =  127458.081485\n",
      "Validation loss: 134801.037003\n",
      "changed index 4322\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 561  ntrees =  9997 \n",
      "best loss =  127455.318704 \n",
      "last loss =  127455.318704\n",
      "Validation loss: 134801.603207\n",
      "changed index 7859\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 562  ntrees =  9997 \n",
      "best loss =  127452.558049 \n",
      "last loss =  127452.558049\n",
      "Validation loss: 134801.65161\n",
      "changed index 3124\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 563  ntrees =  9997 \n",
      "best loss =  127449.793724 \n",
      "last loss =  127449.793724\n",
      "Validation loss: 134801.209807\n",
      "changed index 6573\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 564  ntrees =  9997 \n",
      "best loss =  127447.041631 \n",
      "last loss =  127447.041631\n",
      "Validation loss: 134841.62077\n",
      "changed index 167\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 565  ntrees =  9997 \n",
      "best loss =  127444.286168 \n",
      "last loss =  127444.286168\n",
      "Validation loss: 134841.050243\n",
      "changed index 4587\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 566  ntrees =  9997 \n",
      "best loss =  127441.540359 \n",
      "last loss =  127441.540359\n",
      "Validation loss: 134843.526287\n",
      "changed index 1687\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 567  ntrees =  9997 \n",
      "best loss =  127438.793264 \n",
      "last loss =  127438.793264\n",
      "Validation loss: 134843.884922\n",
      "changed index 9386\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 568  ntrees =  9997 \n",
      "best loss =  127436.045633 \n",
      "last loss =  127436.045633\n",
      "Validation loss: 134844.253452\n",
      "changed index 6783\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 569  ntrees =  9997 \n",
      "best loss =  127433.294976 \n",
      "last loss =  127433.294976\n",
      "Validation loss: 134845.08841\n",
      "changed index 728\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 570  ntrees =  9997 \n",
      "best loss =  127430.550648 \n",
      "last loss =  127430.550648\n",
      "Validation loss: 134844.730841\n",
      "changed index 8569\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 571  ntrees =  9997 \n",
      "best loss =  127427.797881 \n",
      "last loss =  127427.797881\n",
      "Validation loss: 134845.380211\n",
      "changed index 4382\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 572  ntrees =  9997 \n",
      "best loss =  127425.052263 \n",
      "last loss =  127425.052263\n",
      "Validation loss: 134845.283896\n",
      "changed index 9663\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 573  ntrees =  9997 \n",
      "best loss =  127422.307094 \n",
      "last loss =  127422.307094\n",
      "Validation loss: 134845.513893\n",
      "changed index 9657\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 574  ntrees =  9997 \n",
      "best loss =  127419.564323 \n",
      "last loss =  127419.564323\n",
      "Validation loss: 134895.415617\n",
      "changed index 145\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 575  ntrees =  9997 \n",
      "best loss =  127416.824024 \n",
      "last loss =  127416.824024\n",
      "Validation loss: 134894.899641\n",
      "changed index 9338\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 576  ntrees =  9997 \n",
      "best loss =  127414.082974 \n",
      "last loss =  127414.082974\n",
      "Validation loss: 134895.108509\n",
      "changed index 5907\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 577  ntrees =  9997 \n",
      "best loss =  127411.348256 \n",
      "last loss =  127411.348256\n",
      "Validation loss: 134895.91904\n",
      "changed index 8718\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 578  ntrees =  9997 \n",
      "best loss =  127408.618742 \n",
      "last loss =  127408.618742\n",
      "Validation loss: 134896.529188\n",
      "changed index 7502\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 579  ntrees =  9997 \n",
      "best loss =  127405.890025 \n",
      "last loss =  127405.890025\n",
      "Validation loss: 134895.795327\n",
      "changed index 8380\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 580  ntrees =  9997 \n",
      "best loss =  127403.159245 \n",
      "last loss =  127403.159245\n",
      "Validation loss: 134895.414758\n",
      "changed index 973\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 581  ntrees =  9997 \n",
      "best loss =  127400.425433 \n",
      "last loss =  127400.425433\n",
      "Validation loss: 134894.444486\n",
      "changed index 9177\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 582  ntrees =  9997 \n",
      "best loss =  127397.696574 \n",
      "last loss =  127397.696574\n",
      "Validation loss: 134894.389177\n",
      "changed index 4186\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 583  ntrees =  9997 \n",
      "best loss =  127394.972805 \n",
      "last loss =  127394.972805\n",
      "Validation loss: 134894.832861\n",
      "changed index 8089\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 584  ntrees =  9997 \n",
      "best loss =  127392.241981 \n",
      "last loss =  127392.241981\n",
      "Validation loss: 134894.049542\n",
      "changed index 3272\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 585  ntrees =  9997 \n",
      "best loss =  127389.51924 \n",
      "last loss =  127389.51924\n",
      "Validation loss: 134894.448552\n",
      "changed index 6246\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 586  ntrees =  9997 \n",
      "best loss =  127386.807043 \n",
      "last loss =  127386.807043\n",
      "Validation loss: 134894.37783\n",
      "changed index 4781\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 587  ntrees =  9997 \n",
      "best loss =  127384.086235 \n",
      "last loss =  127384.086235\n",
      "Validation loss: 134895.330369\n",
      "changed index 2051\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 588  ntrees =  9997 \n",
      "best loss =  127381.375378 \n",
      "last loss =  127381.375378\n",
      "Validation loss: 134896.318749\n",
      "changed index 2311\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 589  ntrees =  9997 \n",
      "best loss =  127378.669093 \n",
      "last loss =  127378.669093\n",
      "Validation loss: 135006.620658\n",
      "changed index 67\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 590  ntrees =  9997 \n",
      "best loss =  127375.952566 \n",
      "last loss =  127375.952566\n",
      "Validation loss: 135006.170009\n",
      "changed index 4569\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 591  ntrees =  9997 \n",
      "best loss =  127373.23841 \n",
      "last loss =  127373.23841\n",
      "Validation loss: 135006.608909\n",
      "changed index 8028\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 592  ntrees =  9997 \n",
      "best loss =  127370.525733 \n",
      "last loss =  127370.525733\n",
      "Validation loss: 135006.883137\n",
      "changed index 8035\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 593  ntrees =  9997 \n",
      "best loss =  127367.817327 \n",
      "last loss =  127367.817327\n",
      "Validation loss: 135008.278664\n",
      "changed index 3756\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 594  ntrees =  9997 \n",
      "best loss =  127365.116216 \n",
      "last loss =  127365.116216\n",
      "Validation loss: 135009.592147\n",
      "changed index 4621\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 595  ntrees =  9997 \n",
      "best loss =  127362.403744 \n",
      "last loss =  127362.403744\n",
      "Validation loss: 135010.828271\n",
      "changed index 3528\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 596  ntrees =  9997 \n",
      "best loss =  127359.696634 \n",
      "last loss =  127359.696634\n",
      "Validation loss: 135011.175378\n",
      "changed index 6529\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 597  ntrees =  9997 \n",
      "best loss =  127356.998236 \n",
      "last loss =  127356.998236\n",
      "Validation loss: 135010.283182\n",
      "changed index 6242\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 598  ntrees =  9997 \n",
      "best loss =  127354.297794 \n",
      "last loss =  127354.297794\n",
      "Validation loss: 135012.237705\n",
      "changed index 5076\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 599  ntrees =  9997 \n",
      "best loss =  127351.592311 \n",
      "last loss =  127351.592311\n",
      "Validation loss: 135012.236564\n",
      "changed index 5461\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 600  ntrees =  9997 \n",
      "best loss =  127348.890636 \n",
      "last loss =  127348.890636\n",
      "Validation loss: 135013.41666\n",
      "changed index 5753\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 601  ntrees =  9997 \n",
      "best loss =  127346.196509 \n",
      "last loss =  127346.196509\n",
      "Validation loss: 135014.40726\n",
      "changed index 2440\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 602  ntrees =  9997 \n",
      "best loss =  127343.510907 \n",
      "last loss =  127343.510907\n",
      "Validation loss: 135014.073801\n",
      "changed index 6484\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 603  ntrees =  9997 \n",
      "best loss =  127340.816854 \n",
      "last loss =  127340.816854\n",
      "Validation loss: 135015.149319\n",
      "changed index 3541\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 604  ntrees =  9997 \n",
      "best loss =  127338.123503 \n",
      "last loss =  127338.123503\n",
      "Validation loss: 135015.375009\n",
      "changed index 4718\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 605  ntrees =  9997 \n",
      "best loss =  127335.445366 \n",
      "last loss =  127335.445366\n",
      "Validation loss: 135014.735109\n",
      "changed index 8546\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 606  ntrees =  9997 \n",
      "best loss =  127332.758979 \n",
      "last loss =  127332.758979\n",
      "Validation loss: 135014.014619\n",
      "changed index 6378\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 607  ntrees =  9997 \n",
      "best loss =  127330.076423 \n",
      "last loss =  127330.076423\n",
      "Validation loss: 135013.102041\n",
      "changed index 2761\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 608  ntrees =  9997 \n",
      "best loss =  127327.40185 \n",
      "last loss =  127327.40185\n",
      "Validation loss: 135014.059276\n",
      "changed index 7261\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 609  ntrees =  9997 \n",
      "best loss =  127324.724778 \n",
      "last loss =  127324.724778\n",
      "Validation loss: 135014.607077\n",
      "changed index 2027\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 610  ntrees =  9997 \n",
      "best loss =  127322.050771 \n",
      "last loss =  127322.050771\n",
      "Validation loss: 135014.294585\n",
      "changed index 3780\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 611  ntrees =  9997 \n",
      "best loss =  127319.362689 \n",
      "last loss =  127319.362689\n",
      "Validation loss: 135014.039748\n",
      "changed index 8551\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 612  ntrees =  9997 \n",
      "best loss =  127316.683857 \n",
      "last loss =  127316.683857\n",
      "Validation loss: 135017.479441\n",
      "changed index 524\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 613  ntrees =  9997 \n",
      "best loss =  127314.003543 \n",
      "last loss =  127314.003543\n",
      "Validation loss: 135016.596687\n",
      "changed index 5820\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 614  ntrees =  9997 \n",
      "best loss =  127311.329751 \n",
      "last loss =  127311.329751\n",
      "Validation loss: 135017.733942\n",
      "changed index 1393\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 615  ntrees =  9997 \n",
      "best loss =  127308.658329 \n",
      "last loss =  127308.658329\n",
      "Validation loss: 135018.497582\n",
      "changed index 827\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 616  ntrees =  9997 \n",
      "best loss =  127305.987077 \n",
      "last loss =  127305.987077\n",
      "Validation loss: 135019.106688\n",
      "changed index 2997\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 617  ntrees =  9997 \n",
      "best loss =  127303.323238 \n",
      "last loss =  127303.323238\n",
      "Validation loss: 135018.959482\n",
      "changed index 4913\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 618  ntrees =  9997 \n",
      "best loss =  127300.661675 \n",
      "last loss =  127300.661675\n",
      "Validation loss: 135018.901674\n",
      "changed index 3177\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 619  ntrees =  9997 \n",
      "best loss =  127297.998239 \n",
      "last loss =  127297.998239\n",
      "Validation loss: 135019.288522\n",
      "changed index 7076\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 620  ntrees =  9997 \n",
      "best loss =  127295.334391 \n",
      "last loss =  127295.334391\n",
      "Validation loss: 135020.102439\n",
      "changed index 9214\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 621  ntrees =  9997 \n",
      "best loss =  127292.669435 \n",
      "last loss =  127292.669435\n",
      "Validation loss: 135019.895059\n",
      "changed index 1241\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 622  ntrees =  9997 \n",
      "best loss =  127290.006521 \n",
      "last loss =  127290.006521\n",
      "Validation loss: 135019.322165\n",
      "changed index 3800\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 623  ntrees =  9997 \n",
      "best loss =  127287.347018 \n",
      "last loss =  127287.347018\n",
      "Validation loss: 135019.024785\n",
      "changed index 1989\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 624  ntrees =  9997 \n",
      "best loss =  127284.688921 \n",
      "last loss =  127284.688921\n",
      "Validation loss: 135019.379569\n",
      "changed index 8265\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 625  ntrees =  9997 \n",
      "best loss =  127282.032988 \n",
      "last loss =  127282.032988\n",
      "Validation loss: 135019.767464\n",
      "changed index 7518\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 626  ntrees =  9997 \n",
      "best loss =  127279.37467 \n",
      "last loss =  127279.37467\n",
      "Validation loss: 135018.853492\n",
      "changed index 6453\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 627  ntrees =  9997 \n",
      "best loss =  127276.722957 \n",
      "last loss =  127276.722957\n",
      "Validation loss: 135019.481147\n",
      "changed index 1156\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 628  ntrees =  9997 \n",
      "best loss =  127274.068383 \n",
      "last loss =  127274.068383\n",
      "Validation loss: 135018.364358\n",
      "changed index 6672\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 629  ntrees =  9997 \n",
      "best loss =  127271.414093 \n",
      "last loss =  127271.414093\n",
      "Validation loss: 135019.322036\n",
      "changed index 7536\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 630  ntrees =  9997 \n",
      "best loss =  127268.764883 \n",
      "last loss =  127268.764883\n",
      "Validation loss: 135020.043498\n",
      "changed index 2459\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 631  ntrees =  9997 \n",
      "best loss =  127266.113733 \n",
      "last loss =  127266.113733\n",
      "Validation loss: 135020.225781\n",
      "changed index 9241\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 632  ntrees =  9997 \n",
      "best loss =  127263.465176 \n",
      "last loss =  127263.465176\n",
      "Validation loss: 135020.344181\n",
      "changed index 7479\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 633  ntrees =  9997 \n",
      "best loss =  127260.816531 \n",
      "last loss =  127260.816531\n",
      "Validation loss: 135020.686301\n",
      "changed index 7127\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 634  ntrees =  9997 \n",
      "best loss =  127258.170023 \n",
      "last loss =  127258.170023\n",
      "Validation loss: 135020.498725\n",
      "changed index 8068\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 635  ntrees =  9997 \n",
      "best loss =  127255.527716 \n",
      "last loss =  127255.527716\n",
      "Validation loss: 135022.658596\n",
      "changed index 9809\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 636  ntrees =  9997 \n",
      "best loss =  127252.885029 \n",
      "last loss =  127252.885029\n",
      "Validation loss: 135022.053318\n",
      "changed index 9575\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 637  ntrees =  9997 \n",
      "best loss =  127250.245279 \n",
      "last loss =  127250.245279\n",
      "Validation loss: 135021.753162\n",
      "changed index 1348\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 638  ntrees =  9997 \n",
      "best loss =  127247.604483 \n",
      "last loss =  127247.604483\n",
      "Validation loss: 135022.772726\n",
      "changed index 6886\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 639  ntrees =  9997 \n",
      "best loss =  127244.953759 \n",
      "last loss =  127244.953759\n",
      "Validation loss: 135023.091671\n",
      "changed index 5665\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 640  ntrees =  9997 \n",
      "best loss =  127242.320305 \n",
      "last loss =  127242.320305\n",
      "Validation loss: 135022.661627\n",
      "changed index 4603\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 641  ntrees =  9997 \n",
      "best loss =  127239.683969 \n",
      "last loss =  127239.683969\n",
      "Validation loss: 135022.10778\n",
      "changed index 7454\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 642  ntrees =  9997 \n",
      "best loss =  127237.043226 \n",
      "last loss =  127237.043226\n",
      "Validation loss: 135022.906696\n",
      "changed index 3441\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 643  ntrees =  9997 \n",
      "best loss =  127234.412636 \n",
      "last loss =  127234.412636\n",
      "Validation loss: 135022.695426\n",
      "changed index 5149\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 644  ntrees =  9997 \n",
      "best loss =  127231.786374 \n",
      "last loss =  127231.786374\n",
      "Validation loss: 135022.887238\n",
      "changed index 7121\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 645  ntrees =  9997 \n",
      "best loss =  127229.164759 \n",
      "last loss =  127229.164759\n",
      "Validation loss: 135022.836511\n",
      "changed index 6867\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 646  ntrees =  9997 \n",
      "best loss =  127226.541578 \n",
      "last loss =  127226.541578\n",
      "Validation loss: 135023.612092\n",
      "changed index 7584\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 647  ntrees =  9997 \n",
      "best loss =  127223.912035 \n",
      "last loss =  127223.912035\n",
      "Validation loss: 135023.93084\n",
      "changed index 6340\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 648  ntrees =  9997 \n",
      "best loss =  127221.285422 \n",
      "last loss =  127221.285422\n",
      "Validation loss: 135022.775435\n",
      "changed index 6377\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 649  ntrees =  9997 \n",
      "best loss =  127218.661565 \n",
      "last loss =  127218.661565\n",
      "Validation loss: 135023.085225\n",
      "changed index 9287\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 650  ntrees =  9997 \n",
      "best loss =  127216.037756 \n",
      "last loss =  127216.037756\n",
      "Validation loss: 135024.278657\n",
      "changed index 4411\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 651  ntrees =  9997 \n",
      "best loss =  127213.420086 \n",
      "last loss =  127213.420086\n",
      "Validation loss: 135023.540261\n",
      "changed index 6292\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 652  ntrees =  9997 \n",
      "best loss =  127210.796132 \n",
      "last loss =  127210.796132\n",
      "Validation loss: 135022.936119\n",
      "changed index 6141\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 653  ntrees =  9997 \n",
      "best loss =  127208.182647 \n",
      "last loss =  127208.182647\n",
      "Validation loss: 135024.600972\n",
      "changed index 857\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 654  ntrees =  9997 \n",
      "best loss =  127205.571971 \n",
      "last loss =  127205.571971\n",
      "Validation loss: 135024.843478\n",
      "changed index 7414\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 655  ntrees =  9997 \n",
      "best loss =  127202.955162 \n",
      "last loss =  127202.955162\n",
      "Validation loss: 135025.695505\n",
      "changed index 3401\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 656  ntrees =  9997 \n",
      "best loss =  127200.340094 \n",
      "last loss =  127200.340094\n",
      "Validation loss: 135024.071532\n",
      "changed index 7964\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 657  ntrees =  9997 \n",
      "best loss =  127197.732847 \n",
      "last loss =  127197.732847\n",
      "Validation loss: 135024.840598\n",
      "changed index 7044\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 658  ntrees =  9997 \n",
      "best loss =  127195.119979 \n",
      "last loss =  127195.119979\n",
      "Validation loss: 135024.240211\n",
      "changed index 9552\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 659  ntrees =  9997 \n",
      "best loss =  127192.513311 \n",
      "last loss =  127192.513311\n",
      "Validation loss: 135022.793594\n",
      "changed index 4514\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 660  ntrees =  9997 \n",
      "best loss =  127189.900463 \n",
      "last loss =  127189.900463\n",
      "Validation loss: 135023.566494\n",
      "changed index 4341\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 661  ntrees =  9997 \n",
      "best loss =  127187.297312 \n",
      "last loss =  127187.297312\n",
      "Validation loss: 135024.188859\n",
      "changed index 8431\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 662  ntrees =  9997 \n",
      "best loss =  127184.696026 \n",
      "last loss =  127184.696026\n",
      "Validation loss: 135189.51036\n",
      "changed index 30\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 663  ntrees =  9997 \n",
      "best loss =  127182.100568 \n",
      "last loss =  127182.100568\n",
      "Validation loss: 135191.891673\n",
      "changed index 638\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 664  ntrees =  9997 \n",
      "best loss =  127179.502283 \n",
      "last loss =  127179.502283\n",
      "Validation loss: 135192.535271\n",
      "changed index 1141\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 665  ntrees =  9997 \n",
      "best loss =  127176.906294 \n",
      "last loss =  127176.906294\n",
      "Validation loss: 135193.928832\n",
      "changed index 950\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 666  ntrees =  9997 \n",
      "best loss =  127174.31046 \n",
      "last loss =  127174.31046\n",
      "Validation loss: 135193.41672\n",
      "changed index 8413\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 667  ntrees =  9997 \n",
      "best loss =  127171.718276 \n",
      "last loss =  127171.718276\n",
      "Validation loss: 135193.986609\n",
      "changed index 4525\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 668  ntrees =  9997 \n",
      "best loss =  127169.119483 \n",
      "last loss =  127169.119483\n",
      "Validation loss: 135194.525551\n",
      "changed index 4350\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 669  ntrees =  9997 \n",
      "best loss =  127166.530923 \n",
      "last loss =  127166.530923\n",
      "Validation loss: 135194.311282\n",
      "changed index 4531\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 670  ntrees =  9997 \n",
      "best loss =  127163.941669 \n",
      "last loss =  127163.941669\n",
      "Validation loss: 135196.849706\n",
      "changed index 630\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 671  ntrees =  9997 \n",
      "best loss =  127161.354435 \n",
      "last loss =  127161.354435\n",
      "Validation loss: 135198.356632\n",
      "changed index 3919\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 672  ntrees =  9997 \n",
      "best loss =  127158.767769 \n",
      "last loss =  127158.767769\n",
      "Validation loss: 135198.483871\n",
      "changed index 1846\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 673  ntrees =  9997 \n",
      "best loss =  127156.185434 \n",
      "last loss =  127156.185434\n",
      "Validation loss: 135199.077568\n",
      "changed index 7182\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 674  ntrees =  9997 \n",
      "best loss =  127153.603313 \n",
      "last loss =  127153.603313\n",
      "Validation loss: 135199.010967\n",
      "changed index 8499\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 675  ntrees =  9997 \n",
      "best loss =  127151.019434 \n",
      "last loss =  127151.019434\n",
      "Validation loss: 135198.825934\n",
      "changed index 4455\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 676  ntrees =  9997 \n",
      "best loss =  127148.439671 \n",
      "last loss =  127148.439671\n",
      "Validation loss: 135197.937673\n",
      "changed index 8961\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 677  ntrees =  9997 \n",
      "best loss =  127145.85891 \n",
      "last loss =  127145.85891\n",
      "Validation loss: 135197.994354\n",
      "changed index 8866\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 678  ntrees =  9997 \n",
      "best loss =  127143.278075 \n",
      "last loss =  127143.278075\n",
      "Validation loss: 135199.575144\n",
      "changed index 3081\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 679  ntrees =  9997 \n",
      "best loss =  127140.699305 \n",
      "last loss =  127140.699305\n",
      "Validation loss: 135198.818157\n",
      "changed index 5101\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 680  ntrees =  9997 \n",
      "best loss =  127138.115533 \n",
      "last loss =  127138.115533\n",
      "Validation loss: 135198.093733\n",
      "changed index 6409\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 681  ntrees =  9997 \n",
      "best loss =  127135.539544 \n",
      "last loss =  127135.539544\n",
      "Validation loss: 135198.692099\n",
      "changed index 6850\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 682  ntrees =  9997 \n",
      "best loss =  127132.966189 \n",
      "last loss =  127132.966189\n",
      "Validation loss: 135198.96316\n",
      "changed index 6837\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 683  ntrees =  9997 \n",
      "best loss =  127130.395623 \n",
      "last loss =  127130.395623\n",
      "Validation loss: 135199.213577\n",
      "changed index 2411\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 684  ntrees =  9997 \n",
      "best loss =  127127.822937 \n",
      "last loss =  127127.822937\n",
      "Validation loss: 135199.438612\n",
      "changed index 3965\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 685  ntrees =  9997 \n",
      "best loss =  127125.255272 \n",
      "last loss =  127125.255272\n",
      "Validation loss: 135199.528989\n",
      "changed index 8010\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 686  ntrees =  9997 \n",
      "best loss =  127122.683984 \n",
      "last loss =  127122.683984\n",
      "Validation loss: 135199.184658\n",
      "changed index 4557\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 687  ntrees =  9997 \n",
      "best loss =  127120.118835 \n",
      "last loss =  127120.118835\n",
      "Validation loss: 135198.749311\n",
      "changed index 6700\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 688  ntrees =  9997 \n",
      "best loss =  127117.557772 \n",
      "last loss =  127117.557772\n",
      "Validation loss: 135199.827106\n",
      "changed index 1854\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 689  ntrees =  9997 \n",
      "best loss =  127114.986894 \n",
      "last loss =  127114.986894\n",
      "Validation loss: 135199.848745\n",
      "changed index 6672\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 690  ntrees =  9997 \n",
      "best loss =  127112.421804 \n",
      "last loss =  127112.421804\n",
      "Validation loss: 135201.274082\n",
      "changed index 1267\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 691  ntrees =  9997 \n",
      "best loss =  127109.860222 \n",
      "last loss =  127109.860222\n",
      "Validation loss: 135202.10599\n",
      "changed index 4004\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 692  ntrees =  9997 \n",
      "best loss =  127107.293598 \n",
      "last loss =  127107.293598\n",
      "Validation loss: 135202.193614\n",
      "changed index 4388\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 693  ntrees =  9997 \n",
      "best loss =  127104.726356 \n",
      "last loss =  127104.726356\n",
      "Validation loss: 135203.76313\n",
      "changed index 2876\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 694  ntrees =  9997 \n",
      "best loss =  127102.162814 \n",
      "last loss =  127102.162814\n",
      "Validation loss: 135204.337252\n",
      "changed index 8975\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 695  ntrees =  9997 \n",
      "best loss =  127099.602597 \n",
      "last loss =  127099.602597\n",
      "Validation loss: 135205.344876\n",
      "changed index 1770\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 696  ntrees =  9997 \n",
      "best loss =  127097.046168 \n",
      "last loss =  127097.046168\n",
      "Validation loss: 135205.636953\n",
      "changed index 8261\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 697  ntrees =  9997 \n",
      "best loss =  127094.490852 \n",
      "last loss =  127094.490852\n",
      "Validation loss: 135207.12099\n",
      "changed index 2259\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 698  ntrees =  9997 \n",
      "best loss =  127091.937248 \n",
      "last loss =  127091.937248\n",
      "Validation loss: 135234.779654\n",
      "changed index 241\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 699  ntrees =  9997 \n",
      "best loss =  127089.389642 \n",
      "last loss =  127089.389642\n",
      "Validation loss: 135234.531067\n",
      "changed index 6722\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 700  ntrees =  9997 \n",
      "best loss =  127086.840419 \n",
      "last loss =  127086.840419\n",
      "Validation loss: 135234.645133\n",
      "changed index 3229\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 701  ntrees =  9997 \n",
      "best loss =  127084.290216 \n",
      "last loss =  127084.290216\n",
      "Validation loss: 135233.895014\n",
      "changed index 9633\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 702  ntrees =  9997 \n",
      "best loss =  127081.74549 \n",
      "last loss =  127081.74549\n",
      "Validation loss: 135232.888497\n",
      "changed index 4795\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 703  ntrees =  9997 \n",
      "best loss =  127079.190049 \n",
      "last loss =  127079.190049\n",
      "Validation loss: 135233.603779\n",
      "changed index 4309\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 704  ntrees =  9997 \n",
      "best loss =  127076.641853 \n",
      "last loss =  127076.641853\n",
      "Validation loss: 135233.7396\n",
      "changed index 4379\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 705  ntrees =  9997 \n",
      "best loss =  127074.099813 \n",
      "last loss =  127074.099813\n",
      "Validation loss: 135234.281373\n",
      "changed index 3416\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 706  ntrees =  9997 \n",
      "best loss =  127071.560691 \n",
      "last loss =  127071.560691\n",
      "Validation loss: 135234.346973\n",
      "changed index 9550\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 707  ntrees =  9997 \n",
      "best loss =  127069.023596 \n",
      "last loss =  127069.023596\n",
      "Validation loss: 135234.121092\n",
      "changed index 3695\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 708  ntrees =  9997 \n",
      "best loss =  127066.489528 \n",
      "last loss =  127066.489528\n",
      "Validation loss: 135235.495478\n",
      "changed index 3227\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 709  ntrees =  9997 \n",
      "best loss =  127063.947055 \n",
      "last loss =  127063.947055\n",
      "Validation loss: 135234.725008\n",
      "changed index 7327\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 710  ntrees =  9997 \n",
      "best loss =  127061.409409 \n",
      "last loss =  127061.409409\n",
      "Validation loss: 135236.491336\n",
      "changed index 4455\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 711  ntrees =  9997 \n",
      "best loss =  127058.87899 \n",
      "last loss =  127058.87899\n",
      "Validation loss: 135237.074716\n",
      "changed index 8746\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 712  ntrees =  9997 \n",
      "best loss =  127056.34155 \n",
      "last loss =  127056.34155\n",
      "Validation loss: 135236.699572\n",
      "changed index 1369\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 713  ntrees =  9997 \n",
      "best loss =  127053.807199 \n",
      "last loss =  127053.807199\n",
      "Validation loss: 135447.090239\n",
      "changed index 11\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 714  ntrees =  9997 \n",
      "best loss =  127051.270052 \n",
      "last loss =  127051.270052\n",
      "Validation loss: 135447.900248\n",
      "changed index 8940\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 715  ntrees =  9997 \n",
      "best loss =  127048.742627 \n",
      "last loss =  127048.742627\n",
      "Validation loss: 135454.096402\n",
      "changed index 452\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 716  ntrees =  9997 \n",
      "best loss =  127046.213161 \n",
      "last loss =  127046.213161\n",
      "Validation loss: 135454.514025\n",
      "changed index 9242\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 717  ntrees =  9997 \n",
      "best loss =  127043.686914 \n",
      "last loss =  127043.686914\n",
      "Validation loss: 135453.991669\n",
      "changed index 6424\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 718  ntrees =  9997 \n",
      "best loss =  127041.16304 \n",
      "last loss =  127041.16304\n",
      "Validation loss: 135454.073365\n",
      "changed index 2422\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 719  ntrees =  9997 \n",
      "best loss =  127038.631357 \n",
      "last loss =  127038.631357\n",
      "Validation loss: 135458.958552\n",
      "changed index 618\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 720  ntrees =  9997 \n",
      "best loss =  127036.108942 \n",
      "last loss =  127036.108942\n",
      "Validation loss: 135458.405665\n",
      "changed index 9451\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 721  ntrees =  9997 \n",
      "best loss =  127033.590342 \n",
      "last loss =  127033.590342\n",
      "Validation loss: 135458.804763\n",
      "changed index 3138\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 722  ntrees =  9997 \n",
      "best loss =  127031.068993 \n",
      "last loss =  127031.068993\n",
      "Validation loss: 135458.453854\n",
      "changed index 8080\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 723  ntrees =  9997 \n",
      "best loss =  127028.555773 \n",
      "last loss =  127028.555773\n",
      "Validation loss: 135458.632863\n",
      "changed index 4231\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 724  ntrees =  9997 \n",
      "best loss =  127026.040763 \n",
      "last loss =  127026.040763\n",
      "Validation loss: 135457.716935\n",
      "changed index 4088\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 725  ntrees =  9997 \n",
      "best loss =  127023.526449 \n",
      "last loss =  127023.526449\n",
      "Validation loss: 135458.94576\n",
      "changed index 4895\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 726  ntrees =  9997 \n",
      "best loss =  127021.011259 \n",
      "last loss =  127021.011259\n",
      "Validation loss: 135495.875033\n",
      "changed index 197\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 727  ntrees =  9997 \n",
      "best loss =  127018.498334 \n",
      "last loss =  127018.498334\n",
      "Validation loss: 135494.789052\n",
      "changed index 3374\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 728  ntrees =  9997 \n",
      "best loss =  127015.989521 \n",
      "last loss =  127015.989521\n",
      "Validation loss: 135494.874314\n",
      "changed index 2012\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 729  ntrees =  9997 \n",
      "best loss =  127013.479423 \n",
      "last loss =  127013.479423\n",
      "Validation loss: 135495.07691\n",
      "changed index 2318\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 730  ntrees =  9997 \n",
      "best loss =  127010.97412 \n",
      "last loss =  127010.97412\n",
      "Validation loss: 135496.548141\n",
      "changed index 2325\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 731  ntrees =  9997 \n",
      "best loss =  127008.463266 \n",
      "last loss =  127008.463266\n",
      "Validation loss: 135496.734468\n",
      "changed index 7224\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 732  ntrees =  9997 \n",
      "best loss =  127005.954789 \n",
      "last loss =  127005.954789\n",
      "Validation loss: 135499.437879\n",
      "changed index 763\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 733  ntrees =  9997 \n",
      "best loss =  127003.446904 \n",
      "last loss =  127003.446904\n",
      "Validation loss: 135499.04542\n",
      "changed index 4051\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 734  ntrees =  9997 \n",
      "best loss =  127000.947667 \n",
      "last loss =  127000.947667\n",
      "Validation loss: 135499.28985\n",
      "changed index 8367\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 735  ntrees =  9997 \n",
      "best loss =  126998.446925 \n",
      "last loss =  126998.446925\n",
      "Validation loss: 135498.484758\n",
      "changed index 9433\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 736  ntrees =  9997 \n",
      "best loss =  126995.943696 \n",
      "last loss =  126995.943696\n",
      "Validation loss: 135498.187355\n",
      "changed index 3268\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 737  ntrees =  9997 \n",
      "best loss =  126993.445268 \n",
      "last loss =  126993.445268\n",
      "Validation loss: 135498.136003\n",
      "changed index 3820\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 738  ntrees =  9997 \n",
      "best loss =  126990.950265 \n",
      "last loss =  126990.950265\n",
      "Validation loss: 135499.353165\n",
      "changed index 2788\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 739  ntrees =  9997 \n",
      "best loss =  126988.449809 \n",
      "last loss =  126988.449809\n",
      "Validation loss: 135499.403611\n",
      "changed index 6620\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 740  ntrees =  9997 \n",
      "best loss =  126985.954493 \n",
      "last loss =  126985.954493\n",
      "Validation loss: 135501.385374\n",
      "changed index 8652\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 741  ntrees =  9997 \n",
      "best loss =  126983.457887 \n",
      "last loss =  126983.457887\n",
      "Validation loss: 135500.062066\n",
      "changed index 4258\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 742  ntrees =  9997 \n",
      "best loss =  126980.962182 \n",
      "last loss =  126980.962182\n",
      "Validation loss: 135499.457938\n",
      "changed index 6492\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 743  ntrees =  9997 \n",
      "best loss =  126978.458988 \n",
      "last loss =  126978.458988\n",
      "Validation loss: 135500.177147\n",
      "changed index 5297\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 744  ntrees =  9997 \n",
      "best loss =  126975.96132 \n",
      "last loss =  126975.96132\n",
      "Validation loss: 135501.252652\n",
      "changed index 1570\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 745  ntrees =  9997 \n",
      "best loss =  126973.46358 \n",
      "last loss =  126973.46358\n",
      "Validation loss: 135502.121123\n",
      "changed index 1766\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 746  ntrees =  9997 \n",
      "best loss =  126970.970438 \n",
      "last loss =  126970.970438\n",
      "Validation loss: 135506.744287\n",
      "changed index 472\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 747  ntrees =  9997 \n",
      "best loss =  126968.479583 \n",
      "last loss =  126968.479583\n",
      "Validation loss: 135505.856676\n",
      "changed index 1832\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 748  ntrees =  9997 \n",
      "best loss =  126965.987999 \n",
      "last loss =  126965.987999\n",
      "Validation loss: 135522.393372\n",
      "changed index 305\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 749  ntrees =  9997 \n",
      "best loss =  126963.496448 \n",
      "last loss =  126963.496448\n",
      "Validation loss: 135523.021856\n",
      "changed index 5561\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 750  ntrees =  9997 \n",
      "best loss =  126961.009917 \n",
      "last loss =  126961.009917\n",
      "Validation loss: 135521.263348\n",
      "changed index 7156\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 751  ntrees =  9997 \n",
      "best loss =  126958.521936 \n",
      "last loss =  126958.521936\n",
      "Validation loss: 135521.521522\n",
      "changed index 6687\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 752  ntrees =  9997 \n",
      "best loss =  126956.034716 \n",
      "last loss =  126956.034716\n",
      "Validation loss: 135520.647456\n",
      "changed index 1397\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 753  ntrees =  9997 \n",
      "best loss =  126953.552719 \n",
      "last loss =  126953.552719\n",
      "Validation loss: 135520.591718\n",
      "changed index 9687\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 754  ntrees =  9997 \n",
      "best loss =  126951.068013 \n",
      "last loss =  126951.068013\n",
      "Validation loss: 135520.659838\n",
      "changed index 6506\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 755  ntrees =  9997 \n",
      "best loss =  126948.590013 \n",
      "last loss =  126948.590013\n",
      "Validation loss: 135520.811627\n",
      "changed index 6573\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 756  ntrees =  9997 \n",
      "best loss =  126946.107941 \n",
      "last loss =  126946.107941\n",
      "Validation loss: 135521.121017\n",
      "changed index 1690\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 757  ntrees =  9997 \n",
      "best loss =  126943.629485 \n",
      "last loss =  126943.629485\n",
      "Validation loss: 135521.313674\n",
      "changed index 2420\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 758  ntrees =  9997 \n",
      "best loss =  126941.148637 \n",
      "last loss =  126941.148637\n",
      "Validation loss: 135521.929322\n",
      "changed index 7013\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 759  ntrees =  9997 \n",
      "best loss =  126938.675524 \n",
      "last loss =  126938.675524\n",
      "Validation loss: 135522.809936\n",
      "changed index 9291\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 760  ntrees =  9997 \n",
      "best loss =  126936.202237 \n",
      "last loss =  126936.202237\n",
      "Validation loss: 135521.676601\n",
      "changed index 9126\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 761  ntrees =  9997 \n",
      "best loss =  126933.727017 \n",
      "last loss =  126933.727017\n",
      "Validation loss: 135522.637257\n",
      "changed index 9901\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 762  ntrees =  9997 \n",
      "best loss =  126931.255895 \n",
      "last loss =  126931.255895\n",
      "Validation loss: 135522.810408\n",
      "changed index 4270\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 763  ntrees =  9997 \n",
      "best loss =  126928.781248 \n",
      "last loss =  126928.781248\n",
      "Validation loss: 135522.603437\n",
      "changed index 7306\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 764  ntrees =  9997 \n",
      "best loss =  126926.312747 \n",
      "last loss =  126926.312747\n",
      "Validation loss: 135522.58193\n",
      "changed index 8524\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 765  ntrees =  9997 \n",
      "best loss =  126923.841506 \n",
      "last loss =  126923.841506\n",
      "Validation loss: 135522.166038\n",
      "changed index 9106\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 766  ntrees =  9997 \n",
      "best loss =  126921.373451 \n",
      "last loss =  126921.373451\n",
      "Validation loss: 135522.271076\n",
      "changed index 895\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 767  ntrees =  9997 \n",
      "best loss =  126918.905994 \n",
      "last loss =  126918.905994\n",
      "Validation loss: 135523.803245\n",
      "changed index 6178\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 768  ntrees =  9997 \n",
      "best loss =  126916.442355 \n",
      "last loss =  126916.442355\n",
      "Validation loss: 135524.035476\n",
      "changed index 5066\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 769  ntrees =  9997 \n",
      "best loss =  126913.974576 \n",
      "last loss =  126913.974576\n",
      "Validation loss: 135524.403506\n",
      "changed index 5318\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 770  ntrees =  9997 \n",
      "best loss =  126911.512616 \n",
      "last loss =  126911.512616\n",
      "Validation loss: 135523.835298\n",
      "changed index 2117\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 771  ntrees =  9997 \n",
      "best loss =  126909.051267 \n",
      "last loss =  126909.051267\n",
      "Validation loss: 135523.874601\n",
      "changed index 1369\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 772  ntrees =  9997 \n",
      "best loss =  126906.591473 \n",
      "last loss =  126906.591473\n",
      "Validation loss: 135524.9643\n",
      "changed index 8914\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 773  ntrees =  9997 \n",
      "best loss =  126904.13207 \n",
      "last loss =  126904.13207\n",
      "Validation loss: 135524.75548\n",
      "changed index 1662\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 774  ntrees =  9997 \n",
      "best loss =  126901.673876 \n",
      "last loss =  126901.673876\n",
      "Validation loss: 135525.172525\n",
      "changed index 8585\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 775  ntrees =  9997 \n",
      "best loss =  126899.216458 \n",
      "last loss =  126899.216458\n",
      "Validation loss: 135523.56125\n",
      "changed index 7635\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 776  ntrees =  9997 \n",
      "best loss =  126896.761201 \n",
      "last loss =  126896.761201\n",
      "Validation loss: 135523.136481\n",
      "changed index 8597\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 777  ntrees =  9997 \n",
      "best loss =  126894.309813 \n",
      "last loss =  126894.309813\n",
      "Validation loss: 135523.609051\n",
      "changed index 6613\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 778  ntrees =  9997 \n",
      "best loss =  126891.855566 \n",
      "last loss =  126891.855566\n",
      "Validation loss: 135522.963716\n",
      "changed index 4649\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 779  ntrees =  9997 \n",
      "best loss =  126889.401076 \n",
      "last loss =  126889.401076\n",
      "Validation loss: 135523.940894\n",
      "changed index 8155\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 780  ntrees =  9997 \n",
      "best loss =  126886.946582 \n",
      "last loss =  126886.946582\n",
      "Validation loss: 135525.047395\n",
      "changed index 1864\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 781  ntrees =  9997 \n",
      "best loss =  126884.497481 \n",
      "last loss =  126884.497481\n",
      "Validation loss: 135524.695775\n",
      "changed index 401\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 782  ntrees =  9997 \n",
      "best loss =  126882.047429 \n",
      "last loss =  126882.047429\n",
      "Validation loss: 135523.527504\n",
      "changed index 5425\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 783  ntrees =  9997 \n",
      "best loss =  126879.596557 \n",
      "last loss =  126879.596557\n",
      "Validation loss: 135525.237613\n",
      "changed index 6831\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 784  ntrees =  9997 \n",
      "best loss =  126877.149245 \n",
      "last loss =  126877.149245\n",
      "Validation loss: 135525.810367\n",
      "changed index 9948\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 785  ntrees =  9997 \n",
      "best loss =  126874.704065 \n",
      "last loss =  126874.704065\n",
      "Validation loss: 135526.178322\n",
      "changed index 3020\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 786  ntrees =  9997 \n",
      "best loss =  126872.259826 \n",
      "last loss =  126872.259826\n",
      "Validation loss: 135527.97778\n",
      "changed index 6706\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 787  ntrees =  9997 \n",
      "best loss =  126869.819031 \n",
      "last loss =  126869.819031\n",
      "Validation loss: 135528.864155\n",
      "changed index 1652\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 788  ntrees =  9997 \n",
      "best loss =  126867.376441 \n",
      "last loss =  126867.376441\n",
      "Validation loss: 135530.150773\n",
      "changed index 5489\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 789  ntrees =  9997 \n",
      "best loss =  126864.937642 \n",
      "last loss =  126864.937642\n",
      "Validation loss: 135528.352275\n",
      "changed index 6612\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 790  ntrees =  9997 \n",
      "best loss =  126862.497751 \n",
      "last loss =  126862.497751\n",
      "Validation loss: 135528.447765\n",
      "changed index 1639\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 791  ntrees =  9997 \n",
      "best loss =  126860.05986 \n",
      "last loss =  126860.05986\n",
      "Validation loss: 135528.095679\n",
      "changed index 5357\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 792  ntrees =  9997 \n",
      "best loss =  126857.618529 \n",
      "last loss =  126857.618529\n",
      "Validation loss: 135598.993977\n",
      "changed index 138\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 793  ntrees =  9997 \n",
      "best loss =  126855.180765 \n",
      "last loss =  126855.180765\n",
      "Validation loss: 135598.692351\n",
      "changed index 4957\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 794  ntrees =  9997 \n",
      "best loss =  126852.739877 \n",
      "last loss =  126852.739877\n",
      "Validation loss: 135597.674753\n",
      "changed index 8717\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 795  ntrees =  9997 \n",
      "best loss =  126850.308843 \n",
      "last loss =  126850.308843\n",
      "Validation loss: 135598.034871\n",
      "changed index 9897\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 796  ntrees =  9997 \n",
      "best loss =  126847.875172 \n",
      "last loss =  126847.875172\n",
      "Validation loss: 135597.86817\n",
      "changed index 7679\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 797  ntrees =  9997 \n",
      "best loss =  126845.445707 \n",
      "last loss =  126845.445707\n",
      "Validation loss: 135597.689422\n",
      "changed index 2787\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 798  ntrees =  9997 \n",
      "best loss =  126843.015543 \n",
      "last loss =  126843.015543\n",
      "Validation loss: 135598.169059\n",
      "changed index 5378\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 799  ntrees =  9997 \n",
      "best loss =  126840.591152 \n",
      "last loss =  126840.591152\n",
      "Validation loss: 135598.635664\n",
      "changed index 7583\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 800  ntrees =  9997 \n",
      "best loss =  126838.159695 \n",
      "last loss =  126838.159695\n",
      "Validation loss: 135598.373586\n",
      "changed index 8155\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 801  ntrees =  9997 \n",
      "best loss =  126835.734897 \n",
      "last loss =  126835.734897\n",
      "Validation loss: 135598.091284\n",
      "changed index 8675\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 802  ntrees =  9997 \n",
      "best loss =  126833.311136 \n",
      "last loss =  126833.311136\n",
      "Validation loss: 135599.813613\n",
      "changed index 2036\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 803  ntrees =  9997 \n",
      "best loss =  126830.88413 \n",
      "last loss =  126830.88413\n",
      "Validation loss: 135598.958236\n",
      "changed index 9545\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 804  ntrees =  9997 \n",
      "best loss =  126828.46086 \n",
      "last loss =  126828.46086\n",
      "Validation loss: 135622.177226\n",
      "changed index 261\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 805  ntrees =  9997 \n",
      "best loss =  126826.036194 \n",
      "last loss =  126826.036194\n",
      "Validation loss: 135622.862606\n",
      "changed index 6110\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 806  ntrees =  9997 \n",
      "best loss =  126823.617839 \n",
      "last loss =  126823.617839\n",
      "Validation loss: 135622.486814\n",
      "changed index 7209\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 807  ntrees =  9997 \n",
      "best loss =  126821.191699 \n",
      "last loss =  126821.191699\n",
      "Validation loss: 135622.056815\n",
      "changed index 7151\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 808  ntrees =  9997 \n",
      "best loss =  126818.772097 \n",
      "last loss =  126818.772097\n",
      "Validation loss: 135621.642386\n",
      "changed index 6785\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 809  ntrees =  9997 \n",
      "best loss =  126816.353117 \n",
      "last loss =  126816.353117\n",
      "Validation loss: 135621.133933\n",
      "changed index 7219\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 810  ntrees =  9997 \n",
      "best loss =  126813.93088 \n",
      "last loss =  126813.93088\n",
      "Validation loss: 135621.665274\n",
      "changed index 3195\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 811  ntrees =  9997 \n",
      "best loss =  126811.51209 \n",
      "last loss =  126811.51209\n",
      "Validation loss: 135621.658728\n",
      "changed index 5616\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 812  ntrees =  9997 \n",
      "best loss =  126809.095248 \n",
      "last loss =  126809.095248\n",
      "Validation loss: 135621.240664\n",
      "changed index 4432\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 813  ntrees =  9997 \n",
      "best loss =  126806.678169 \n",
      "last loss =  126806.678169\n",
      "Validation loss: 135621.110636\n",
      "changed index 4719\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 814  ntrees =  9997 \n",
      "best loss =  126804.264315 \n",
      "last loss =  126804.264315\n",
      "Validation loss: 135621.772163\n",
      "changed index 4001\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 815  ntrees =  9997 \n",
      "best loss =  126801.851712 \n",
      "last loss =  126801.851712\n",
      "Validation loss: 135622.548107\n",
      "changed index 2017\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 816  ntrees =  9997 \n",
      "best loss =  126799.441707 \n",
      "last loss =  126799.441707\n",
      "Validation loss: 135622.566917\n",
      "changed index 9035\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 817  ntrees =  9997 \n",
      "best loss =  126797.035698 \n",
      "last loss =  126797.035698\n",
      "Validation loss: 135624.877054\n",
      "changed index 760\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 818  ntrees =  9997 \n",
      "best loss =  126794.634218 \n",
      "last loss =  126794.634218\n",
      "Validation loss: 135625.491751\n",
      "changed index 4655\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 819  ntrees =  9997 \n",
      "best loss =  126792.223308 \n",
      "last loss =  126792.223308\n",
      "Validation loss: 135627.256831\n",
      "changed index 1037\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 820  ntrees =  9997 \n",
      "best loss =  126789.817299 \n",
      "last loss =  126789.817299\n",
      "Validation loss: 135627.075551\n",
      "changed index 7765\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 821  ntrees =  9997 \n",
      "best loss =  126787.411671 \n",
      "last loss =  126787.411671\n",
      "Validation loss: 135628.251944\n",
      "changed index 6424\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 822  ntrees =  9997 \n",
      "best loss =  126785.008011 \n",
      "last loss =  126785.008011\n",
      "Validation loss: 135628.422249\n",
      "changed index 4844\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 823  ntrees =  9997 \n",
      "best loss =  126782.604022 \n",
      "last loss =  126782.604022\n",
      "Validation loss: 135628.497091\n",
      "changed index 7351\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 824  ntrees =  9997 \n",
      "best loss =  126780.197509 \n",
      "last loss =  126780.197509\n",
      "Validation loss: 135629.01536\n",
      "changed index 3728\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 825  ntrees =  9997 \n",
      "best loss =  126777.799485 \n",
      "last loss =  126777.799485\n",
      "Validation loss: 135629.907944\n",
      "changed index 1611\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 826  ntrees =  9997 \n",
      "best loss =  126775.39893 \n",
      "last loss =  126775.39893\n",
      "Validation loss: 135631.270541\n",
      "changed index 6179\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 827  ntrees =  9997 \n",
      "best loss =  126773.002136 \n",
      "last loss =  126773.002136\n",
      "Validation loss: 135632.997475\n",
      "changed index 9076\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 828  ntrees =  9997 \n",
      "best loss =  126770.600606 \n",
      "last loss =  126770.600606\n",
      "Validation loss: 135633.317217\n",
      "changed index 4326\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 829  ntrees =  9997 \n",
      "best loss =  126768.206659 \n",
      "last loss =  126768.206659\n",
      "Validation loss: 135633.896621\n",
      "changed index 8611\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 830  ntrees =  9997 \n",
      "best loss =  126765.801535 \n",
      "last loss =  126765.801535\n",
      "Validation loss: 135634.172544\n",
      "changed index 6851\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 831  ntrees =  9997 \n",
      "best loss =  126763.399452 \n",
      "last loss =  126763.399452\n",
      "Validation loss: 135633.111863\n",
      "changed index 2459\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 832  ntrees =  9997 \n",
      "best loss =  126760.998805 \n",
      "last loss =  126760.998805\n",
      "Validation loss: 135633.768895\n",
      "changed index 8381\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 833  ntrees =  9997 \n",
      "best loss =  126758.602311 \n",
      "last loss =  126758.602311\n",
      "Validation loss: 135634.125367\n",
      "changed index 9264\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 834  ntrees =  9997 \n",
      "best loss =  126756.212026 \n",
      "last loss =  126756.212026\n",
      "Validation loss: 135634.397437\n",
      "changed index 8278\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 835  ntrees =  9997 \n",
      "best loss =  126753.820739 \n",
      "last loss =  126753.820739\n",
      "Validation loss: 135633.51202\n",
      "changed index 4568\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 836  ntrees =  9997 \n",
      "best loss =  126751.43052 \n",
      "last loss =  126751.43052\n",
      "Validation loss: 135633.092796\n",
      "changed index 6154\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 837  ntrees =  9997 \n",
      "best loss =  126749.044744 \n",
      "last loss =  126749.044744\n",
      "Validation loss: 135633.750672\n",
      "changed index 2312\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 838  ntrees =  9997 \n",
      "best loss =  126746.656611 \n",
      "last loss =  126746.656611\n",
      "Validation loss: 135633.475327\n",
      "changed index 1213\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 839  ntrees =  9997 \n",
      "best loss =  126744.260709 \n",
      "last loss =  126744.260709\n",
      "Validation loss: 135632.861561\n",
      "changed index 6565\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 840  ntrees =  9997 \n",
      "best loss =  126741.878385 \n",
      "last loss =  126741.878385\n",
      "Validation loss: 135632.474078\n",
      "changed index 4536\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 841  ntrees =  9997 \n",
      "best loss =  126739.492936 \n",
      "last loss =  126739.492936\n",
      "Validation loss: 135632.536418\n",
      "changed index 7573\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 842  ntrees =  9997 \n",
      "best loss =  126737.107159 \n",
      "last loss =  126737.107159\n",
      "Validation loss: 135632.207566\n",
      "changed index 3815\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 843  ntrees =  9997 \n",
      "best loss =  126734.724828 \n",
      "last loss =  126734.724828\n",
      "Validation loss: 135633.132198\n",
      "changed index 2660\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 844  ntrees =  9997 \n",
      "best loss =  126732.340747 \n",
      "last loss =  126732.340747\n",
      "Validation loss: 135633.624948\n",
      "changed index 3633\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 845  ntrees =  9997 \n",
      "best loss =  126729.958953 \n",
      "last loss =  126729.958953\n",
      "Validation loss: 135632.099852\n",
      "changed index 5204\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 846  ntrees =  9997 \n",
      "best loss =  126727.580063 \n",
      "last loss =  126727.580063\n",
      "Validation loss: 135632.410116\n",
      "changed index 3814\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 847  ntrees =  9997 \n",
      "best loss =  126725.203701 \n",
      "last loss =  126725.203701\n",
      "Validation loss: 135632.548105\n",
      "changed index 8376\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 848  ntrees =  9997 \n",
      "best loss =  126722.823985 \n",
      "last loss =  126722.823985\n",
      "Validation loss: 135631.825803\n",
      "changed index 4198\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 849  ntrees =  9997 \n",
      "best loss =  126720.44729 \n",
      "last loss =  126720.44729\n",
      "Validation loss: 135631.254492\n",
      "changed index 9520\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 850  ntrees =  9997 \n",
      "best loss =  126718.069093 \n",
      "last loss =  126718.069093\n",
      "Validation loss: 135631.436016\n",
      "changed index 6564\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 851  ntrees =  9997 \n",
      "best loss =  126715.693477 \n",
      "last loss =  126715.693477\n",
      "Validation loss: 135632.148263\n",
      "changed index 2818\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 852  ntrees =  9997 \n",
      "best loss =  126713.315223 \n",
      "last loss =  126713.315223\n",
      "Validation loss: 135632.687989\n",
      "changed index 3243\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 853  ntrees =  9997 \n",
      "best loss =  126710.940226 \n",
      "last loss =  126710.940226\n",
      "Validation loss: 135631.372232\n",
      "changed index 9970\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 854  ntrees =  9997 \n",
      "best loss =  126708.567842 \n",
      "last loss =  126708.567842\n",
      "Validation loss: 135632.105794\n",
      "changed index 8709\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 855  ntrees =  9997 \n",
      "best loss =  126706.193814 \n",
      "last loss =  126706.193814\n",
      "Validation loss: 135632.455982\n",
      "changed index 3997\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 856  ntrees =  9997 \n",
      "best loss =  126703.825523 \n",
      "last loss =  126703.825523\n",
      "Validation loss: 135634.17583\n",
      "changed index 3130\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 857  ntrees =  9997 \n",
      "best loss =  126701.455573 \n",
      "last loss =  126701.455573\n",
      "Validation loss: 135635.935714\n",
      "changed index 4483\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 858  ntrees =  9997 \n",
      "best loss =  126699.088878 \n",
      "last loss =  126699.088878\n",
      "Validation loss: 135635.673227\n",
      "changed index 6480\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 859  ntrees =  9997 \n",
      "best loss =  126696.72421 \n",
      "last loss =  126696.72421\n",
      "Validation loss: 135635.404115\n",
      "changed index 8400\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 860  ntrees =  9997 \n",
      "best loss =  126694.359096 \n",
      "last loss =  126694.359096\n",
      "Validation loss: 135635.424167\n",
      "changed index 2820\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 861  ntrees =  9997 \n",
      "best loss =  126691.992598 \n",
      "last loss =  126691.992598\n",
      "Validation loss: 135635.704353\n",
      "changed index 1933\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 862  ntrees =  9997 \n",
      "best loss =  126689.623794 \n",
      "last loss =  126689.623794\n",
      "Validation loss: 135635.686261\n",
      "changed index 2965\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 863  ntrees =  9997 \n",
      "best loss =  126687.258671 \n",
      "last loss =  126687.258671\n",
      "Validation loss: 135636.862529\n",
      "changed index 1014\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 864  ntrees =  9997 \n",
      "best loss =  126684.900818 \n",
      "last loss =  126684.900818\n",
      "Validation loss: 135636.542532\n",
      "changed index 2344\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 865  ntrees =  9997 \n",
      "best loss =  126682.538741 \n",
      "last loss =  126682.538741\n",
      "Validation loss: 135690.082453\n",
      "changed index 168\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 866  ntrees =  9997 \n",
      "best loss =  126680.183021 \n",
      "last loss =  126680.183021\n",
      "Validation loss: 135691.372903\n",
      "changed index 5536\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 867  ntrees =  9997 \n",
      "best loss =  126677.828251 \n",
      "last loss =  126677.828251\n",
      "Validation loss: 135690.517698\n",
      "changed index 1543\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 868  ntrees =  9997 \n",
      "best loss =  126675.473249 \n",
      "last loss =  126675.473249\n",
      "Validation loss: 135878.205643\n",
      "changed index 38\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 869  ntrees =  9997 \n",
      "best loss =  126673.123244 \n",
      "last loss =  126673.123244\n",
      "Validation loss: 135878.129441\n",
      "changed index 5948\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 870  ntrees =  9997 \n",
      "best loss =  126670.766776 \n",
      "last loss =  126670.766776\n",
      "Validation loss: 135880.183618\n",
      "changed index 3930\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 871  ntrees =  9997 \n",
      "best loss =  126668.414013 \n",
      "last loss =  126668.414013\n",
      "Validation loss: 135879.292257\n",
      "changed index 4472\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 872  ntrees =  9997 \n",
      "best loss =  126666.062611 \n",
      "last loss =  126666.062611\n",
      "Validation loss: 135879.775651\n",
      "changed index 4186\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 873  ntrees =  9997 \n",
      "best loss =  126663.70785 \n",
      "last loss =  126663.70785\n",
      "Validation loss: 135880.339536\n",
      "changed index 9271\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 874  ntrees =  9997 \n",
      "best loss =  126661.355345 \n",
      "last loss =  126661.355345\n",
      "Validation loss: 135880.53435\n",
      "changed index 4674\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 875  ntrees =  9997 \n",
      "best loss =  126659.004967 \n",
      "last loss =  126659.004967\n",
      "Validation loss: 135880.852441\n",
      "changed index 7921\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 876  ntrees =  9997 \n",
      "best loss =  126656.655361 \n",
      "last loss =  126656.655361\n",
      "Validation loss: 135880.507106\n",
      "changed index 5240\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 877  ntrees =  9997 \n",
      "best loss =  126654.306705 \n",
      "last loss =  126654.306705\n",
      "Validation loss: 135879.938104\n",
      "changed index 3950\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 878  ntrees =  9997 \n",
      "best loss =  126651.954973 \n",
      "last loss =  126651.954973\n",
      "Validation loss: 135879.857436\n",
      "changed index 2040\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 879  ntrees =  9997 \n",
      "best loss =  126649.60386 \n",
      "last loss =  126649.60386\n",
      "Validation loss: 135879.875727\n",
      "changed index 7685\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 880  ntrees =  9997 \n",
      "best loss =  126647.260207 \n",
      "last loss =  126647.260207\n",
      "Validation loss: 135883.780268\n",
      "changed index 7184\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 881  ntrees =  9997 \n",
      "best loss =  126644.915094 \n",
      "last loss =  126644.915094\n",
      "Validation loss: 135883.589196\n",
      "changed index 6676\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 882  ntrees =  9997 \n",
      "best loss =  126642.57127 \n",
      "last loss =  126642.57127\n",
      "Validation loss: 135884.309393\n",
      "changed index 3772\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 883  ntrees =  9997 \n",
      "best loss =  126640.230377 \n",
      "last loss =  126640.230377\n",
      "Validation loss: 135884.118411\n",
      "changed index 7262\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 884  ntrees =  9997 \n",
      "best loss =  126637.884874 \n",
      "last loss =  126637.884874\n",
      "Validation loss: 135883.902148\n",
      "changed index 4107\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 885  ntrees =  9997 \n",
      "best loss =  126635.544995 \n",
      "last loss =  126635.544995\n",
      "Validation loss: 135883.611355\n",
      "changed index 1926\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 886  ntrees =  9997 \n",
      "best loss =  126633.205168 \n",
      "last loss =  126633.205168\n",
      "Validation loss: 135884.306397\n",
      "changed index 2909\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 887  ntrees =  9997 \n",
      "best loss =  126630.863282 \n",
      "last loss =  126630.863282\n",
      "Validation loss: 135883.892522\n",
      "changed index 4501\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 888  ntrees =  9997 \n",
      "best loss =  126628.526537 \n",
      "last loss =  126628.526537\n",
      "Validation loss: 135886.114039\n",
      "changed index 9041\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 889  ntrees =  9997 \n",
      "best loss =  126626.185929 \n",
      "last loss =  126626.185929\n",
      "Validation loss: 135886.576845\n",
      "changed index 9844\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 890  ntrees =  9997 \n",
      "best loss =  126623.848102 \n",
      "last loss =  126623.848102\n",
      "Validation loss: 135886.409123\n",
      "changed index 9930\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 891  ntrees =  9997 \n",
      "best loss =  126621.513217 \n",
      "last loss =  126621.513217\n",
      "Validation loss: 135886.438656\n",
      "changed index 4165\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 892  ntrees =  9997 \n",
      "best loss =  126619.178514 \n",
      "last loss =  126619.178514\n",
      "Validation loss: 135886.255097\n",
      "changed index 824\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 893  ntrees =  9997 \n",
      "best loss =  126616.845284 \n",
      "last loss =  126616.845284\n",
      "Validation loss: 135887.612166\n",
      "changed index 682\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 894  ntrees =  9997 \n",
      "best loss =  126614.516382 \n",
      "last loss =  126614.516382\n",
      "Validation loss: 135888.062504\n",
      "changed index 6068\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 895  ntrees =  9997 \n",
      "best loss =  126612.183149 \n",
      "last loss =  126612.183149\n",
      "Validation loss: 135889.956658\n",
      "changed index 6232\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 896  ntrees =  9997 \n",
      "best loss =  126609.853071 \n",
      "last loss =  126609.853071\n",
      "Validation loss: 135890.626885\n",
      "changed index 1476\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 897  ntrees =  9997 \n",
      "best loss =  126607.523175 \n",
      "last loss =  126607.523175\n",
      "Validation loss: 135891.50166\n",
      "changed index 7695\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 898  ntrees =  9997 \n",
      "best loss =  126605.195578 \n",
      "last loss =  126605.195578\n",
      "Validation loss: 135892.037295\n",
      "changed index 1087\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 899  ntrees =  9997 \n",
      "best loss =  126602.86869 \n",
      "last loss =  126602.86869\n",
      "Validation loss: 135892.704901\n",
      "changed index 6031\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 900  ntrees =  9997 \n",
      "best loss =  126600.542958 \n",
      "last loss =  126600.542958\n",
      "Validation loss: 135912.94985\n",
      "changed index 303\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 901  ntrees =  9997 \n",
      "best loss =  126598.217052 \n",
      "last loss =  126598.217052\n",
      "Validation loss: 135912.761868\n",
      "changed index 3931\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 902  ntrees =  9997 \n",
      "best loss =  126595.888061 \n",
      "last loss =  126595.888061\n",
      "Validation loss: 135914.057795\n",
      "changed index 4207\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 903  ntrees =  9997 \n",
      "best loss =  126593.563569 \n",
      "last loss =  126593.563569\n",
      "Validation loss: 135913.234042\n",
      "changed index 8684\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 904  ntrees =  9997 \n",
      "best loss =  126591.237676 \n",
      "last loss =  126591.237676\n",
      "Validation loss: 135911.81422\n",
      "changed index 7174\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 905  ntrees =  9997 \n",
      "best loss =  126588.913987 \n",
      "last loss =  126588.913987\n",
      "Validation loss: 135911.690657\n",
      "changed index 8098\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 906  ntrees =  9997 \n",
      "best loss =  126586.592369 \n",
      "last loss =  126586.592369\n",
      "Validation loss: 135911.883006\n",
      "changed index 2425\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 907  ntrees =  9997 \n",
      "best loss =  126584.271593 \n",
      "last loss =  126584.271593\n",
      "Validation loss: 135911.672981\n",
      "changed index 7494\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 908  ntrees =  9997 \n",
      "best loss =  126581.949071 \n",
      "last loss =  126581.949071\n",
      "Validation loss: 135911.536989\n",
      "changed index 5571\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 909  ntrees =  9997 \n",
      "best loss =  126579.629566 \n",
      "last loss =  126579.629566\n",
      "Validation loss: 135911.73591\n",
      "changed index 2752\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 910  ntrees =  9997 \n",
      "best loss =  126577.310236 \n",
      "last loss =  126577.310236\n",
      "Validation loss: 135912.477614\n",
      "changed index 3008\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 911  ntrees =  9997 \n",
      "best loss =  126574.99433 \n",
      "last loss =  126574.99433\n",
      "Validation loss: 135912.463992\n",
      "changed index 9663\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 912  ntrees =  9997 \n",
      "best loss =  126572.684957 \n",
      "last loss =  126572.684957\n",
      "Validation loss: 135962.105894\n",
      "changed index 191\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 913  ntrees =  9997 \n",
      "best loss =  126570.37039 \n",
      "last loss =  126570.37039\n",
      "Validation loss: 136056.112117\n",
      "changed index 120\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 914  ntrees =  9997 \n",
      "best loss =  126568.052953 \n",
      "last loss =  126568.052953\n",
      "Validation loss: 136057.010676\n",
      "changed index 6920\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 915  ntrees =  9997 \n",
      "best loss =  126565.741892 \n",
      "last loss =  126565.741892\n",
      "Validation loss: 136056.592814\n",
      "changed index 2026\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 916  ntrees =  9997 \n",
      "best loss =  126563.430874 \n",
      "last loss =  126563.430874\n",
      "Validation loss: 136056.531141\n",
      "changed index 3376\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 917  ntrees =  9997 \n",
      "best loss =  126561.116639 \n",
      "last loss =  126561.116639\n",
      "Validation loss: 136057.044767\n",
      "changed index 4242\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 918  ntrees =  9997 \n",
      "best loss =  126558.805189 \n",
      "last loss =  126558.805189\n",
      "Validation loss: 136056.628318\n",
      "changed index 3817\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 919  ntrees =  9997 \n",
      "best loss =  126556.495815 \n",
      "last loss =  126556.495815\n",
      "Validation loss: 136056.017906\n",
      "changed index 9240\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 920  ntrees =  9997 \n",
      "best loss =  126554.18387 \n",
      "last loss =  126554.18387\n",
      "Validation loss: 136056.796757\n",
      "changed index 3953\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 921  ntrees =  9997 \n",
      "best loss =  126551.876484 \n",
      "last loss =  126551.876484\n",
      "Validation loss: 136057.731833\n",
      "changed index 4909\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 922  ntrees =  9997 \n",
      "best loss =  126549.567461 \n",
      "last loss =  126549.567461\n",
      "Validation loss: 136057.978147\n",
      "changed index 7987\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 923  ntrees =  9997 \n",
      "best loss =  126547.26248 \n",
      "last loss =  126547.26248\n",
      "Validation loss: 136057.431626\n",
      "changed index 3943\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 924  ntrees =  9997 \n",
      "best loss =  126544.956927 \n",
      "last loss =  126544.956927\n",
      "Validation loss: 136057.01214\n",
      "changed index 3810\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 925  ntrees =  9997 \n",
      "best loss =  126542.65256 \n",
      "last loss =  126542.65256\n",
      "Validation loss: 136057.670616\n",
      "changed index 5275\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 926  ntrees =  9997 \n",
      "best loss =  126540.343071 \n",
      "last loss =  126540.343071\n",
      "Validation loss: 136057.266456\n",
      "changed index 4200\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 927  ntrees =  9997 \n",
      "best loss =  126538.037785 \n",
      "last loss =  126538.037785\n",
      "Validation loss: 136056.744277\n",
      "changed index 8907\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 928  ntrees =  9997 \n",
      "best loss =  126535.735237 \n",
      "last loss =  126535.735237\n",
      "Validation loss: 136056.473983\n",
      "changed index 8525\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 929  ntrees =  9997 \n",
      "best loss =  126533.433151 \n",
      "last loss =  126533.433151\n",
      "Validation loss: 136055.805493\n",
      "changed index 4449\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 930  ntrees =  9997 \n",
      "best loss =  126531.129771 \n",
      "last loss =  126531.129771\n",
      "Validation loss: 136055.258652\n",
      "changed index 3343\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 931  ntrees =  9997 \n",
      "best loss =  126528.828038 \n",
      "last loss =  126528.828038\n",
      "Validation loss: 136054.130991\n",
      "changed index 6546\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 932  ntrees =  9997 \n",
      "best loss =  126526.529384 \n",
      "last loss =  126526.529384\n",
      "Validation loss: 136053.5853\n",
      "changed index 4391\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 933  ntrees =  9997 \n",
      "best loss =  126524.228568 \n",
      "last loss =  126524.228568\n",
      "Validation loss: 136052.957857\n",
      "changed index 9051\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 934  ntrees =  9997 \n",
      "best loss =  126521.929163 \n",
      "last loss =  126521.929163\n",
      "Validation loss: 136053.002173\n",
      "changed index 7758\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 935  ntrees =  9997 \n",
      "best loss =  126519.632825 \n",
      "last loss =  126519.632825\n",
      "Validation loss: 136056.150812\n",
      "changed index 731\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 936  ntrees =  9997 \n",
      "best loss =  126517.340804 \n",
      "last loss =  126517.340804\n",
      "Validation loss: 136057.222463\n",
      "changed index 6540\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 937  ntrees =  9997 \n",
      "best loss =  126515.042346 \n",
      "last loss =  126515.042346\n",
      "Validation loss: 136057.12621\n",
      "changed index 9196\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 938  ntrees =  9997 \n",
      "best loss =  126512.746724 \n",
      "last loss =  126512.746724\n",
      "Validation loss: 136055.942718\n",
      "changed index 3549\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 939  ntrees =  9997 \n",
      "best loss =  126510.456071 \n",
      "last loss =  126510.456071\n",
      "Validation loss: 136058.09149\n",
      "changed index 7676\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 940  ntrees =  9997 \n",
      "best loss =  126508.1667 \n",
      "last loss =  126508.1667\n",
      "Validation loss: 136058.492002\n",
      "changed index 8508\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 941  ntrees =  9997 \n",
      "best loss =  126505.877357 \n",
      "last loss =  126505.877357\n",
      "Validation loss: 136059.074695\n",
      "changed index 7291\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 942  ntrees =  9997 \n",
      "best loss =  126503.588926 \n",
      "last loss =  126503.588926\n",
      "Validation loss: 136059.702418\n",
      "changed index 5790\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 943  ntrees =  9997 \n",
      "best loss =  126501.296351 \n",
      "last loss =  126501.296351\n",
      "Validation loss: 136059.944544\n",
      "changed index 2782\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 944  ntrees =  9997 \n",
      "best loss =  126499.010104 \n",
      "last loss =  126499.010104\n",
      "Validation loss: 136061.001116\n",
      "changed index 2633\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 945  ntrees =  9997 \n",
      "best loss =  126496.723467 \n",
      "last loss =  126496.723467\n",
      "Validation loss: 136061.391937\n",
      "changed index 5903\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 946  ntrees =  9997 \n",
      "best loss =  126494.437669 \n",
      "last loss =  126494.437669\n",
      "Validation loss: 136060.924033\n",
      "changed index 7647\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 947  ntrees =  9997 \n",
      "best loss =  126492.156099 \n",
      "last loss =  126492.156099\n",
      "Validation loss: 136143.687562\n",
      "changed index 136\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 948  ntrees =  9997 \n",
      "best loss =  126489.871014 \n",
      "last loss =  126489.871014\n",
      "Validation loss: 136144.494821\n",
      "changed index 4050\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 949  ntrees =  9997 \n",
      "best loss =  126487.587028 \n",
      "last loss =  126487.587028\n",
      "Validation loss: 136144.200658\n",
      "changed index 1644\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 950  ntrees =  9997 \n",
      "best loss =  126485.302651 \n",
      "last loss =  126485.302651\n",
      "Validation loss: 136144.069386\n",
      "changed index 7506\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 951  ntrees =  9997 \n",
      "best loss =  126483.026744 \n",
      "last loss =  126483.026744\n",
      "Validation loss: 136144.812344\n",
      "changed index 1955\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 952  ntrees =  9997 \n",
      "best loss =  126480.736817 \n",
      "last loss =  126480.736817\n",
      "Validation loss: 136151.203951\n",
      "changed index 416\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 953  ntrees =  9997 \n",
      "best loss =  126478.453862 \n",
      "last loss =  126478.453862\n",
      "Validation loss: 136150.816683\n",
      "changed index 4815\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 954  ntrees =  9997 \n",
      "best loss =  126476.170856 \n",
      "last loss =  126476.170856\n",
      "Validation loss: 136150.15085\n",
      "changed index 7831\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 955  ntrees =  9997 \n",
      "best loss =  126473.89019 \n",
      "last loss =  126473.89019\n",
      "Validation loss: 136150.397311\n",
      "changed index 4770\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 956  ntrees =  9997 \n",
      "best loss =  126471.611139 \n",
      "last loss =  126471.611139\n",
      "Validation loss: 136151.582443\n",
      "changed index 8392\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 957  ntrees =  9997 \n",
      "best loss =  126469.336292 \n",
      "last loss =  126469.336292\n",
      "Validation loss: 136151.559316\n",
      "changed index 2466\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 958  ntrees =  9997 \n",
      "best loss =  126467.064433 \n",
      "last loss =  126467.064433\n",
      "Validation loss: 136151.372265\n",
      "changed index 5984\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 959  ntrees =  9997 \n",
      "best loss =  126464.78795 \n",
      "last loss =  126464.78795\n",
      "Validation loss: 136151.90892\n",
      "changed index 7970\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 960  ntrees =  9997 \n",
      "best loss =  126462.511573 \n",
      "last loss =  126462.511573\n",
      "Validation loss: 136150.730292\n",
      "changed index 9080\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 961  ntrees =  9997 \n",
      "best loss =  126460.235861 \n",
      "last loss =  126460.235861\n",
      "Validation loss: 136152.742277\n",
      "changed index 4716\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 962  ntrees =  9997 \n",
      "best loss =  126457.966983 \n",
      "last loss =  126457.966983\n",
      "Validation loss: 136153.926254\n",
      "changed index 1935\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 963  ntrees =  9997 \n",
      "best loss =  126455.693866 \n",
      "last loss =  126455.693866\n",
      "Validation loss: 136154.815591\n",
      "changed index 1780\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 964  ntrees =  9997 \n",
      "best loss =  126453.422103 \n",
      "last loss =  126453.422103\n",
      "Validation loss: 136154.28338\n",
      "changed index 1382\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 965  ntrees =  9997 \n",
      "best loss =  126451.152833 \n",
      "last loss =  126451.152833\n",
      "Validation loss: 136153.907736\n",
      "changed index 7901\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 966  ntrees =  9997 \n",
      "best loss =  126448.884391 \n",
      "last loss =  126448.884391\n",
      "Validation loss: 136154.961012\n",
      "changed index 1882\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 967  ntrees =  9997 \n",
      "best loss =  126446.611435 \n",
      "last loss =  126446.611435\n",
      "Validation loss: 136157.140188\n",
      "changed index 1756\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 968  ntrees =  9997 \n",
      "best loss =  126444.341498 \n",
      "last loss =  126444.341498\n",
      "Validation loss: 136156.817771\n",
      "changed index 5291\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 969  ntrees =  9997 \n",
      "best loss =  126442.074821 \n",
      "last loss =  126442.074821\n",
      "Validation loss: 136156.013225\n",
      "changed index 1957\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 970  ntrees =  9997 \n",
      "best loss =  126439.805106 \n",
      "last loss =  126439.805106\n",
      "Validation loss: 136304.536078\n",
      "changed index 77\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 971  ntrees =  9997 \n",
      "best loss =  126437.542592 \n",
      "last loss =  126437.542592\n",
      "Validation loss: 136301.666932\n",
      "changed index 967\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 972  ntrees =  9997 \n",
      "best loss =  126435.27949 \n",
      "last loss =  126435.27949\n",
      "Validation loss: 136303.139039\n",
      "changed index 8971\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 973  ntrees =  9997 \n",
      "best loss =  126433.015301 \n",
      "last loss =  126433.015301\n",
      "Validation loss: 136304.091802\n",
      "changed index 2085\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 974  ntrees =  9997 \n",
      "best loss =  126430.750738 \n",
      "last loss =  126430.750738\n",
      "Validation loss: 136359.343345\n",
      "changed index 192\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 975  ntrees =  9997 \n",
      "best loss =  126428.484457 \n",
      "last loss =  126428.484457\n",
      "Validation loss: 136361.012505\n",
      "changed index 1338\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 976  ntrees =  9997 \n",
      "best loss =  126426.221405 \n",
      "last loss =  126426.221405\n",
      "Validation loss: 136360.648878\n",
      "changed index 8114\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 977  ntrees =  9997 \n",
      "best loss =  126423.959952 \n",
      "last loss =  126423.959952\n",
      "Validation loss: 136360.611636\n",
      "changed index 2397\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 978  ntrees =  9997 \n",
      "best loss =  126421.699708 \n",
      "last loss =  126421.699708\n",
      "Validation loss: 136360.724178\n",
      "changed index 3383\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 979  ntrees =  9997 \n",
      "best loss =  126419.443937 \n",
      "last loss =  126419.443937\n",
      "Validation loss: 136360.977124\n",
      "changed index 5078\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 980  ntrees =  9997 \n",
      "best loss =  126417.190458 \n",
      "last loss =  126417.190458\n",
      "Validation loss: 136360.703374\n",
      "changed index 6837\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 981  ntrees =  9997 \n",
      "best loss =  126414.933718 \n",
      "last loss =  126414.933718\n",
      "Validation loss: 136361.096611\n",
      "changed index 1884\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 982  ntrees =  9997 \n",
      "best loss =  126412.677778 \n",
      "last loss =  126412.677778\n",
      "Validation loss: 136361.43629\n",
      "changed index 4628\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 983  ntrees =  9997 \n",
      "best loss =  126410.42607 \n",
      "last loss =  126410.42607\n",
      "Validation loss: 136360.900174\n",
      "changed index 9546\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 984  ntrees =  9997 \n",
      "best loss =  126408.175903 \n",
      "last loss =  126408.175903\n",
      "Validation loss: 136362.788874\n",
      "changed index 3673\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 985  ntrees =  9997 \n",
      "best loss =  126405.926825 \n",
      "last loss =  126405.926825\n",
      "Validation loss: 136363.705753\n",
      "changed index 2579\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 986  ntrees =  9997 \n",
      "best loss =  126403.67629 \n",
      "last loss =  126403.67629\n",
      "Validation loss: 136364.798697\n",
      "changed index 9699\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 987  ntrees =  9997 \n",
      "best loss =  126401.423647 \n",
      "last loss =  126401.423647\n",
      "Validation loss: 136364.833171\n",
      "changed index 8415\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 988  ntrees =  9997 \n",
      "best loss =  126399.17497 \n",
      "last loss =  126399.17497\n",
      "Validation loss: 136364.882623\n",
      "changed index 6418\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 989  ntrees =  9997 \n",
      "best loss =  126396.929196 \n",
      "last loss =  126396.929196\n",
      "Validation loss: 136364.496512\n",
      "changed index 9367\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 990  ntrees =  9997 \n",
      "best loss =  126394.67963 \n",
      "last loss =  126394.67963\n",
      "Validation loss: 136364.395248\n",
      "changed index 2155\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 991  ntrees =  9997 \n",
      "best loss =  126392.435315 \n",
      "last loss =  126392.435315\n",
      "Validation loss: 136366.091012\n",
      "changed index 3391\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 992  ntrees =  9997 \n",
      "best loss =  126390.191223 \n",
      "last loss =  126390.191223\n",
      "Validation loss: 136366.003071\n",
      "changed index 7959\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 993  ntrees =  9997 \n",
      "best loss =  126387.940805 \n",
      "last loss =  126387.940805\n",
      "Validation loss: 136366.122373\n",
      "changed index 7702\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 994  ntrees =  9997 \n",
      "best loss =  126385.694081 \n",
      "last loss =  126385.694081\n",
      "Validation loss: 136367.653585\n",
      "changed index 3162\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 995  ntrees =  9997 \n",
      "best loss =  126383.451012 \n",
      "last loss =  126383.451012\n",
      "Validation loss: 136368.112987\n",
      "changed index 6704\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 996  ntrees =  9997 \n",
      "best loss =  126381.211287 \n",
      "last loss =  126381.211287\n",
      "Validation loss: 136368.98464\n",
      "changed index 2156\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 997  ntrees =  9997 \n",
      "best loss =  126378.968091 \n",
      "last loss =  126378.968091\n",
      "Validation loss: 136369.234712\n",
      "changed index 1588\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 998  ntrees =  9997 \n",
      "best loss =  126376.728368 \n",
      "last loss =  126376.728368\n",
      "Validation loss: 136369.654043\n",
      "changed index 5931\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 999  ntrees =  9997 \n",
      "best loss =  126374.489173 \n",
      "last loss =  126374.489173\n",
      "Validation loss: 136370.124388\n",
      "changed index 950\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "\n",
      "iteration # 1000  ntrees =  9997 \n",
      "best loss =  126372.250938 \n",
      "last loss =  126372.250938\n",
      "Validation loss: 136371.139549\n",
      "changed index 5255\n",
      "learning_rate =  0.0099\n",
      "sample_size 3000\n",
      "Validation scores history:\n",
      "CPU times: user 11h 7min 19s, sys: 45min 53s, total: 11h 53min 12s\n",
      "Wall time: 3h 43min 12s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEACAYAAAByG0uxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3be4110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "initial = pf(trees[:10000])\n",
    "read = False\n",
    "fname=\"../dumps/last_whl_val.pcl\"\n",
    "if not read:\n",
    "    trees_greedy = greedy.wheel_up_features_bfs(\n",
    "                                    initial,\n",
    "                                    trees,            #все деревья\n",
    "                                    trainFactory,                 #данные\n",
    "                                    loss = MSELoss,               #функция потерь\n",
    "                                    learning_rate = .0099,          #шаг обучения\n",
    "                                    nIters = 1000,      #итоговый размер формулы\n",
    "                                    trees_sample_size =3000,       #размер подвыборки деревьев на каждой итерации\n",
    "                                    verbose = 2,              #логи\n",
    "                                    vali_factory = testFactory,\n",
    "                                    regularizer=0.000005*len(trainFactory.labels), #Регуляризатор значения в листе(аддитивно к знаменателю)\n",
    "                                    use_joblib=True,#global_use_joblib, #использовать ли многопоточность\n",
    "                                    n_jobs=4,         #Число потоков(joblib)\n",
    "                                                )\n",
    "    cDump(trees_greedy,fname)\n",
    "else:\n",
    "    trees_greedy = cLoad(fname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_greedy.pcl\r\n",
      "last_greedy_1k.pcl\r\n",
      "last_greedy_1k_lr.05.pcl\r\n",
      "last_greedy_1k_lr.25.pcl\r\n",
      "last_greedy_from500k.pcl\r\n",
      "last_grid.pcl\r\n",
      "last_grid2.pcl\r\n",
      "last_hierarchy.05.pcl\r\n",
      "last_hierarchy.pcl\r\n",
      "last_splitted.pcl\r\n",
      "last_splitted2.pcl\r\n",
      "last_structure.pcl\r\n",
      "last_whl.pcl\r\n",
      "lastssplitted.pcl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../dumps | grep last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простой жадный прунинг\n",
    "\n",
    "Итеративно берём подвыборку деревьев из оригинальной формулы, перевычисляем значения в листьях и выбираем лучшее дерево в смысле MSE вместе с деревьями, выбранными на предыдущих итерациях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import greedy #модуль, который умеет делать жадный прунинг\n",
    "from loss_functions import MSELoss #функция потерь для него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 ms, sys: 0 ns, total: 21.4 ms\n",
      "Wall time: 22.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read = True\n",
    "fname=\"../dumps/last_greedy.pcl\"\n",
    "if not read:\n",
    "    trees_greedy = greedy.greed_up_features_bfs(trees,            #все деревья\n",
    "                                    trainFactory,                 #данные\n",
    "                                    loss = MSELoss,               #функция потерь\n",
    "                                    learning_rate = .35,          #шаг обучения\n",
    "                                    nTrees = target_n_trees,      #итоговый размер формулы\n",
    "                                    trees_sample_size =1000,       #размер подвыборки деревьев на каждой итерации\n",
    "                                    verbose = False,              #логи\n",
    "                                    regularizer=0.0005*len(trainFactory.labels), #Регуляризатор значения в листе(аддитивно к знаменателю)\n",
    "                                    use_joblib=global_use_joblib, #использовать ли многопоточность\n",
    "                                    n_jobs=global_n_jobs,         #Число потоков(joblib)\n",
    "                                                )\n",
    "    cDump(trees_greedy,fname)\n",
    "else:\n",
    "    trees_greedy = cLoad(fname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_greedy = trees_greedy.predict(testFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563639784007 0.695731252371 0.554568902063\n",
      "well...\n"
     ]
    }
   ],
   "source": [
    "print metrics.mean_squared_error(testFactory.labels,y_pred_greedy),\n",
    "print metrics.mean_squared_error(testFactory.labels,y_pred_stupid),\n",
    "print metrics.mean_squared_error(testFactory.labels,y_pred_full)\n",
    "print \"well...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG@5\n",
      "greedy: 0.523375561899\n",
      "stupid: 0.449222985317\n",
      "full: 0.537504303084\n",
      "\n",
      "NDCG@10\n",
      "greedy: 0.529145210812\n",
      "stupid: 0.456648840525\n",
      "full: 0.543021161437\n",
      "\n",
      "NDCG@50\n",
      "greedy: 0.606894830854\n",
      "stupid: 0.55367057841\n",
      "full: 0.618088956755\n",
      "\n",
      "NDCG@None\n",
      "greedy: 0.751248862003\n",
      "stupid: 0.721413686091\n",
      "full: 0.757625718281\n"
     ]
    }
   ],
   "source": [
    "#NDCG\n",
    "from ranking_metrics import mean_ndcg\n",
    "for rank in [5,10,50,None]:\n",
    "    print \"\\nNDCG@\"+str(rank)\n",
    "    print 'greedy:',mean_ndcg(testFactory.labels,y_pred_greedy,testFactory.ids,rank = rank)\n",
    "    print 'stupid:',mean_ndcg(testFactory.labels,y_pred_stupid,testFactory.ids,rank = rank)\n",
    "    print 'full:',mean_ndcg(testFactory.labels,y_pred_full,testFactory.ids,rank = rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Кривые обучения по MSE\n",
    "Среднеквадратичная ошибка на тесте от числа деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_curve(formula,factory, metric,n_points = None):\n",
    "    \n",
    "    lcurve = []\n",
    "\n",
    "    Ypred = np.zeros(len(factory.labels))\n",
    "                  \n",
    "    for i,tree_pred in enumerate(formula.staged_predict(factory)):\n",
    "\n",
    "        Ypred += tree_pred\n",
    "        lcurve.append(metric(factory.labels, Ypred,sample_weight = factory.weights))\n",
    "        if n_points is not None and i >= n_points:\n",
    "            break\n",
    "    while n_points is not None and i < n_points:\n",
    "        i+=1\n",
    "        lcurve.append(lcurve[-1])\n",
    "        \n",
    "    return lcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x8c616d90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAM4CAYAAAAeRXcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsJEkSZLUeAYbSZIkSY33/wHi89HSQa80IgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8c5edb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_name = 'MSE'\n",
    "n_trees = target_n_trees\n",
    "metric = metrics.mean_squared_error\n",
    "\n",
    "stupid_lcurve = learning_curve(trees_stupid,testFactory,metric,n_trees)\n",
    "greedy_lcurve = learning_curve(trees_greedy,testFactory,metric,n_trees)\n",
    "\n",
    "full_line = metric(testFactory.labels,y_pred_full)\n",
    "\n",
    "p = range(n_trees+1)\n",
    "\n",
    "plt.figure(figsize = [14,14])\n",
    "plt.plot(p,[full_line for i in p],label = \"full 10k ensemble\")\n",
    "plt.plot(p,[0.568 for i in p],label = \"100-tree ensemble\")\n",
    "plt.plot(p,stupid_lcurve,label = \"original ensemble\")\n",
    "plt.plot(p,greedy_lcurve,label = \"greedy pruning\")\n",
    "plt.title('learning curves('+metric_name+')')\n",
    "plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#побольше-пожирнее\n",
    "Отпрунена модель на 1к деревьев. Параметры не подбирал, Learning rate = 0.15 явный перебор, но всё равно качество неплохое. Хотя имхо пока оно проигрывает идеально подобранной по параметрам новой формуле, но это правится нормальным learning-rate-ом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 0 ns, total: 103 ms\n",
      "Wall time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read = True\n",
    "fname=\"../dumps/last_greedy_1k.pcl\"\n",
    "if not read:\n",
    "    trees_greedy_1k = greedy.greed_up_features_bfs(trees,            #все деревья\n",
    "                                    trainFactory,                 #данные\n",
    "                                    loss = MSELoss,               #функция потерь\n",
    "                                    learning_rate = .25,          #шаг обучения\n",
    "                                    nTrees = 1000,#target_n_trees,      #итоговый размер формулы\n",
    "                                    trees_sample_size =1000,       #размер подвыборки деревьев на каждой итерации\n",
    "                                    verbose = False,              #логи\n",
    "                                    regularizer=0.0005*len(trainFactory.labels), #Регуляризатор значения в листе(аддитивно к знаменателю)\n",
    "                                    use_joblib=global_use_joblib, #использовать ли многопоточность\n",
    "                                    n_jobs=global_n_jobs,         #Число потоков(joblib)\n",
    "                                                )\n",
    "    cDump(trees_greedy_1k,fname)\n",
    "else:\n",
    "    trees_greedy_1k = cLoad(fname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_greedy_1k.pcl\r\n",
      "last_greedy_1k_lr.05.pcl\r\n",
      "last_greedy_1k_lr.25.pcl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../dumps/ |grep last_greedy_1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_greedy_1k = trees_greedy_1k.predict(testFactory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees_stupid_1k = pf(trees[:1000],bias)\n",
    "y_pred_stupid_1k = trees_stupid_1k.predict(testFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-greedy  0.563639784007\n",
      "1k -greedy  0.556495018611\n",
      "1k original 0.57106185698\n",
      "10k original 0.554568902063\n",
      "well...\n"
     ]
    }
   ],
   "source": [
    "print '100-greedy ',metrics.mean_squared_error(testFactory.labels,y_pred_greedy)\n",
    "print '1k -greedy ',metrics.mean_squared_error(testFactory.labels,y_pred_greedy_1k)\n",
    "print '1k original',metrics.mean_squared_error(testFactory.labels,y_pred_stupid_1k)\n",
    "print '10k original',metrics.mean_squared_error(testFactory.labels,y_pred_full)\n",
    "print \"well...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG@5\n",
      "100-greedy  : 0.523375561899\n",
      "1k -greedy  : 0.534789116948\n",
      "1k original : 0.449222985317\n",
      "10k original: 0.537504303084\n",
      "\n",
      "NDCG@10\n",
      "100-greedy  : 0.529145210812\n",
      "1k -greedy  : 0.540499836139\n",
      "1k original : 0.456648840525\n",
      "10k original: 0.543021161437\n",
      "\n",
      "NDCG@50\n",
      "100-greedy  : 0.606894830854\n",
      "1k -greedy  : 0.616617041182\n",
      "1k original : 0.55367057841\n",
      "10k original: 0.618088956755\n",
      "\n",
      "NDCG@None\n",
      "100-greedy  : 0.751248862003\n",
      "1k -greedy  : 0.756525750361\n",
      "1k original : 0.721413686091\n",
      "10k original: 0.757625718281\n"
     ]
    }
   ],
   "source": [
    "#NDCG\n",
    "from ranking_metrics import mean_ndcg\n",
    "for rank in [5,10,50,None]:\n",
    "    print \"\\nNDCG@\"+str(rank)\n",
    "    print '100-greedy  :',mean_ndcg(testFactory.labels,y_pred_greedy,testFactory.ids,rank = rank)\n",
    "    print '1k -greedy  :',mean_ndcg(testFactory.labels,y_pred_greedy_1k,testFactory.ids,rank = rank)\n",
    "    print '1k original :',mean_ndcg(testFactory.labels,y_pred_stupid,testFactory.ids,rank = rank)\n",
    "    print '10k original:',mean_ndcg(testFactory.labels,y_pred_full,testFactory.ids,rank = rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x761c8890>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAM4CAYAAADvTiy8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x60c717d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_name = 'MSE'\n",
    "n_trees = 1000\n",
    "metric = metrics.mean_squared_error\n",
    "\n",
    "stupid_lcurve = learning_curve(trees_stupid_1k,testFactory,metric,n_trees)\n",
    "greedy_lcurve = learning_curve(trees_greedy_1k,testFactory,metric,n_trees)\n",
    "\n",
    "full_line = metric(testFactory.labels,y_pred_full)\n",
    "\n",
    "p = range(n_trees+1)\n",
    "\n",
    "plt.figure(figsize = [14,14])\n",
    "plt.plot(p,[full_line for i in p],label = \"full 10k ensemble\")\n",
    "plt.plot(p,stupid_lcurve,label = \"first 1k\")\n",
    "plt.plot(p,greedy_lcurve,label = \"1k pruned\")\n",
    "plt.title('learning curves('+metric_name+')')\n",
    "plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#отбор напрямую по dcg пока не \"зашёл\".\n",
    "Попытался сделать несколько различных извращений от отбора по NDCG до явного LAMBDAMART, все они не лучше (а  иногда хуже) MSE в пределах погрешности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from loss_functions import _MSEDCGLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSEDCGLoss = _MSEDCGLoss(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 ms, sys: 0 ns, total: 14.4 ms\n",
      "Wall time: 16.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read = True\n",
    "fname=\"../dumps/dcg_greedy.pcl\"\n",
    "if not read:\n",
    "    trees_greedy_dcg = greedy.greed_up_features_bfs(trees,            #все деревья\n",
    "                                    trainFactory,                 #данные\n",
    "                                    loss = MSEDCGLoss,               #функция потерь\n",
    "                                    learning_rate = .35,          #шаг обучения\n",
    "                                    nTrees = target_n_trees,      #итоговый размер формулы\n",
    "                                    trees_sample_size =100,       #размер подвыборки деревьев на каждой итерации\n",
    "                                    verbose = True,              #логи\n",
    "                                    regularizer=0.0005*len(trainFactory.labels), #Регуляризатор значения в листе(аддитивно к знаменателю)\n",
    "                                    use_joblib=global_use_joblib, #использовать ли многопоточность\n",
    "                                    n_jobs=global_n_jobs,         #Число потоков(joblib)\n",
    "                                                )\n",
    "    cDump(trees_greedy_dcg,fname)\n",
    "else:\n",
    "    trees_greedy_dcg = cLoad(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_dcg_greedy = trees_greedy_dcg.predict(testFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563639784007 0.568333774093 0.695731252371 0.554568902063\n",
      "well...\n"
     ]
    }
   ],
   "source": [
    "print metrics.mean_squared_error(testFactory.labels,y_pred_greedy),\n",
    "print metrics.mean_squared_error(testFactory.labels,y_pred_dcg_greedy),\n",
    "print metrics.mean_squared_error(testFactory.labels,y_pred_stupid),\n",
    "print metrics.mean_squared_error(testFactory.labels,y_pred_full)\n",
    "print \"well...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG@5\n",
      "nTrees= 100\n",
      "greedy: 0.523375561899\n",
      "dcg: 0.523957769168\n",
      "stupid: 0.449222985317\n",
      "full: 0.537504303084\n",
      "\n",
      "NDCG@10\n",
      "nTrees= 100\n",
      "greedy: 0.529145210812\n",
      "dcg: 0.53250719763\n",
      "stupid: 0.456648840525\n",
      "full: 0.543021161437\n",
      "\n",
      "NDCG@50\n",
      "nTrees= 100\n",
      "greedy: 0.606894830854\n",
      "dcg: 0.606927163386\n",
      "stupid: 0.55367057841\n",
      "full: 0.618088956755\n",
      "\n",
      "NDCG@None\n",
      "nTrees= 100\n",
      "greedy: 0.751248862003\n",
      "dcg: 0.7581451923\n",
      "stupid: 0.721413686091\n",
      "full: 0.757625718281\n"
     ]
    }
   ],
   "source": [
    "#NDCG\n",
    "from ranking_metrics import mean_ndcg\n",
    "for rank in [5,10,50,None]:\n",
    "    print \"\\nNDCG@\"+str(rank);\n",
    "    print 'nTrees=',target_n_trees\n",
    "    print 'greedy:',mean_ndcg(testFactory.labels,y_pred_greedy,testFactory.ids,rank = rank)\n",
    "    print 'dcg:',mean_ndcg(testFactory.labels,y_pred_dcg_greedy,testFactory.ids,rank = rank)\n",
    "    print 'stupid:',mean_ndcg(testFactory.labels,y_pred_stupid,testFactory.ids,rank = rank)\n",
    "    print 'full:',mean_ndcg(testFactory.labels,y_pred_full,testFactory.ids,rank = rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Раздельный прунинг\n",
    "* Выборка делится на части таким образом, чтобы для разных частей были актуальны различные деревья\n",
    "* Далее для каждой части обучается своя формула\n",
    "\n",
    "##Разделение выборки\n",
    "Для простоты имплементации, дерево верхнего уровня строится из наиболее популярных дихотомий изначальной формулы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#usability distribution\n",
    "read = True\n",
    "fname = '../dumps/thresholds.pcl'\n",
    "if not read:\n",
    "    thresholds = mnet.get_thresholds(trees,               #все деревья\n",
    "                                     formula.feature_ids, #названия фич\n",
    "                                     0.001                #tolerance к близким порогам дихотомий, \n",
    "                                                          #внутри которого дихотомии считаются одинаковыми \n",
    "                                                          #(доля дисперсии)\n",
    "                                    )\n",
    "    cDump(thresholds,fname)\n",
    "else:    \n",
    "    thresholds = cLoad(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngcHMzGr+fyCRssrtCSUsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4a0adf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(thresholds)),thresholds[:,2])\n",
    "print sum(thresholds[:,2] >100) #пороги хотя бы 100 раз встречаются в формуле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import alt_hierarchy as hierarchy # модуль, отвечающий за иерархический прунинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 ms, sys: 46 µs, total: 1.31 ms\n",
      "Wall time: 4.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read = True\n",
    "fname = \"../dumps/last_structure.pcl\"\n",
    "if not read:\n",
    "    \n",
    "    cand_thresholds = thresholds[thresholds[:,2]>=100]         #пороги хотя бы 100 раз встречаются в формуле\n",
    "\n",
    "    root = hierarchy.create_hierarchy(trainFactory,            #данные (factory)\n",
    "                                      trees,                   #все деревья\n",
    "                                      cand_thresholds,         #пороги\n",
    "                                      max_depth = 7,           #максимальная глубина\n",
    "                                      event_sample = 0.1,      #доля примеров, по которым выбирается оптимальная\n",
    "                                                               #дихотомия в каждом узле\n",
    "                                      threshold_sample = 1.,   #доля порогов, рассматриваемых в качестве дихотомии\n",
    "                                                               #в каждом узле\n",
    "                                      min_events_split = 0.0,  #минимальная доля примеров в нелистовом узле\n",
    "                                      min_events_leaf = 40000, #минимальная доля примеров в листовом узле\n",
    "                                      \n",
    "                                      metric = hierarchy.Penalized_entropy( #функция потерь\n",
    "                                                                hierarchy.normalized_usability_entropy, 0.25),\n",
    "                                      use_joblib = global_use_joblib,       #использовать ли параллелизм\n",
    "                                      n_jobs = global_n_jobs               #число потоков/процессов\n",
    "                                     ) \n",
    "    cDump(root,fname)\n",
    "else:\n",
    "    root = cLoad(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Вот-так выглядит дерево верхнего уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0\n",
      "\tSplit 1\n",
      "\t\tSplit 2\n",
      "\t\t\tLeaf w: 79149 d: 3 c: 000\n",
      "\t\t\tSplit 3\n",
      "\t\t\t\tLeaf w: 43599 d: 4 c: 0010\n",
      "\t\t\t\tLeaf w: 40786 d: 4 c: 0011\n",
      "\t\tSplit 2\n",
      "\t\t\tLeaf w: 61833 d: 3 c: 010\n",
      "\t\t\tSplit 3\n",
      "\t\t\t\tLeaf w: 42084 d: 4 c: 0110\n",
      "\t\t\t\tLeaf w: 44107 d: 4 c: 0111\n",
      "\tSplit 1\n",
      "\t\tLeaf w: 53186 d: 2 c: 10\n",
      "\t\tSplit 2\n",
      "\t\t\tSplit 3\n",
      "\t\t\t\tLeaf w: 62681 d: 4 c: 1100\n",
      "\t\t\t\tSplit 4\n",
      "\t\t\t\t\tLeaf w: 73720 d: 5 c: 11010\n",
      "\t\t\t\t\tLeaf w: 42776 d: 5 c: 11011\n",
      "\t\t\tSplit 3\n",
      "\t\t\t\tSplit 4\n",
      "\t\t\t\t\tLeaf w: 40993 d: 5 c: 11100\n",
      "\t\t\t\t\tLeaf w: 58043 d: 5 c: 11101\n",
      "\t\t\t\tSplit 4\n",
      "\t\t\t\t\tLeaf w: 40412 d: 5 c: 11110\n",
      "\t\t\t\t\tLeaf w: 40043 d: 5 c: 11111\n"
     ]
    }
   ],
   "source": [
    "def printTree(root,t = '',code = \"\",wdict = None):\n",
    "    if root.isLeaf:\n",
    "        print t+'Leaf',\n",
    "        if wdict is not None:\n",
    "            print 'w:',wdict[code],\n",
    "        print 'd:',len(t),'c:',code\n",
    "    else:\n",
    "        print t+'Split',len(t)\n",
    "        for i in [0,1]:\n",
    "            printTree(root.child[i],t+'\\t',code+str(i),wdict = wdict)\n",
    "def getLeafWeights(root,*args,**kwargs):\n",
    "    sdict = root.split(trainFactory)\n",
    "    wdict = {i:sdict[i].events.shape[0] for i in sdict}\n",
    "    return wdict\n",
    "wdict =getLeafWeights(root)\n",
    "printTree(root,wdict = wdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Прунинг для подвыборок\n",
    "* Обычный жадный прунинг, аналогичный первой секции статьи, производится для каждого листа независимо.\n",
    "* Для уменьшения переобучения, при прунинге в каждом листе в выборку добавляется часть примеров извне листа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 138 ms, sys: 80 µs, total: 138 ms\n",
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read = True\n",
    "fname = \"../dumps/last_splitted2.pcl\"\n",
    "if not read:\n",
    "    \n",
    "    trees_splitted = hierarchy.train_splitted_boosts(trees,                        #все деревья\n",
    "                                                     trainFactory,                 #данные (factory)\n",
    "                                                     root,                         #структура дерева\n",
    "                                                     loss = MSELoss,               #функция потерь\n",
    "                                                     learning_rate = 0.25,         #шаг обучения \n",
    "                                                     nTrees_leaf= target_n_trees,  #итоговое к-во деревьев в каждом листе\n",
    "                                                     trees_sample_size=1000,        #подвыборка деревьев, рассматриваемая на каждой итерации\n",
    "                                                     regularizer =0.0001*sum(trainFactory.weights), #регуляризатор значения в листе (аддитивно к знаменателю)\n",
    "                                                     verbose=True,                 #логи\n",
    "                                                     use_joblib =global_use_joblib,#использовать ли параллелизм\n",
    "                                                     n_jobs = global_n_jobs,       #число потоков/процессов\n",
    "                                                     inclusion_outside_leaf =0.9,  #размер подвыборки примеров извне листа,\n",
    "                                                                                   #используемых при прунинге в нём (относительно листа)\n",
    "                                                     weights_outside_leaf = 0.75,  #веса примеров извне листа, \n",
    "                                                                                   #используемые при прунинге в нём\n",
    "                                                     ) \n",
    "\n",
    "    cDump(trees_splitted,fname)\n",
    "else:\n",
    "    trees_splitted = cLoad(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_splitted= trees_splitted.predict(testFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spltd\t0.559991556357\n",
      "greedy\t0.563639784007\n",
      "stupid\t0.695731252371\n",
      "full\t0.554568902063\n",
      "well...\n"
     ]
    }
   ],
   "source": [
    "w_test = testFactory.weights\n",
    "Yts = testFactory.labels\n",
    "print 'spltd\\t',metrics.mean_squared_error(Yts,y_pred_splitted)\n",
    "print 'greedy\\t',metrics.mean_squared_error(Yts,y_pred_greedy)\n",
    "print 'stupid\\t',metrics.mean_squared_error(Yts,y_pred_stupid)\n",
    "print 'full\\t',metrics.mean_squared_error(Yts,y_pred_full)\n",
    "print \"well...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NDCG@5\n",
      "nTrees= 100\n",
      "greedy: 0.523375561899\n",
      "splitted: 0.528789303636\n",
      "stupid: 0.449222985317\n",
      "full: 0.537504303084\n",
      "\n",
      "NDCG@10\n",
      "nTrees= 100\n",
      "greedy: 0.529145210812\n",
      "splitted: 0.533482659538\n",
      "stupid: 0.456648840525\n",
      "full: 0.543021161437\n",
      "\n",
      "NDCG@50\n",
      "nTrees= 100\n",
      "greedy: 0.606894830854\n",
      "splitted: 0.613047571786\n",
      "stupid: 0.55367057841\n",
      "full: 0.618088956755\n",
      "\n",
      "NDCG@None\n",
      "nTrees= 100\n",
      "greedy: 0.751248862003\n",
      "splitted: 0.755725595318\n",
      "stupid: 0.721413686091\n",
      "full: 0.757625718281\n"
     ]
    }
   ],
   "source": [
    "#NDCG\n",
    "from ranking_metrics import mean_ndcg\n",
    "for rank in [5,10,50,None]:\n",
    "    print \"\\nNDCG@\"+str(rank);\n",
    "    print 'nTrees=',target_n_trees\n",
    "    print 'greedy:',mean_ndcg(testFactory.labels,y_pred_greedy,testFactory.ids,rank = rank)\n",
    "    print 'splitted:',mean_ndcg(testFactory.labels,y_pred_splitted,testFactory.ids,rank = rank)\n",
    "    print 'stupid:',mean_ndcg(testFactory.labels,y_pred_stupid,testFactory.ids,rank = rank)\n",
    "    print 'full:',mean_ndcg(testFactory.labels,y_pred_full,testFactory.ids,rank = rank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Кривые обучения по MSE\n",
    "Среднеквадратичная ошибка на тестовой выборке от количества деревьев\n",
    "\n",
    "Формула EventFilter на 100 деревьев с правильным learning rate, имеющая MSE 0.568, лежит где-то у Лёши"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xcfdc1f50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAM4CAYAAAAeRXcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naeK9B38PhmPa5PThAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xab2cc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_name = 'MSE'\n",
    "n_trees = target_n_trees\n",
    "metric = metrics.mean_squared_error\n",
    "\n",
    "stupid_lcurve = [i for i in learning_curve(trees_stupid,testFactory,metric,n_trees)]\n",
    "greedy_lcurve = learning_curve(trees_greedy,testFactory,metric,n_trees)\n",
    "splitted_lcurve = learning_curve(trees_splitted,testFactory,metric,n_trees)\n",
    "\n",
    "full_line = metric(testFactory.labels,y_pred_full)\n",
    "\n",
    "p = range(n_trees+1)\n",
    "\n",
    "plt.figure(figsize = [14,14])\n",
    "plt.plot(p,[full_line for i in p],label = \"full 10k ensemble\")\n",
    "plt.plot(p,[0.568 for i in p],label = \"100-tree ensemble\")\n",
    "plt.plot(p,stupid_lcurve,label = \"original ensemble\")\n",
    "plt.plot(p,greedy_lcurve,label = \"greedy pruning\")\n",
    "plt.plot(p,splitted_lcurve,label = \"splitted pruning\")\n",
    "plt.title('learning curves('+metric_name+')')\n",
    "plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_learning_curve(formula,factory,n_points = None,rank=50):\n",
    "    \n",
    "    lcurve = []\n",
    "\n",
    "    Ypred = np.zeros(len(factory.labels))\n",
    "                  \n",
    "    for i,tree_pred in enumerate(formula.staged_predict(factory)):\n",
    "\n",
    "        Ypred += tree_pred\n",
    "        lcurve.append(mean_ndcg(factory.labels,Ypred,factory.ids,rank = rank) )\n",
    "        if n_points is not None and i >= n_points:\n",
    "            break\n",
    "    while n_points is not None and i < n_points:\n",
    "        i+=1\n",
    "        lcurve.append(lcurve[-1])\n",
    "        \n",
    "    return lcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAM4CAYAAAAeRXcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvQA0zBCNXecFiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xab3dd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAM4CAYAAAAeRXcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT7ABAAC6J9gAAADd+/8BosBpbINSIuEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x519c7e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAM4CAYAAAAeRXcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4a746290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAM4CAYAAAAeRXcxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9d7d4410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_trees = target_n_trees\n",
    "for rank in [3,10,50,None]:\n",
    "    metric_name = 'NDCG at '+str(rank)\n",
    "    n_trees = target_n_trees \n",
    "    stupid_lcurve = [i for i in dcg_learning_curve(trees_stupid,testFactory,n_trees,rank)]\n",
    "    greedy_lcurve = dcg_learning_curve(trees_greedy,testFactory,n_trees,rank)\n",
    "    splitted_lcurve = dcg_learning_curve(trees_splitted,testFactory,n_trees,rank)\n",
    "\n",
    "    full_line = mean_ndcg(testFactory.labels,y_pred_full,testFactory.ids,rank=rank)\n",
    "\n",
    "    \n",
    "    p = range(n_trees+1)\n",
    "\n",
    "    plt.figure(figsize = [14,14])\n",
    "    plt.plot(p,[full_line for i in p],label = \"full 10k ensemble\")\n",
    "    plt.plot(p,[0.0 for i in p],label = \"100-tree ensemble\")\n",
    "    plt.plot(p,stupid_lcurve,label = \"original ensemble\")\n",
    "    plt.plot(p,greedy_lcurve,label = \"greedy pruning\")\n",
    "    plt.plot(p,splitted_lcurve,label = \"splitted pruning\")\n",
    "    plt.title('learning curves('+metric_name+')')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
